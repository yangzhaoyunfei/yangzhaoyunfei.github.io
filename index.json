[{"categories":["development kit"],"content":"概念 仓库(版本库) 仓库是任何一个版本系统的核心，它是开发者们保存工作的总部，仓库不止处理文件还有历史记录，它需要访问网络，扮演服务器的角色，版本控制工具扮演客户端的角色，客户端可以连接仓库，那么他们就可以从仓库中存储或者提取。仓库通过保存这些更改，一个客户端的更改可以被其他人检索到，一个客户端可以让其他人的更改作为一个工作副本。 主干 trunk 是主要开发所在的目录，经常被项目开发者们查看。 标签 tags 用于标识项目中某个被命名的快照，标签操作允许给予对仓库中特定版本一个描述和一个难忘的名字。比如，LAST_STABLE_CODE_BEFORE_EMAIL_SUPPORT 比 Repository UUID: 7ceef8cb-3799-40dd-a067-c216ec2e5247 和 Revision: 13 更令人难忘。 分支 分支操作用于创建开发的另一条线，当你想把开发进程复制进两个不同的方向是很有用的。比如，当你发布 5.0 版本时，你可能想从 5.0 的 bug 修复中分离出来创建一个开发 6.0 功能的分支。 工作副本( 即本地仓库) 工作副本是仓库的一个快照。这个仓库被所有的成员共享，但人们不直接修改它，相反每个开发者检查这个工作副本，工作副本是一个私人的工作空间，这里开发者可以独立于其他成员做自己的工作。 提交更改 提交是一个保存更改的过程，从私人工作空间提交到中央服务器。提交后，更改对全部成员可用，通过更新工作副本其他开发者提取这些更改。提交是一个原子操作，要么全部提交成功要么回滚，用户绝不会看到一半完成提交。 变更列表 已被版本控制跟踪的文件, 被修改后默认会被添加到变更列表. ","date":"2020-06-28","objectID":"/svn/:1:0","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"在服务端上工作 ","date":"2020-06-28","objectID":"/svn/:2:0","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"安装svn # ubuntu sudo apt install subversion -y # centos sudo dnf install subversion -y # 测试安装 svn --version ","date":"2020-06-28","objectID":"/svn/:2:1","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"创建版本库 简单项目 mkdir /opt/svn svnadmin create /opt/svn/runoob 复杂项目 照惯例，每个 SVN 项目都有主干，标签，分支在项目的 root 目录。 主干是主要开发和经常被开发者们查看的目录。 分支目录用于追求不同的开发方向。 推荐: 在项目版本库底下创建主干，标签，分支结构。 所以我们采用如下的目录结构: . └── svn-template ├── branches ├── tags └── trunk # 创建典型结构 targetdir=/tmp/svn-template mkdir $targetdir svnadmin create $targetdir mkdir $targetdir/trunk $targetdir/branches $targetdir/tags ","date":"2020-06-28","objectID":"/svn/:2:2","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"服务端的启动方式 一般都会以多库方式启动 svnserve -d -r 目录 --listen-port 端口号 -r: 配置方式决定了版本库访问方式。 –listen-port: 指定SVN监听端口，不加此参数，SVN默认监听3690 -r直接指定到版本库(称之为单库svnserve方式) svnserve -d -r /opt/svn/runoob 指定到版本库的上级目录(称之为多库svnserve方式) svnserve -d -r /opt/svn ","date":"2020-06-28","objectID":"/svn/:2:3","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"在客户端上工作 ","date":"2020-06-28","objectID":"/svn/:3:0","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"检出 svn checkout svn://192.168.0.1/runoob01 --username=user1 ","date":"2020-06-28","objectID":"/svn/:3:1","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"导入 # 将某文件夹导入到已有的svn版本库,版本库中abc目录不必存在 svn import -m 'Create trunk, branches, tags directory structure' /xxxdir svn://192.168.0.1/runoob01/abc ","date":"2020-06-28","objectID":"/svn/:3:2","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"提交 # 工作 touch readme # 查看工作副本中的状态, ？说明它还未加到版本控制中; A 表示已添加到变更列表. svn status # 添加修改到版本控制; 对已被跟踪的文件的修改会默认添加到变更列表 svn add readme # 提交到仓库 svn commit -m \"SVN readme.\" ","date":"2020-06-28","objectID":"/svn/:3:3","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"解决冲突 如对某文件在版本号为100的工作副本上做出变更后, 提交时遇到冲突(仓库中该文件已经是100+版本了), 执行下列命令 svn update # 选择mc(以本地的文件为主),做出修改后,再次提交 svn commit -m \"change xxx second\" ","date":"2020-06-28","objectID":"/svn/:3:4","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"回退 只对已添加到版本控制的文件有作用 # M 表示文件已被修改 M readme # 回退单个文件 svn revert readme # 回退整个目录 svn revert -R xxxdir # 将文件回退到某个版本(即撤销合并;假如现在是22,要退到21) svn merge -r 22:21 readme # 目录同 svn merge -r 22:21 -R xxxdir # 某版本(22)已提交,但是不想要了, 回退到21,修改后再次提交,即可. ","date":"2020-06-28","objectID":"/svn/:3:5","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"查看历史消息 svn log: 用来展示svn 的版本作者、日期、路径等等。 svn diff: 用来显示特定修改的行级详细信息。 svn cat: 取得在特定版本的某文件显示在当前屏幕。 svn list: 显示一个目录或某一版本存在的文件。 详细用法 ","date":"2020-06-28","objectID":"/svn/:3:6","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"分支 svn的分支,更像是目录的手动管理 # 拷贝主干为一个分支 svn copy trunk/ branches/my_branch # 查看状态 svn status # 提交新增的分支到版本库 svn commit -m \"add my_branch\" 在分支上工作 cd branches/my_branch/ # 工作..... 合并分支 # 切换回主干分支 cd branches/trunk # 更新 svn update # 合并其他分支 svn merge ../branches/my_branch/ # 提交 svn commit -m \"xxx\" ","date":"2020-06-28","objectID":"/svn/:3:7","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"标签 使用 tag 的概念，可以给某一个具体版本的代码一个更加有意义的名字。 Tags 即标签主要用于项目开发中的里程碑，比如开发到一定阶段可以单独一个版本作为发布等，它往往代表一个可以固定的完整的版本. # 为工作副本创建一个tag svn copy trunk/ tags/v1.0 # 提交tag内容 svn commit -m \"tags v1.0\" ","date":"2020-06-28","objectID":"/svn/:3:8","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"GUI工具 TortoiseSVN 下载地址, 下载安装; 或者使用如下命令安装 choco install tortoisesvn -y ","date":"2020-06-28","objectID":"/svn/:4:0","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["development kit"],"content":"References SVN 教程 ","date":"2020-06-28","objectID":"/svn/:5:0","tags":["svn"],"title":"Svn","uri":"/svn/"},{"categories":["lib"],"content":"jackson 常见用法 ","date":"2020-06-28","objectID":"/jackson/:0:0","tags":[""],"title":"Jackson","uri":"/jackson/"},{"categories":["lib"],"content":"References Jackson 框架的高阶应用 Jackson Project Home @github ","date":"2020-06-28","objectID":"/jackson/:1:0","tags":[""],"title":"Jackson","uri":"/jackson/"},{"categories":["development kit"],"content":"子模块使用 官方指南 ","date":"2020-06-07","objectID":"/git-submodule/:1:0","tags":["Git","子模块"],"title":"Git-子模块","uri":"/git-submodule/"},{"categories":["development kit"],"content":"最常用 添加子模块 初始化并更新子模块 ","date":"2020-06-07","objectID":"/git-submodule/:2:0","tags":["Git","子模块"],"title":"Git-子模块","uri":"/git-submodule/"},{"categories":["development kit"],"content":"添加子模块 默认情况下，子模块会将子项目放到当前工作目录下的一个与仓库同名的目录中，本例中是 repository-sub-one、repository-sub-two. 如果你想要放到其他地方，那么可以在命令结尾添加一个不同的路径。 git submodule add git@gitee.com:yangzhaoyunfei/repository-sub-one.git\rgit submodule add git@gitee.com:yangzhaoyunfei/repository-sub-two.git\r# 或\rgit submodule add git@gitee.com:yangzhaoyunfei/repository-sub-two.git path/to/dir\r .gitmodules 文件。 该配置文件保存了项目 URL 与已经拉取的本地目录之间的映射： [submodule \"repository-sub-two\"]\rpath = repository-sub-two\rurl = git@gitee.com:yangzhaoyunfei/repository-sub-two.git\r[submodule \"repository-sub-one\"]\rpath = repository-sub-one\rurl = git@gitee.com:yangzhaoyunfei/repository-sub-one.git\r Git 子模块允许你将一个 Git 仓库作为另一个 Git 仓库的子目录。 它能让你将另一个仓库克隆到自己的项目中，同时还保持提交的独立。 当你不在子模块那个目录中时，Git 并不会跟踪它的内容， 而是将它看作子模块仓库中的某个具体的提交。 ","date":"2020-06-07","objectID":"/git-submodule/:2:1","tags":["Git","子模块"],"title":"Git-子模块","uri":"/git-submodule/"},{"categories":["development kit"],"content":"克隆带有子模块的项目 手动选择要检出的子模块 # 默认会包含该子模块目录，但其中还没有任何文件.\rgit clone git@gitee.com:yangzhaoyunfei/repository-main\r# 在子模块目录中初始化出本地git配置文件\rcd ./repository-main/repository-sub-one\rgit submodule init\r# 检出子模块文件\r# 从该项目中抓取所有数据并检出到在父项目中列出的合适的提交(子模块自身有多个提交,但检出到父模块的只能有一个提交)\rgit submodule update\r# 或者init update 可以合并为一个操作\rgit submodule update --init\r 自动检出全部子模块 # 会自动初始化并更新仓库中的每一个子模块， 包括可能存在的嵌套子模块\rgit clone --recurse-submodules git@gitee.com:yangzhaoyunfei/repository-main\r ","date":"2020-06-07","objectID":"/git-submodule/:2:2","tags":["Git","子模块"],"title":"Git-子模块","uri":"/git-submodule/"},{"categories":["development kit"],"content":"在主项目上工作 ","date":"2020-06-07","objectID":"/git-submodule/:3:0","tags":["Git","子模块"],"title":"Git-子模块","uri":"/git-submodule/"},{"categories":["development kit"],"content":"从子模块的远端拉取上游修改 手动抓取与合并 # 在子模块目录操作, 主项目中的子模块提交记录会更新\rgit fetch \u0026\u0026 git merge origin/master\r 自动抓取与合并 # 在主项目中操作, Git 将会自动进入**所有子模块**然后抓取并更新\r# 默认master分支\rgit submodule update --remote\r# 或(只更新某个模块)\rgit submodule update --remote repository-sub-one\r ","date":"2020-06-07","objectID":"/git-submodule/:3:1","tags":["Git","子模块"],"title":"Git-子模块","uri":"/git-submodule/"},{"categories":["development kit"],"content":"从主项目远端拉取上游更改 在主模块中拉取更改只会获取子模块的提交记录,不会检出子模块更新后的文件.所以需要手动更新, # 为防止在主模块中添加了新子模块,所以需要添加--init\rgit submodule update --init --recursive\r ","date":"2020-06-07","objectID":"/git-submodule/:3:2","tags":["Git","子模块"],"title":"Git-子模块","uri":"/git-submodule/"},{"categories":["development kit"],"content":"在子模块上工作 与在普通仓库上工作无异。 ","date":"2020-06-07","objectID":"/git-submodule/:4:0","tags":["Git","子模块"],"title":"Git-子模块","uri":"/git-submodule/"},{"categories":["development kit"],"content":"添加 \\ 删除子模块 子模块与父模块使用不同的远程仓库，互不影响,以下命令均在父模块根目录下操作 # 添加\rgit submodule add -b master https://github.com/username/reponame.git dirname\r# 或\rgit submodule add -b master git@github.com:username/reponame.git dirname\r# 移除\rgit rm submodule-name\r Removing a submodule is useful when it is no longer required. The steps below outline the removal of a submodule. Remove Submodule Delete the section referring to the submodule from the .gitmodules file Stage the changes via git add .gitmodules Delete the relevant section of the submodule from .git/config. Run git rm –cached path_to_submodule (no trailing slash) Run rm -rf .git/modules/path_to_submodule Commit the changes with ```git commit -m “Removed submodule \" Delete the now untracked submodule files rm -rf path_to_submodule ","date":"2020-06-07","objectID":"/git-submodule/:4:1","tags":["Git","子模块"],"title":"Git-子模块","uri":"/git-submodule/"},{"categories":["development kit"],"content":"References 移除子模块 ","date":"2020-06-07","objectID":"/git-submodule/:5:0","tags":["Git","子模块"],"title":"Git-子模块","uri":"/git-submodule/"},{"categories":["development kit"],"content":" docker run -p 8080:8080 -p 50000:5000 --name jenkins \\ -u root \\ -v /mydata/jenkins_home:/var/jenkins_home \\ -e JENKINS_UC_DOWNLOAD=\"https://updates.jenkins-zh.cn/update-center.json\" \\ -d jenkins/jenkins:lts ","date":"2020-05-08","objectID":"/docker_jenkins/:0:0","tags":["docker","jenkins"],"title":"Docker 安装 jenkins","uri":"/docker_jenkins/"},{"categories":["development kit"],"content":"References 真实有用的 Jenkins 插件安装加速 使用Jenkins一键打包部署SpringBoot应用，就是这么6！ Jenkins for Docker 跳过插件安装及插件加速镜像设置 ","date":"2020-05-08","objectID":"/docker_jenkins/:1:0","tags":["docker","jenkins"],"title":"Docker 安装 jenkins","uri":"/docker_jenkins/"},{"categories":["java"],"content":"java中如何获取各种路径","date":"2020-05-06","objectID":"/get_path/","tags":["java","获取路径"],"title":"获取各种路径","uri":"/get_path/"},{"categories":["java"],"content":"获取spring boot 可执行jar包所在路径 @SpringBootApplication public class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); ApplicationHome home = new ApplicationHome(DemoApplication.class); home.getDir(); // returns the folder where the jar is. This is what I wanted. home.getSource(); // returns the jar absolute path. //输出如下： //C:\\Users\\foo\\IdeaProjects\\code-snippet\\spring-boot\\demo\\target //C:\\Users\\foo\\IdeaProjects\\code-snippet\\spring-boot\\demo\\target\\demo-0.0.1-SNAPSHOT.jar } } ","date":"2020-05-06","objectID":"/get_path/:1:0","tags":["java","获取路径"],"title":"获取各种路径","uri":"/get_path/"},{"categories":["java"],"content":"未完待续 ","date":"2020-05-06","objectID":"/get_path/:2:0","tags":["java","获取路径"],"title":"获取各种路径","uri":"/get_path/"},{"categories":["java"],"content":"References JAVA获取文件路径 How to get spring boot application jar parent folder path dynamically? ","date":"2020-05-06","objectID":"/get_path/:3:0","tags":["java","获取路径"],"title":"获取各种路径","uri":"/get_path/"},{"categories":["spring"],"content":"相关概念 ","date":"2020-04-25","objectID":"/spring_testing/:1:0","tags":["spring","测试"],"title":"Spring 单元测试 \u0026 集成测试","uri":"/spring_testing/"},{"categories":["spring"],"content":"References 高手都这么给 Spring MVC 做单元测试！ - 芋道源码的文章 - 知乎 一篇教你学会Junit5 - 粥粥的文章 - 知乎 ","date":"2020-04-25","objectID":"/spring_testing/:2:0","tags":["spring","测试"],"title":"Spring 单元测试 \u0026 集成测试","uri":"/spring_testing/"},{"categories":["web"],"content":"跨域解决方案","date":"2020-04-08","objectID":"/crossorigin/","tags":["跨域","CORS"],"title":"跨域资源共享CORS","uri":"/crossorigin/"},{"categories":["web"],"content":"详细代码及测试案例见ref。 ","date":"2020-04-08","objectID":"/crossorigin/:0:0","tags":["跨域","CORS"],"title":"跨域资源共享CORS","uri":"/crossorigin/"},{"categories":["web"],"content":"跨域错误产生的条件 必须是浏览器上发出的请求 必须是XMLHttpRequest请求 跨域: 协议，域名，端口任何一个不同就算跨域 ","date":"2020-04-08","objectID":"/crossorigin/:1:0","tags":["跨域","CORS"],"title":"跨域资源共享CORS","uri":"/crossorigin/"},{"categories":["web"],"content":"解决思路 从三个产生条件上进行解决 针对浏览器 以chrome为例，增加参数–disable-web-security 针对XMLHttpRequest请求 使用jsonp Spring 4 中可以通过 AbstractJsonpResponseBodyAdvice 支持 jsonp； Spring 5 中已经移除了相关支持； 针对跨域 服务器返回支持跨域信息 //在class上或service方法上使用@CrossOrigin @RestController @CrossOrigin public class TestController { //... } @RestController public class Controller { @CrossOrigin @GetMapping(\"/show\") public Banner getBanner() { //... } } 使用反向代理(具体见ref) 使用反向代理，代理非本域名的请求，在外面看来就是同一个系统的请求，自然不用担心跨域问题。 以nginx配置为例，配置非常简单，配置如下： 表示 /bcom 开头的请求都转发到 http://b.com:8080/ server { listen 80; server_name a.com; location / { proxy_pass http://a.com:8080/; } location /bcom/ { proxy_pass http://b.com:8080/; } } ","date":"2020-04-08","objectID":"/crossorigin/:2:0","tags":["跨域","CORS"],"title":"跨域资源共享CORS","uri":"/crossorigin/"},{"categories":["web"],"content":"带cookie的跨域请求 默认跨域都是不带cookie或身份认证信息等的。 但我们很多时候需要发送cookie（如会话等），这种情况发送XMLHttpRequest请求的时候，客户端需要设置 withCredentials 为true，然后服务端需要返回支持cookie配置，需要返回 Access-Control-Allow-Credentials : true 和 Access-Control-Allow-Origin : 对应的域名 ，注意：此处不能用*，必须是具体的域名。 编写js代码: function getWithCookie() { $.ajax({ type : \"GET\", url : \"http://b.com:8080/getWithCookie\", xhrFields : { withCredentials : true }, success : function(data) { console.log(\"getWithCookie Loaded: \", data); } }) } 编写java代码，后台使用spring的@CookieValue注解获取cookie值。 @RestController public class Controller { @GetMapping(\"/getWithCookie\") public ResultBean\u003cString\u003e getWithCookie(@CookieValue(required=false) String cookie1) { System.out.println(\"\\n-------TestController.getWithCookie(), cookie1=\"+cookie1); return new ResultBean\u003cString\u003e(\"getWithCookie ok, cookie1=\"+cookie1); } } 注意，@CrossOrigin(allowedHeaders = { “X-Custom-Header1”, “X-Custom-Header2”, “X-Custom-Header4” })需要配置在方法上，不要配在类上面的 @CrossOrigin 注解上，否则会导致一些问题。 编写js代码，JQ里面增加自定义头有2种方法。headers 和 beforeSend事件 加。 ","date":"2020-04-08","objectID":"/crossorigin/:3:0","tags":["跨域","CORS"],"title":"跨域资源共享CORS","uri":"/crossorigin/"},{"categories":["web"],"content":"带自定义header的跨域请求 很多时候，我们需要发送自定义的header，这个时候首先先要在服务器配置能接受哪些header。并使用 @RequestHeader 得到头字段。 @RestController public class Controller { @GetMapping(\"/getWithHeader\") @CrossOrigin(allowedHeaders = { \"X-Custom-Header1\", \"X-Custom-Header2\", \"X-Custom-Header4\" }) public ResultBean\u003cString\u003e getWithHeader( @RequestHeader(required = false, name = \"X-Custom-Header1\") String header1) { System.out.println(\"\\n-------TestController.getWithHeader(), header1=\" + header1); return new ResultBean\u003cString\u003e(\"getWithHeader ok, header1=\" + header1); } } ","date":"2020-04-08","objectID":"/crossorigin/:4:0","tags":["跨域","CORS"],"title":"跨域资源共享CORS","uri":"/crossorigin/"},{"categories":["web"],"content":"总结 本着工匠精神就写细一点，发现东西还是比较多的，本来觉得写4个小时应该就能写完了，结果周末花了快2天才写完，最后总结一下，对工作中用得上的知识点。 发生跨域访问的三个条件：浏览器端，跨域，异步。 针对异步的解决方法jsonp有很多硬伤，并不推荐。 浏览器发送跨域请求之前会区分简单请求还是非简单请求，简单请求是直接请求，请求完再根据响应头信息判断（如果不支持跨域，尽管服务器成功执行返回200，但浏览器还是报错），非简单请求会先发送 OPTIONS咨询命令（如果不支持跨域，返回403禁止访问错误，支持则返回200，但并不一定就代表该请求能发出去，某些情况服务器还需要额外判断）。 工作中遇到比较常见的非简单请求就是发送json数据的和带自定义头的。（带cookie的是简单请求） 使用Spring的 @CrossOrigin 能很方便的解决跨域访问问题，几乎只需要一行代码。 使用反向代理也是比较好的解决方法，公司内部配置也比较简单，反向代理能封装很多细节，增加很多其他特性。 学会注解 @RequestHeader 和 @CookieValue 的使用，不要自己去request对象上获取这些信息。 ","date":"2020-04-08","objectID":"/crossorigin/:5:0","tags":["跨域","CORS"],"title":"跨域资源共享CORS","uri":"/crossorigin/"},{"categories":["web"],"content":"相关问题 ","date":"2020-04-08","objectID":"/crossorigin/:6:0","tags":["跨域","CORS"],"title":"跨域资源共享CORS","uri":"/crossorigin/"},{"categories":["web"],"content":"jsonp为什么只支持get，不支持post？ jsonp不是使用xhr发送的，是使用动态插入script标签实现的，当前无法指定请求的method，只能是get。调用的地方看着一样，实际上和普通的ajax有2点明显差异：1. 不是使用xhr 2.服务器返回的不是json数据，而是js代码。 ","date":"2020-04-08","objectID":"/crossorigin/:7:0","tags":["跨域","CORS"],"title":"跨域资源共享CORS","uri":"/crossorigin/"},{"categories":["web"],"content":"spring boot 跨域实现 https://spring.io/guides/gs/rest-service-cors/ ","date":"2020-04-08","objectID":"/crossorigin/:8:0","tags":["跨域","CORS"],"title":"跨域资源共享CORS","uri":"/crossorigin/"},{"categories":["web"],"content":"spring cloud 跨域实现 https://segmentfault.com/a/1190000017188296 https://cloud.spring.io/spring-cloud-gateway/multi/multi__cors_configuration.html ","date":"2020-04-08","objectID":"/crossorigin/:9:0","tags":["跨域","CORS"],"title":"跨域资源共享CORS","uri":"/crossorigin/"},{"categories":["web"],"content":"References ajaxdemo 1.7. CORS Spring 5 JSONP deprecated. Use CORS 简单跨域请求和复杂跨域请求的区别 ","date":"2020-04-08","objectID":"/crossorigin/:10:0","tags":["跨域","CORS"],"title":"跨域资源共享CORS","uri":"/crossorigin/"},{"categories":["mybatis"],"content":"项目中的最佳实践是把自动生成的代码和手工写的代码放在不同的地方，xml和Mapper都分开放，方便管理。 比如： src/main/java/xxx/mapper/auto src/main/java/xxx/mapper/manual imagepop \" image xml也是类似的，这样就不用担心重新生成时的覆盖问题了。 imagepop \" image 然后manual里可以继承auto中的结果映射关系, 示例: \u003cresultMap id=\"BaseResultMap\" type=\"com.company.xxx.model.SysPermission\" extends=\"com.company.xxx.mapper.auto.SysPermissionMapper.BaseResultMap\"\u003e \u003c/resultMap\u003e ","date":"2020-04-08","objectID":"/mybatis_xml_management/:0:0","tags":["自动生成代码","分开管理","最佳实践"],"title":"mybatis-自动生成代码管理 最佳实践","uri":"/mybatis_xml_management/"},{"categories":["mybatis"],"content":"References 1 ","date":"2020-04-08","objectID":"/mybatis_xml_management/:1:0","tags":["自动生成代码","分开管理","最佳实践"],"title":"mybatis-自动生成代码管理 最佳实践","uri":"/mybatis_xml_management/"},{"categories":["Operating system"],"content":"管程再功能上与信号量及PV操作类似，属于一种高级进程同步与互斥工具，但是具有与信号量及PV操作不同的属性 ","date":"2020-04-02","objectID":"/monitors/","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"引入原因 信号量机制的缺点：进程自备同步操作，P(S)、V(S)操作大量分散在各个进程中，还要仔细安排P(S)的顺序，不易管理，易发生死锁。1974年和1977年，Hore和Hansen提出了管程。 引入管程的目的： 把分散在各进程中的临界区集中起来进行管理； 防止进程的非法同步操作； 便于利用高级语言来编程，便于验证程序正确性； ","date":"2020-04-02","objectID":"/monitors/:1:0","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"概念 管程是由局限于自己的若干共享变量(数据结构)及其说明，和所有访问这些共享变量的过程所组成的软件模块。 基本思想：把信号量及其操作原语封装在一个对象中，即将共享资源及其操作集中在一个模块中。管程可以使用函数库的形式实现，众多语言中都已经实现了管程。 简单地说管程就是一个概念模型，任何语言都可以实现。 ","date":"2020-04-02","objectID":"/monitors/:2:0","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"特点 局限于管程的共享变量(数据结构)只能被管程中的过程访问； 一个进程通过调用管程中的任一过程进入管程； 任何时候只能有一个进程在管程中执行，调用管程的其他进程将被挂起，以等待管程变为可用，即管程有效地实现互斥。进入管程的互斥机制由编译器负责，通常使用信号量。 管程可被系统范围内的进程互斥访问，属于共享资源。 ","date":"2020-04-02","objectID":"/monitors/:3:0","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"组成结构 局部共享变量和条件变量组成管程内的数据结构； 对数据结构进行操作的一组过程 对数据结构进行初始化的语句 一个互斥锁(由编译器添加) 在管程的简单实现中，编译器为每个管程对象自动加入一把私有的互斥锁。该互斥锁初始状态为解锁，在管程的每个公共过程的入口给该互斥锁加锁，在管程的每个公共过程的出口给该互斥锁解锁。 ","date":"2020-04-02","objectID":"/monitors/:4:0","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"条件变量 条件变量(以c为例)是管程内的一种数据结构，只能通过两个原语来操作它： wait(c)：调用进程被阻塞并移入与条件变量c相关的队列中，并释放管程，直到另一个进程在该条件变量c上执行signal()唤醒等待进程并将其移出c的队列。 signal(c)：如果存在其他进程由于执行wait(c)而被阻塞，便释放一个；如果没有进程在等待，那么信号被丢弃而不会产生任何效果。 条件变量与P、V操作中的信号量的区别： 条件变量是一种信号量，但不是P、V操作中纯粹的计数信号量，不能累计数目，仅仅起到维护等待队列的作用。因此在使用条件变量x时，通常需要定义一个与之配套使用的整型变量x-count用于记录x所维护的等待队列中的进程数。 ","date":"2020-04-02","objectID":"/monitors/:4:1","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"为什么要有条件变量 首先，入口等待队列及互斥锁只能保证进程对临界资源的互斥访问，无法解决进程同步(时序)的问题。于是引入了条件变量及其对应的队列。并为条件变量提供了wait()、signal()原语，使得可以实现进程的阻塞和唤醒，从而提供进程同步的机制。 ","date":"2020-04-02","objectID":"/monitors/:4:2","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"管程入口处的等待队列 管程是互斥进入的，所以当一个进程试图进入一个已被占有的管程时它应该在管程的入口处等待，因而，管程的入口处应当有一个进程等待队列，称为入口等待队列。 ","date":"2020-04-02","objectID":"/monitors/:4:3","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"管程内的资源等待队列 管程是用于管理资源的，当已进入管程的进程因资源被占用等原因不能继续执行时应使其等待，即将等待资源的进程加入资源等待队列，该队列由条件变量维护。资源等待队列可以有多个，每种资源一个队列。 ","date":"2020-04-02","objectID":"/monitors/:4:4","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"管程内的紧急等待队列 进入管程中的进程，执行唤醒signal操作后(如P唤醒Q，注意：signal操作可能不在管程过程的最后，看实现管程者是如何编写的)，就有两个进程活跃在管程中，由于管程是互斥使用的，因此必须将其中一个进程挂起： P等待Q继续，直到Q退出或等待； Q等待P继续，直到P等待或退出； 规定signal为管程过程中的最后一个操作，执行完后进程即刻退出管程。 此时要么把挂起进程放入入口等待队列，该进程就会与其他等待进入管程的进程一起竞争。但从某种角度上来说，该挂起进程已经在管程中执行了部分任务，使他优先于其他等待进程是有意义的。因此，我们可以建议一个紧急等待队列，将该挂起进程放入其中。 ","date":"2020-04-02","objectID":"/monitors/:4:5","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"管程模型与信号量模型的区别 使用信号量机制时，互斥和同步都属于进程自己的责任，同步代码(PV操作等)分散在进程各处；各进程还要仔细安排PV操作的顺序，谨慎定义信号量的数值，遗漏一个V操作都有可能时其他进程永远挂起。 而管程构造了自己的互斥机制，由编译器实现，通常使用信号量机制。管程优于信号量之处在于所有同步机制都被限制在管程内部，因此易于验证同步的正确性，易于检查出错误。 ","date":"2020-04-02","objectID":"/monitors/:5:0","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"历史上的管程模型 并发编程领域已经发展半个世纪了，管程也经历了多种模型。分别是： Hasen模型； Hoare模型； Mesa模型； 现在广泛应用的是Mesa模型。 imagepop \" image ","date":"2020-04-02","objectID":"/monitors/:6:0","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"java中的管程 java中每个对象都可以关联一个管程，通过在Java对象头中的mark word中存储了指向monitor的指针。synchronized关键字、wait()、notify()、notifyAll()这几个方法都是java中管程实现的一部分，其底层是调用了ObjectMonitor的方法。详细内容可参考此处 java参考了Mesa模型，语言内置的管程实现(synchronized)对Mesa模型做了简化。Mesa模型中，条件变量可以有多个，Java语言内置的管程里只有一个条件变量(就是对象锁)。如下图所示： imagepop \" image juc中实现的管程支持多个条件变量，不过juc中的锁，需要开发人员自己进行加锁和解锁操作。 ","date":"2020-04-02","objectID":"/monitors/:7:0","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"总结 并发编程领域的两大问题–互斥、同步，都可以通过管程来解决。管程的解决方法如下： 互斥：管程将共享变量及对共享变量的操作统一封装起来,并通过一个互斥锁来保证同一时刻只允许一个进程进入管程，以实现对共享变量的互斥访问。这个互斥锁一般是由编译器自动添加的。 同步(时序)：管程中引入了条件变量，而且每个条件变量都对应有一个等待队列，通过这两者来提供同步的机制。条件变量有wait()、signal()两种操作原语，管程中的过程通过调用条件变量的操作原语来封装了进程的同步操作，使进程在条件不满足时被阻塞，条件满足时被唤醒。进程调用管程中的过程就可以实现同步。但管程的过程里何时应该阻塞进程，何时唤醒进程都是由程序员自己决定的，管程模型并不知道你的程序逻辑。 管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程。但是管程更容易使用，所以 Java 选择了管程。 ","date":"2020-04-02","objectID":"/monitors/:8:0","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"References 维基百科 百度百科 知乎-应该如何理解管程？ [Java并发-6]“管程”-java管程初探 Synchronized之管程 ","date":"2020-04-02","objectID":"/monitors/:9:0","tags":["管程","进程同步","进程互斥"],"title":"管程(Monitors)","uri":"/monitors/"},{"categories":["Operating system"],"content":"问题引出 信号量可以很好的解决单个资源的互斥访问。 在有些应用中，进程需要先获得两个或更多共享资源后才能执行其任务，由此产生进程对多个资源的互斥访问。 比如p1、p2共享两个全局变量，r1\\r2，p1先P(mutex1),p2再P(mutex2),然后两个分别再申请另一个变量，这时候，两个进程都会阻塞，无法再继续执行。 ","date":"2020-04-02","objectID":"/and_semaphore/:1:0","tags":["信号量"],"title":"and 信号量","uri":"/and_semaphore/"},{"categories":["Operating system"],"content":"And信号量 and信号量同步机制就是要解决上述问题，其基本思想是将进程在整个运行期间所需要的所有临界资源一次性全部分配给进程，待进程使用完成后再一起释放。 只要有一个资源不能满足进程的要求，其他资源也都不会分配，因此再P操作上增加了and条件，所以称作and信号量。 ","date":"2020-04-02","objectID":"/and_semaphore/:2:0","tags":["信号量"],"title":"and 信号量","uri":"/and_semaphore/"},{"categories":["Operating system"],"content":"and信号量 VS 普通信号量 代码上： 普通信号量的P操作中只需要判断单个资源的数量是否满足进程要求。 and信号量的P操作中使用\u0026\u0026操作符判断多个资源的数量是否满足进程要求。 使用上： 普通信号量适用于申请单个资源。 and信号量适用于一次性申请多个资源，防止死锁发生。 ","date":"2020-04-02","objectID":"/and_semaphore/:3:0","tags":["信号量"],"title":"and 信号量","uri":"/and_semaphore/"},{"categories":["Operating system"],"content":"应用 用and信号量解决哲学家进餐问题 用and信号量解决生产者-消费者问题 ","date":"2020-04-02","objectID":"/and_semaphore/:4:0","tags":["信号量"],"title":"and 信号量","uri":"/and_semaphore/"},{"categories":["Operating system"],"content":"操作系统中的并发进程有些是独立的, 有些需要相互协作.进程之间的协作关系包括互斥、同步、通信。 互斥：多个进程不能同时使用同一个资源，当某个进程使用某种资源时，其他要使用该资源的进程必须等待。 同步：多个进程中发生的事情存在着某种时序关系，某些进程的执行必须先于另一些进程。 通信：多个进程之间要传递一定量的信息。 ","date":"2020-04-01","objectID":"/process_sync_mutex/:0:0","tags":["同步","互斥"],"title":"进程同步与互斥","uri":"/process_sync_mutex/"},{"categories":["Operating system"],"content":"基础概念 临界资源: 在某段时间内只允许一个进程使用的资源。 临界区: 进程中访问临界资源的那段程序。 ","date":"2020-04-01","objectID":"/process_sync_mutex/:1:0","tags":["同步","互斥"],"title":"进程同步与互斥","uri":"/process_sync_mutex/"},{"categories":["Operating system"],"content":"进程并发执行的条件(Bernstein condition) 假设R(Pi)={a1,a2,…,am}表示程序Pi在执行期间所要参考的所有变量的集合，称为“读集”。W(Pi)={b1,b2,…,bn}表示程序Pi执行期间要改变的所有变量的集合，称为“写集”。两个程序P1和P2并发执行的条件是： 当且仅当R(P1)∩W(P2)∪R(P2)∩W(P1)∪W(P1)∩W(P2)={}。 ","date":"2020-04-01","objectID":"/process_sync_mutex/:2:0","tags":["同步","互斥"],"title":"进程同步与互斥","uri":"/process_sync_mutex/"},{"categories":["Operating system"],"content":"进程访问临界区的一般结构 进入区：对临界资源进行检查，看他是否正在被访问。如果未被访问则可进入，并设置它正被访问的标志。如正被访问，则不能进入。 临界区：访问临界资源。 退出区：将临界区正被访问的标志恢复为未被访问。 剩余区：除上述之外的区域。 ","date":"2020-04-01","objectID":"/process_sync_mutex/:3:0","tags":["同步","互斥"],"title":"进程同步与互斥","uri":"/process_sync_mutex/"},{"categories":["Operating system"],"content":"互斥访问的实现方式 实现互斥有多种方法： 让希望并发执行的进程自己完成，不需要操作系统提供任何支持； 使用专门的机器指令来完成，与具体的硬件系统相关，难成为通用方案； 由操作系统提供支持。 ","date":"2020-04-01","objectID":"/process_sync_mutex/:4:0","tags":["同步","互斥"],"title":"进程同步与互斥","uri":"/process_sync_mutex/"},{"categories":["Operating system"],"content":"硬件实现 禁止中断 在临界区内的进程不能被中断，故保证了互斥进入临界区。只适用于单处理机。 专用机器指令(原子指令/原语操作，防止被调度) TS(Test and Set)指令 Swap指令 都是给临界资源设置一个布尔变量lock，表示资源的两种状态，true表示正被占用；false表示空闲。在进入区中检查lock变量，在退出区中检查 ","date":"2020-04-01","objectID":"/process_sync_mutex/:4:1","tags":["同步","互斥"],"title":"进程同步与互斥","uri":"/process_sync_mutex/"},{"categories":["Operating system"],"content":"软件实现 通过平等协商方式实现进程互斥。基本思路是在进入区检查和设置一些标志，如果有进程在临界区，则在进入区通过循环检查进行等待；在退出区修改标志。 单标志算法 双标志、先检查算法 双标志、先修改后检查算法 先修改、后检查、后修改者等待算法。 上述算法在进程数上有很大局限性，不同的进程数，代码不一样。故很少使用。 ","date":"2020-04-01","objectID":"/process_sync_mutex/:4:2","tags":["同步","互斥"],"title":"进程同步与互斥","uri":"/process_sync_mutex/"},{"categories":["Operating system"],"content":"信号量和PV操作 信号量：包含一个整型数值s.value和一个s上的等待队列s.queue，信号量只能通过P、V原语来操作。 原语：。。。 ","date":"2020-04-01","objectID":"/process_sync_mutex/:5:0","tags":["同步","互斥"],"title":"进程同步与互斥","uri":"/process_sync_mutex/"},{"categories":["Operating system"],"content":"信号量的物理意义 s.value表示系统中某种资源的数目(并不是资源本身)，因此又称为资源信号量。 p操作意味着进程请求一个资源，如果无法满足，进程将自我阻塞，并将自己投入s.queue. v操作意味着进程释放一个资源，当有进程在s.queue上等待时，还会从中唤醒一个进程。 s.value\u003c0时，其绝对值表示等待队列中的进程数。 ","date":"2020-04-01","objectID":"/process_sync_mutex/:5:1","tags":["同步","互斥"],"title":"进程同步与互斥","uri":"/process_sync_mutex/"},{"categories":["Operating system"],"content":"用信号量解决互斥问题 当s.value=1时，表示仅有一个资源，即仅允许一个进程访问临界区，此时的信号量转换为互斥信号量。通常定义为mutex=1. 在进入区使用P操作申请资源，失败则阻塞自己。 在退出区使用V操作释放资源，从等待队列中唤醒一个阻塞进程。 ","date":"2020-04-01","objectID":"/process_sync_mutex/:6:0","tags":["同步","互斥"],"title":"进程同步与互斥","uri":"/process_sync_mutex/"},{"categories":["Operating system"],"content":"用信号量解决同步问题 如果进程P2必须在进程P1执行完成之后才执行，则可以设置一个信号量s.value=0. 在P1的尾部V(s), 给信号量+1，在P2头部使用P(s)，即可控制先后顺序。 这类思想，可以推广到多各进程当中，但麻烦之处是，n个先后关系需要n个信号量。 ","date":"2020-04-01","objectID":"/process_sync_mutex/:7:0","tags":["同步","互斥"],"title":"进程同步与互斥","uri":"/process_sync_mutex/"},{"categories":["development kit"],"content":" # 拉取镜像 docker pull node:lts # 查看镜像 docker images node # 运行容器 docker run -itd --name mynode node:lts # 连接到容器 docker exec -it mynode /bin/bash # 参看版本 node -v ","date":"2020-03-28","objectID":"/nodejs_docker/:0:0","tags":["环境部署","nodejs"],"title":"Docker 安装 NodeJS","uri":"/nodejs_docker/"},{"categories":["distributed system"],"content":"背景 分布式事务一致性与 raft或paxos协议 解决的共识性问题不是同一回事. 这种歧义源于对英文学术名词的错误翻译。分布式事务一致性中的\"一致\"对应的英文单词是consistency，而raft或paxos中的\"一致\"对应的英文单词是consensus。新出版的文献正逐渐把consensus翻译为共识，而consistency继续翻译为一致。 ","date":"2020-03-28","objectID":"/consistency_consensus/:1:0","tags":["一致性","共识"],"title":"一致性(consistency)与共识(consensus)","uri":"/consistency_consensus/"},{"categories":["distributed system"],"content":"共识问题 raft和paxos论文中所涉及的consensus( /kənˈsensəs/)问题是分布式系统理论中三大基本问题（time、consensus、message model）之一，是元问题；共识问题关注进程容错，通过一种巧妙的算法使得数据和计算得到复制，并协同进行，与共识问题相关的学术名词叫做复制状态机。 ","date":"2020-03-28","objectID":"/consistency_consensus/:2:0","tags":["一致性","共识"],"title":"一致性(consistency)与共识(consensus)","uri":"/consistency_consensus/"},{"categories":["distributed system"],"content":"事务 事务是用户定义的一个数据库操作序列, 这些操作要么全做, 要么全不做, 是一个不可分割的工作单位. 事务的特性: 原子性 一致性 事务执行的结果必须是使数据库从一个一致性状态(正确状态)变到另一个一致性状态. 隔离性 持续性 其中, 当数据库只包含成功事务提交的结果时, 就说数据库处于一致性状态. 如果数据库系统运行中发生故障, 有些事务尚未完成就被迫中断, 这些未完成的事务对数据库所做的修改有一部分已写入物理数据库, 这时数据库就处于一种不正确的状态, 或者说不一致的状态. ","date":"2020-03-28","objectID":"/consistency_consensus/:3:0","tags":["一致性","共识"],"title":"一致性(consistency)与共识(consensus)","uri":"/consistency_consensus/"},{"categories":["distributed system"],"content":"分布式事务 上面说的都是单机数据库上的事务. 随着微服务架构的普及，一个大型业务系统往往由若干个子系统构成，这些子系统又拥有各自独立的数据库。往往一个业务流程需要由多个子系统共同完成，而且这些操作可能需要在一个事务中完成。以实现 宏观上的整个数据库系统的一致性(状态正确) . 在微服务系统中，这些业务场景是普遍存在的。此时，我们就需要在多个单机数据库之上通过某种手段，实现支持跨数据库的事务支持，这也就是大家常说的\"分布式事务”。 ","date":"2020-03-28","objectID":"/consistency_consensus/:4:0","tags":["一致性","共识"],"title":"一致性(consistency)与共识(consensus)","uri":"/consistency_consensus/"},{"categories":["distributed system"],"content":"数据(非数据库)的一致性 DB在各个时刻对共享某数据的事务应反映出一致的状态/数据。即任意时刻，多个事务来读同一个数据，多个事务看到的数据应该是一致的才对。数据一致性由事务隔离性来保障。 ","date":"2020-03-28","objectID":"/consistency_consensus/:5:0","tags":["一致性","共识"],"title":"一致性(consistency)与共识(consensus)","uri":"/consistency_consensus/"},{"categories":["distributed system"],"content":"分布式事务一致性问题与分布式系统共识问题的联系 分布式环境下的事务提交问题本质上是个共识问题.即, 一个业务流程中, 各子系统操作各自数据库后, 就是否提交事务, 各子系统需要达成一致. ","date":"2020-03-28","objectID":"/consistency_consensus/:6:0","tags":["一致性","共识"],"title":"一致性(consistency)与共识(consensus)","uri":"/consistency_consensus/"},{"categories":["distributed system"],"content":"References 1 2 ","date":"2020-03-28","objectID":"/consistency_consensus/:7:0","tags":["一致性","共识"],"title":"一致性(consistency)与共识(consensus)","uri":"/consistency_consensus/"},{"categories":["java"],"content":"前言 这几个概念其实都是设计模式你的概念, 其命名都跟真实场景密切相关, 理解了命名, 就了解了模式. ","date":"2020-03-26","objectID":"/filter_interceptor_listenter/:1:0","tags":["设计模式","filter","interceptor","listenter"],"title":"filter interceptor listenter","uri":"/filter_interceptor_listenter/"},{"categories":["java"],"content":"Filter 当你有一堆东西的时候，你只希望选择符合某些要求的东西。定义这些要求的工具，就是过滤器。 应用场景: 过滤掉非法url请求（不是login.do的地址请求，如果用户没有登陆都过滤掉）, 在传入servlet或者 struts的action前统一设置字符集， 去除掉一些非法字符（聊天室经常用到的，一些骂人的话）。。。 public class Test { public static void main(String[] args) { filter(); } public static void filter() { // 填充100个带有随机字母标签的球 List\u003cString\u003e array = new ArrayList\u003c\u003e(); Random r = new Random(); String[] balls = new String[]{\"A\", \"B\", \"C\"}; for (int i = 0; i \u003c 100; i++) { array.add(balls[r.nextInt(3)]); } System.out.println(array); // 只拿出B的来。不明白的自行学习Java 8 array = array.stream().filter(\"B\"::equals).collect(Collectors.toList()); System.out.println(array); } ","date":"2020-03-26","objectID":"/filter_interceptor_listenter/:2:0","tags":["设计模式","filter","interceptor","listenter"],"title":"filter interceptor listenter","uri":"/filter_interceptor_listenter/"},{"categories":["java"],"content":"Interceptor 在一个流程正在进行的时候，你希望干预它的进展，甚至终止它进行，这是拦截器做的事情。 应用场景: 进行权限验证，或者是来判断用户是否登陆，日志记录，或者限制时间点访问。 我自己用过拦截器，是用户每次登录时，都能记录一个登录时间。 （这点用拦截器明显合适，用过滤器明显不合适，因为没有过滤任何东西） interface Interceptor { void intercept(River river); } public class Test { public static void main(String[] args) { RiverController rc = new RiverController(); Interceptor inter = new SomeInterceptor(); // 这一步通常叫做控制反转或依赖注入，其实也没啥子 rc.setInterceptor(inter); rc.flow(new River()); } } class River { // 流量 int volume; // 总鱼数 int numFish; @Override public String toString() { return \"River{\" + \"volume=\" + volume + \", numFish=\" + numFish + '}'; } } class PowerGenerator { double generate(int volume) { // 假设每一百立方米水发一度电 return volume / 100d; } } class SomeInterceptor implements Interceptor { PowerGenerator generator = new PowerGenerator(); @Override public void intercept(River river) { // 消耗了1000立方米水来发电 int waterUsed = 1000; // 水量减少了1000。 river.volume -= waterUsed; // 发电 generator.generate(waterUsed); // 拦截所有的鱼 river.numFish = 0; System.out.println(\"passed interceptor\"); } } class RiverController { Interceptor interceptor; void setInterceptor(Interceptor interceptor) { this.interceptor = interceptor; } void flow(River river) { // 大坝前, 源头积累下来的水量和鱼 river.volume += 100000; river.numFish += 1000; System.out.println(river); // 经过了大坝 interceptor.intercept(river); System.out.println(river); // 下了点雨 river.volume += 1000; } } ","date":"2020-03-26","objectID":"/filter_interceptor_listenter/:3:0","tags":["设计模式","filter","interceptor","listenter"],"title":"filter interceptor listenter","uri":"/filter_interceptor_listenter/"},{"categories":["java"],"content":"Listener 当一个事件发生的时候，你希望获得这个事件发生的详细信息，而并不想干预这个事件本身的进程，这就要用到监听器。 应用场景: 当你要触发一个事件，但这件事既不是过滤，又不是拦截，那很可能就是监听！ 联想到Windows编程里的，单击鼠标、改变窗口尺寸、按下键盘上的一个键都会使Windows发送一个消息给应用程序。监听器的概念类似于这些。 // 监听器 interface BedListener { // 监听器在参数中收到了某个事件，而这个事件往往是只读的 // 监听器的方法名通常以\"on\"开头 void onBedSound(String sound); } public class Test { public static void main(String args[]) { Neighbor n = new Neighbor(); n.setListener(sound -\u003e generatePower()); n.doInterestingStuff(); } private static void generatePower() { // 根据当地法律法规，部分内容无法显示 } } // 邻居 class Neighbor { BedListener listener; // 依然是所谓控制反转 void setListener(BedListener listener) { this.listener = listener; } void doInterestingStuff() { // 根据当地法律法规，部分内容无法显示 // 将事件发送给监听器 listener.onBedSound(\"嘿咻\"); listener.onBedSound(\"oyeah\"); } } ","date":"2020-03-26","objectID":"/filter_interceptor_listenter/:4:0","tags":["设计模式","filter","interceptor","listenter"],"title":"filter interceptor listenter","uri":"/filter_interceptor_listenter/"},{"categories":["java"],"content":"Summary 约定： 过滤器：用于属性甄别，对象收集（不可改变过滤对象的属性和行为） 监听器：用于对象监听，行为记录（不可改变监听对象的属性和行为） 拦截器：用于对象拦截，行为干预（可以改变拦截对象的属性和行为） 能力逐渐增强：过滤器–\u003e监听器–\u003e拦截器 三者的用法完全不同，不存在什么交集。你也可以用拦截器做过滤器的工作，但是大材小用了，也不符合约定。 ","date":"2020-03-26","objectID":"/filter_interceptor_listenter/:5:0","tags":["设计模式","filter","interceptor","listenter"],"title":"filter interceptor listenter","uri":"/filter_interceptor_listenter/"},{"categories":["java"],"content":"References 请教一下关于过滤器，拦截器，监听器具体应用上的区别？ - Kangol LI的回答 - 知乎 请教一下关于过滤器，拦截器，监听器具体应用上的区别？ - 支浩宇的回答 - 知乎 请教一下关于过滤器，拦截器，监听器具体应用上的区别？ - 至尊七虾堡的回答 - 知乎 ","date":"2020-03-26","objectID":"/filter_interceptor_listenter/:6:0","tags":["设计模式","filter","interceptor","listenter"],"title":"filter interceptor listenter","uri":"/filter_interceptor_listenter/"},{"categories":["java"],"content":"java构造函数的注意事项","date":"2020-03-25","objectID":"/constructor/","tags":["java","构造函数","面试"],"title":"java构造函数","uri":"/constructor/"},{"categories":["java"],"content":"构造方法的作用 我们创建一个类的对象必须要调用构造方法，但构造方法的作用其实并不是为了创建对象，而是为了 “初始化对象的内部状态”, 就是为了给对象的各个属性赋初始值。 ","date":"2020-03-25","objectID":"/constructor/:1:0","tags":["java","构造函数","面试"],"title":"java构造函数","uri":"/constructor/"},{"categories":["java"],"content":"无参构造方法 当且仅当没有显式为类定义构造方法时,编译器会在编译的时候给这个类去自动添加一个无参数的构造方法; 并且其中会隐式的带有一个语句; ","date":"2020-03-25","objectID":"/constructor/:2:0","tags":["java","构造函数","面试"],"title":"java构造函数","uri":"/constructor/"},{"categories":["java"],"content":"构造方法重载 一个类可以定义多个构造方法, 完成不同的初始化工作, 所以可以重载. ","date":"2020-03-25","objectID":"/constructor/:3:0","tags":["java","构造函数","面试"],"title":"java构造函数","uri":"/constructor/"},{"categories":["java"],"content":"构造方法内调用构造方法 一个构造方法内可以调用另外一个构造方法, 但是使用this关键字来调用, 而不是类名. public class Test { public Test() { } public Test(int i) { //调用另一个构造方法,且必须在第一行 this(); i = 3; } } ","date":"2020-03-25","objectID":"/constructor/:4:0","tags":["java","构造函数","面试"],"title":"java构造函数","uri":"/constructor/"},{"categories":["java"],"content":"带继承关系的构造方法 在调用子类的构造方法时, jvm默认会先调用父类的构造方法. public class Test { public static void main(String[] args) { new Son(); } static class Father { public Father() { System.out.println(\"Father\"); } } static class Son extends Father{ public Son() { System.out.println(\"Son\"); } } } 输出如下: Father Son 即使程序员没有显式的这样编码, 编译器也会把调用父类构造方法的语句添加到子类的构造方法中. 所以编译过后, 应该时这样的. class Son extends Father { public Son() { super();//如果没有显式添加, 则编译器会添加, 且必须在第一行. System.out.println(\"Son\"); } } ","date":"2020-03-25","objectID":"/constructor/:5:0","tags":["java","构造函数","面试"],"title":"java构造函数","uri":"/constructor/"},{"categories":["java"],"content":"设计原因 无论程序员是否愿意，子类在它的构造方法当中必须要调用父类的构造方法, 这个设计与面向对象理念有关. 一般来讲，子类都会比父类拥有更多的属性, 且一部分属性是从父类那里继承过来的. 那么在创建一个子类对象之后, 可以调用父类的构造方法对继承来的属性进行初始化, 自有的属性可以在子类自身构造方法中初始化. public class Test { public static void main(String[] args) { new Son(\"tony\", 18); } static class Father { public String name; public Father(String name) { this.name = name; } } static class Son extends Father { public Integer age; public Son(String name, Integer age) { // 调用父类构造方法,初始化继承来的属性 super(name); // 再初始化子类自身的属性 this.age = age; } } } ","date":"2020-03-25","objectID":"/constructor/:5:1","tags":["java","构造函数","面试"],"title":"java构造函数","uri":"/constructor/"},{"categories":["java"],"content":"References 如何理解java的构造方法? - 穆哥学堂的回答 - 知乎 ","date":"2020-03-25","objectID":"/constructor/:6:0","tags":["java","构造函数","面试"],"title":"java构造函数","uri":"/constructor/"},{"categories":["java"],"content":"常见面试题","date":"2020-03-25","objectID":"/print-abc/","tags":["多线程","线程同步"],"title":"顺序多次打印ABC的几种实现方式","uri":"/print-abc/"},{"categories":["java"],"content":"基于Semaphore 一个先后关系需要一个信号量来进行控制，n个先后关系就需要n个信号量。(见操作系统书中例子)这个例子是其有向环图版本。 // 设计思想是把一个代表打印资格的信号量在多个线程之间按顺序传递. public class Test { public static void main(String[] args) throws InterruptedException { Semaphore a = new Semaphore(1); Semaphore b = new Semaphore(0); Semaphore c = new Semaphore(0); ExecutorService poolService = Executors.newFixedThreadPool(3); // 打印次数 Integer count = 10; poolService.execute(new Worker(a, b, \"A\", count)); poolService.execute(new Worker(b, c, \"B\", count)); poolService.execute(new Worker(c, a, \"C\", count)); Thread.sleep(1000); poolService.shutdown(); } public static class Worker implements Runnable { private Semaphore current; private Semaphore next; private String key; private Integer count; public Worker(Semaphore current, Semaphore next, String key, Integer count) { this.current = current; this.next = next; this.key = key; this.count = count; } @Override public void run() { for (int i = 0; i \u003c count; i++) { try { // 获取资源 current.acquire(); System.out.print(key); // 传递资源 next.release(); } catch (InterruptedException e) { e.printStackTrace(); } } } } } ","date":"2020-03-25","objectID":"/print-abc/:1:0","tags":["多线程","线程同步"],"title":"顺序多次打印ABC的几种实现方式","uri":"/print-abc/"},{"categories":["java"],"content":"基于Synchronized // 设计思想是, 用一个lock代表打印资格, 谁获取到谁可以打印; // 并且用一个state来控制打印顺序, 一个线程打印完后, 将state变为下一个状态, // 即,state在 a-\u003eb-\u003ec-\u003ea-\u003eb-\u003e...这样流转; // 这个思想跟semaphore差不多的 public class Test { private static volatile int currentState = 1; public static void main(String[] args) throws InterruptedException { ExecutorService poolSerivce = Executors.newFixedThreadPool(3); int count = 10; Object lock = new Object(); poolSerivce.execute(new Worker(\"A\", 1, 2, count, lock)); poolSerivce.execute(new Worker(\"B\", 2, 3, count, lock)); poolSerivce.execute(new Worker(\"C\", 3, 1, count, lock)); Thread.sleep(1000); poolSerivce.shutdown(); } public static class Worker implements Runnable { private String key; private int targetState; private int nextState; private int count; private Object lock; public Worker(String key, int targetState, int nextState, int count, Object lock) { this.key = key; this.targetState = targetState; this.nextState = nextState; this.count = count; this.lock = lock; } @Override public void run() { for (int i = 0; i \u003c count; i++) { synchronized (lock) { // 判断当前该谁打印 while (currentState != targetState) { try { lock.wait(); } catch (Exception e) { e.printStackTrace(); } } System.out.print(key); currentState = nextState; lock.notifyAll(); } } } } } ","date":"2020-03-25","objectID":"/print-abc/:2:0","tags":["多线程","线程同步"],"title":"顺序多次打印ABC的几种实现方式","uri":"/print-abc/"},{"categories":["java"],"content":"基于ReentrantLock 设计思想跟 synchronized 一样, 但是有多个等待队列, 提升了竞争效率. // 设计思想是, 用一个lock代表打印资格, 谁获取到谁可以打印; // 并且用一个state来控制打印顺序, 一个线程打印完后, 将state变为下一个状态, // 即,state在 a-\u003eb-\u003ec-\u003ea-\u003eb-\u003e...控制当前应打印字符的流转; public class Test { private static volatile Integer currentState = 1; private static ReentrantLock lock = new ReentrantLock(); // 一个condition对应一个等待队列, 一个lock可以绑定多个condition, 即支持多个等待队列. // 相比synchronized,有多个等待队列, 通知下一个队列时也有针对性, 即 竞争效率比较高 // 效率最高的应该还是semaphore private static Condition conditionA = lock.newCondition(); private static Condition conditionB = lock.newCondition(); private static Condition conditionC = lock.newCondition(); public static void main(String[] args) throws InterruptedException { ExecutorService poolSerivce = Executors.newFixedThreadPool(3); Integer count = 10; poolSerivce.execute(new Worker(\"A\", 1, 2, count, lock, conditionA, conditionB)); poolSerivce.execute(new Worker(\"B\", 2, 3, count, lock, conditionB, conditionC)); poolSerivce.execute(new Worker(\"C\", 3, 1, count, lock, conditionC, conditionA)); Thread.sleep(1000); poolSerivce.shutdown(); } public static class Worker implements Runnable { private String key; //本线程期待的state private int targetState; private int nextState; private Integer count; private Lock lock; private Condition current; private Condition next; public Worker(String key, int targetState, int nextState, Integer count, Lock lock, Condition current, Condition next) { this.key = key; this.targetState = targetState; this.nextState = nextState; this.count = count; this.lock = lock; this.current = current; this.next = next; } @Override public void run() { this.lock.lock(); try { for (int i = 0; i \u003c count; i++) { // 等待流转到目标状态 while (currentState != targetState) { // 放进当前的等待队列中 current.await(); } System.out.print(key); currentState = nextState; // 通知下一个等待队列 next.signal(); } } catch (Exception e) { e.printStackTrace(); } finally { this.lock.unlock(); } } } } ","date":"2020-03-25","objectID":"/print-abc/:3:0","tags":["多线程","线程同步"],"title":"顺序多次打印ABC的几种实现方式","uri":"/print-abc/"},{"categories":["java"],"content":"References Java多线程—顺序打印ABC打印10次的实现-三种实现 java - ReentrantLock和Condition实现生产者-消费者 ","date":"2020-03-25","objectID":"/print-abc/:4:0","tags":["多线程","线程同步"],"title":"顺序多次打印ABC的几种实现方式","uri":"/print-abc/"},{"categories":["spring"],"content":"Spring 新老配置方式对比","date":"2020-03-23","objectID":"/spring_old_new_config_compare/","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"IOC容器配置文件 配置文件是IOC容器的Bean定义来源. ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:1:0","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"xml形式 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003c!--bean定义--\u003e \u003c/beans\u003e xml形式下, 对注解的支持: \u003ccontext:annotation-config/\u003e ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:1:1","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"java形式 @Configuration 将一个类标识为JavaConfig形式的Spring Ioc容器的配置类. @Configuration public class SpringConfig{ //bean定义 } 然后, 使用配置文件初始化spring IOC 容器: public class MyApp { public static void main(String[] args) { // xml文件形式 ApplicationContext context = new ClassPathXmlApplicationContext(\"spring-config.xml\"); // java代码形式 ApplicationContext ctx = new AnnotationConfigApplicationContext(SpringConfig.class); MyBean myBean = (MyBean) context.getBean(\"myBean\"); } } ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:1:2","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"Bean定义 ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:2:0","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"xml形式 \u003cbean id=\"myBean\" class=\"com.company.myapp.MyBean\"\u003e ... \u003c/bean\u003e ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:2:1","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"java形式 @Bean 常与 @Configuration 搭档使用, 其将一个方法标识为Ioc容器中Bean的定义来源, 方法返回值将作为一个bean定义注册到Spring的IoC容器，方法名将默认成该bean定义的id. @Configuration public class SpringConfig{ @Bean public MyBean myBean(){ return new MyBean(); } } ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:2:2","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"依赖注入 表达bean与bean之间的依赖关系 ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:3:0","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"xml形式 \u003cbean id=\"myBean\" class=\"com.company.myapp.MyBean\"\u003e \u003cpropery name =\"dependencyService\" ref=\"myBean2\" /\u003e \u003c/bean\u003e \u003cbean id=\"myBean2\" class=\"com.company.myapp.MyBean2\"\u003e\u003c/bean\u003e ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:3:1","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"java形式 @Configuration public class SpringConfig{ @Bean public MyBean myBean(){ return new MyBean(myBean2()); } @Bean public MyBean2 myBean2(){ return new MyBean2(); } } ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:3:2","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"ComponentScan 自动扫描并加载指定路径下符合条件的组件（比如@Component和@Repository等）或者bean定义，最终将这些bean注册到IoC容器中。 可以通过basePackages等属性来细粒度的定制@ComponentScan自动扫描的范围，如果不指定，则默认Spring框架实现会从声明@ComponentScan所在类的package进行扫描. ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:4:0","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"xml形式 \u003ccontext:component-scan base-package=\"com.company.myapp`\"/\u003e ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:4:1","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"java形式 @ComponentScan(basePackages = \"com.company.myapp\") ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:4:2","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"bean属性值 ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:5:0","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"xml形式 \u003cbean class=\"Person\"\u003e \u003cproperty name =\"name\" value=\"i am name\"\u003e\u003c/property\u003e \u003c/bean\u003e ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:5:1","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"java形式 @Value就相当于传统 xml 配置文件中的 value 字段。 @Component public class Person { @Value(\"i am name\") private String name; } value 的取值可以是： 字面量 通过 ${key}方式从环境变量中获取值 通过 ${key}方式全局配置文件中获取值 #{SpEL} ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:5:2","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"References 这样讲 SpringBoot 自动配置原理，你应该能明白了吧 ","date":"2020-03-23","objectID":"/spring_old_new_config_compare/:6:0","tags":["spring boot","自动配置"],"title":"Spring 两种配置文件对比","uri":"/spring_old_new_config_compare/"},{"categories":["spring"],"content":"@ConfigurationProperties 【SpringBoot 提供】 我们需要取 N 个配置项，通过 @Value 的方式一个一个去取很麻烦。我们可以使用 @ConfigurationProperties. 被 @ConfigurationProperties 标识的类的所有属性和配置文件中相关的配置项进行绑定, 前提是被标示类具有setter方法。（默认从全局配置文件中获取配置值），绑定之后我们就可以通过这个类去访问全局配置文件中的属性值了。 如: 配置文件中有如下属性: person.name=kundy person.age=13 person.sex=male 这里 @ConfigurationProperties 有一个 prefix参数，主要是用来指定该配置项在配置文件中的前缀。 @Component @ConfigurationProperties(prefix = \"person\") public class Person { private String name; private Integer age; private String sex; // getter \u0026 setter... } ","date":"2020-03-23","objectID":"/spring_annotation/:1:0","tags":["常用注解"],"title":"spring 中几个常见注解","uri":"/spring_annotation/"},{"categories":["spring"],"content":"@EnableConfigurationProperties 形如 @ConfigurationProperties(prefix = “com.cxytiandi”), 单独使用 @ConfigurationProperties 注解，被注解类不会被注册到ioc容器中，也就无法通过被注解类获取到配置文件中的属性。 还需要使用其他注解将被注解类注册到容器中，如@Componet,@Configuration，@EnableConfigurationProperties(MyConfig.class)等 @ConfigurationProperties(prefix = \"com.cxytiandi\") @Configuration public class MyConfig { private String name; // getter \u0026 setter \u0026 constructor } ","date":"2020-03-23","objectID":"/spring_annotation/:2:0","tags":["常用注解"],"title":"spring 中几个常见注解","uri":"/spring_annotation/"},{"categories":["spring"],"content":"@Import 【Spring 提供】 @Import注解支持导入普通 java 类，并将其声明成一个bean。主要用于将多个分散的 java config 配置类融合成一个更大的 config 类 @Import 三种使用方式 直接导入普通的 Java 类。 配合自定义的 ImportSelector 使用。 配合 ImportBeanDefinitionRegistrar 使用。 ","date":"2020-03-23","objectID":"/spring_annotation/:3:0","tags":["常用注解"],"title":"spring 中几个常见注解","uri":"/spring_annotation/"},{"categories":["spring"],"content":"导入普通的 Java 类 创建一个普通的 Java 类。 public class Circle { public void sayHi() { System.out.println(\"Circle sayHi()\"); } } 创建一个配置类，里面没有显式声明任何的 Bean，然后将刚才创建的 Circle 导入。 @Import({Circle.class}) @Configuration public class MainConfig { } 测试 public static void main(String[] args) { ApplicationContext context = new AnnotationConfigApplicationContext(MainConfig.class); Circle circle = context.getBean(Circle.class); circle.sayHi(); } 运行结果 Circle sayHi() 可以看到我们顺利的从 IOC 容器中获取到了 Circle 对象，证明我们在配置类中导入的 Circle 类，确实被声明为了一个 Bean。 ","date":"2020-03-23","objectID":"/spring_annotation/:3:1","tags":["常用注解"],"title":"spring 中几个常见注解","uri":"/spring_annotation/"},{"categories":["spring"],"content":"配合自定义的 ImportSelector 使用 ImportSelector是一个接口，该接口中只有一个 selectImports 方法，用于返回完整类名的数组。所以利用该特性我们可以给容器动态导入 N 个Bean。 创建普通 Java 类 Triangle。 public class Triangle { public void sayHi(){ System.out.println(\"Triangle sayHi()\"); } } 创建 ImportSelector 实现类，selectImports 返回 Triangle 的全类名。 public class MyImportSelector implements ImportSelector { @Override public String[] selectImports(AnnotationMetadata annotationMetadata) { return new String[]{\"com.company.Triangle\"}; } } 创建配置类，在原来的基础上还导入了 MyImportSelector。 @Import({Circle.class,MyImportSelector.class}) @Configuration public class MainConfigTwo { } 创建测试类 public static void main(String[] args) { ApplicationContext context = new AnnotationConfigApplicationContext(MainConfigTwo.class); Circle circle = context.getBean(Circle.class); Triangle triangle = context.getBean(Triangle.class); circle.sayHi(); triangle.sayHi(); } ","date":"2020-03-23","objectID":"/spring_annotation/:3:2","tags":["常用注解"],"title":"spring 中几个常见注解","uri":"/spring_annotation/"},{"categories":["spring"],"content":"配合 ImportBeanDefinitionRegistrar 使用 ImportBeanDefinitionRegistrar也是一个接口，它可以手动注册bean到容器中，从而我们可以对类进行个性化的定制。(需要搭配 @Import 与 @Configuration 一起使用。） 创建普通 Java 类 Rectangle。 public class Rectangle { public void sayHi() { System.out.println(\"Rectangle sayHi()\"); } } 创建 ImportBeanDefinitionRegistrar 实现类，实现方法直接手动注册一个名叫 rectangle 的 Bean 到 IOC 容器中 public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar { @Override public void registerBeanDefinitions(AnnotationMetadata annotationMetadata, BeanDefinitionRegistry beanDefinitionRegistry) { RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Rectangle.class); // 注册一个名字叫做 rectangle 的 bean beanDefinitionRegistry.registerBeanDefinition(\"rectangle\", rootBeanDefinition); } } 创建配置类，导入 MyImportBeanDefinitionRegistrar 类。 @Import({Circle.class, MyImportSelector.class, MyImportBeanDefinitionRegistrar.class}) @Configuration public class MainConfigThree { } 创建测试类。 public static void main(String[] args) { ApplicationContext context = new AnnotationConfigApplicationContext(MainConfigThree.class); Circle circle = context.getBean(Circle.class); Triangle triangle = context.getBean(Triangle.class); Rectangle rectangle = context.getBean(Rectangle.class); circle.sayHi(); triangle.sayHi(); rectangle.sayHi(); } } 运行结果 Circle sayHi() Triangle sayHi() Rectangle sayHi() 嗯对，Rectangle 对象也被注册进来了。 ","date":"2020-03-23","objectID":"/spring_annotation/:3:3","tags":["常用注解"],"title":"spring 中几个常见注解","uri":"/spring_annotation/"},{"categories":["spring"],"content":"@Conditional 【Spring提供】 @Conditional 注解可以实现只有在特定条件满足时才启用一些配置。 创建普通 Java 类 ConditionBean，该类主要用来验证 Bean 是否成功加载 public class ConditionBean { public void sayHi() { System.out.println(\"ConditionBean sayHi()\"); } } 创建 Condition 实现类，@Conditional 注解只有一个 Condition 类型的参数，Condition 是一个接口，该接口只有一个返回布尔值的 matches() 方法，该方法返回 true 则条件成立，配置类生效。反之，则不生效。在该例子中我们直接返回 true。 public class MyCondition implements Condition { @Override public boolean matches(ConditionContext conditionContext, AnnotatedTypeMetadata annotatedTypeMetadata) { return true; } } 创建配置类，可以看到该配置的 @Conditional 传了我们刚才创建的 Condition 实现类进去，用作条件判断。 @Configuration @Conditional(MyCondition.class) public class ConditionConfig { @Bean public ConditionBean conditionBean(){ return new ConditionBean(); } } 编写测试方法 public static void main(String[] args) { ApplicationContext context = new AnnotationConfigApplicationContext(ConditionConfig.class); ConditionBean conditionBean = context.getBean(ConditionBean.class); conditionBean.sayHi(); } 结果分析 因为 Condition 的 matches 方法直接返回了 true，配置类会生效，我们可以把 matches 改成返回 false，则配置类就不会生效了。 ","date":"2020-03-23","objectID":"/spring_annotation/:4:0","tags":["常用注解"],"title":"spring 中几个常见注解","uri":"/spring_annotation/"},{"categories":["spring"],"content":"@Conditional 扩展注解 除了自定义 Condition，Spring 还为我们扩展了一些常用的 Condition。 @ConditionalOnBean : 容器中存在指定 Bean，则生效 @ConditionalOnMissingBean : 容器中不存在指定 Bean，则生效 @ConditionalOnClass : classpath中有指定的类，则生效 @ConditionalOnMissingClass : classpath中没有指定的类，则生效 @ConditionalOnProperty : 系统中指定的属性有指定的值, 则生效 @ConditionalOnWebApplication : 当前是web环境，则生效 ","date":"2020-03-23","objectID":"/spring_annotation/:5:0","tags":["常用注解"],"title":"spring 中几个常见注解","uri":"/spring_annotation/"},{"categories":["spring"],"content":"@Primary 和 @Qualifier https://blog.csdn.net/sinat_32023305/article/details/90718687 当一个接口有2个不同实现时,使用@Autowired注解时会报org.springframework.beans.factory.NoUniqueBeanDefinitionException异常信息 @Qualifier 选择一个对象的名称,通常比较常用 @Primary 可以理解为默认优先选择,不可以同时设置多个 ","date":"2020-03-23","objectID":"/spring_annotation/:6:0","tags":["常用注解"],"title":"spring 中几个常见注解","uri":"/spring_annotation/"},{"categories":["spring"],"content":"@Resource 和 @Autowired 和 @Inject ","date":"2020-03-23","objectID":"/spring_annotation/:7:0","tags":["常用注解"],"title":"spring 中几个常见注解","uri":"/spring_annotation/"},{"categories":["spring"],"content":"@Resource @Resource注释是JSR-250注释集合的一部分，位于 javax.annotation.Resource，并打包在Jakarta EE中。该注释有以下执行路径，按优先级列出: Match by Name Match by Type Match by Qualifier 这些执行路径适用于setter和字段注入。 ","date":"2020-03-23","objectID":"/spring_annotation/:7:1","tags":["常用注解"],"title":"spring 中几个常见注解","uri":"/spring_annotation/"},{"categories":["spring"],"content":"@Autowired @Autowired注解的行为与@Inject注解相似。唯一的区别是@Autowired注解是Spring框架的一部分。 此注释与@Inject注释有相同的执行路径，按优先级顺序列出: Match by Type Match by Qualifier Match by Name 这些执行路径适用于setter和字段注入。 ","date":"2020-03-23","objectID":"/spring_annotation/:7:2","tags":["常用注解"],"title":"spring 中几个常见注解","uri":"/spring_annotation/"},{"categories":["spring"],"content":"@Inject @Inject注释属于JSR-330注释集合。该注释有以下执行路径，按优先级列出: Match by Type Match by Qualifier Match by Name 这些执行路径适用于setter和字段注入。为了使用@Inject注释， 必须在Gradle或Maven中添加 javax.inject 相关依赖。 具体使用场景 ","date":"2020-03-23","objectID":"/spring_annotation/:7:3","tags":["常用注解"],"title":"spring 中几个常见注解","uri":"/spring_annotation/"},{"categories":["spring"],"content":"References 这样讲 SpringBoot 自动配置原理，你应该能明白了吧 ","date":"2020-03-23","objectID":"/spring_annotation/:8:0","tags":["常用注解"],"title":"spring 中几个常见注解","uri":"/spring_annotation/"},{"categories":["spring"],"content":"Spring boot启动过程分析","date":"2020-03-22","objectID":"/spring_boot_start_process/","tags":["spring boot","启动流程"],"title":"Spring Boot启动流程","uri":"/spring_boot_start_process/"},{"categories":["spring"],"content":"SpringApplication启动流程 以spring boot 2.2.5.RELEASE版本为例, 详细解析启动过程: 启动类, 即主配置类: @SpringBootApplication public class MyApplication { public static void main(String[] args) { SpringApplication.run(MyApplication.class, args); } } // 1.创建一个SpringApplication对象 // 2.调用了SpringApplication对象的run() public static ConfigurableApplicationContext run(Class\u003c?\u003e[] primarySources, String[] args) { return new SpringApplication(primarySources).run(args); } ","date":"2020-03-22","objectID":"/spring_boot_start_process/:1:0","tags":["spring boot","启动流程"],"title":"Spring Boot启动流程","uri":"/spring_boot_start_process/"},{"categories":["spring"],"content":"创建SpringApplication对象 public SpringApplication(ResourceLoader resourceLoader, Class\u003c?\u003e... primarySources) { this.resourceLoader = resourceLoader; Assert.notNull(primarySources, \"PrimarySources must not be null\"); // 1.保存主配置类, 它是主要的bean来源, 也就是@SpringBootApplication注解的类 this.primarySources = new LinkedHashSet\u003c\u003e(Arrays.asList(primarySources)); // 2.推断web应用类型 this.webApplicationType = WebApplicationType.deduceFromClasspath(); // 3.从classpath下找到META-INF/spring.factories配置的所有ApplicationContextInitializer；实例化并配置好它们 setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); // 4.从classpath下找到ETA-INF/spring.factories配置的所有ApplicationListener;实例化并配置好它们 setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); // 5.从堆栈信息中推断有main方法的主配置类, 也就是@SpringBootApplication注解的类 this.mainApplicationClass = deduceMainApplicationClass(); } ","date":"2020-03-22","objectID":"/spring_boot_start_process/:1:1","tags":["spring boot","启动流程"],"title":"Spring Boot启动流程","uri":"/spring_boot_start_process/"},{"categories":["spring"],"content":"调用SpringApplication对象的run()方法 public ConfigurableApplicationContext run(String... args) { StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection\u003cSpringBootExceptionReporter\u003e exceptionReporters = new ArrayList\u003c\u003e(); configureHeadlessProperty(); // 1.从类路径下META-INF/spring.factories获取SpringApplicationRunListeners SpringApplicationRunListeners listeners = getRunListeners(args); // 2.回调所有的获取SpringApplicationRunListener.starting()方法 listeners.starting(); try { // 3.封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); // 4.准备环境，调用prepareEnvironment方法 //方法中创建环境完成会后回调SpringApplicationRunListener#environmentPrepared()；表示环境准备完成 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); // 5.打印Banner图（就是启动时的标识图）。 Banner printedBanner = printBanner(environment); // 6.创建ApplicationContext,决定创建web的ioc还是普通的ioc context = createApplicationContext(); // 7.异常分析报告 exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] { ConfigurableApplicationContext.class }, context); // 8.准备上下文环境，将environment保存到ioc中 // applyInitializers()：回调之前保存的所有的ApplicationContextInitializer的initialize方法 // listeners.contextPrepared(context):回调所有的SpringApplicationRunListener的contextPrepared()， // listeners.contextLoaded(context): prepareContext()最后会回调所有的SpringApplicationRunListener的contextLoaded（） prepareContext(context, environment, listeners, applicationArguments, printedBanner); // 9.刷新容器,ioc容器初始化（如果是web应用还会创建嵌入式的Tomcat） // 扫描，创建，加载所有组件的地方,（配置类，组件，自动配置） refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); } // 10.所有的SpringApplicationRunListener回调started方法 listeners.started(context); // 11.从ioc容器中获取所有的ApplicationRunner和CommandLineRunner进行回调， // ApplicationRunner先回调，CommandLineRunner再回调 callRunners(context, applicationArguments); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); } try { // 12.所有的SpringApplicationRunListener回调running方法 listeners.running(context); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); } // 13.整个SpringBoot应用启动完成以后返回启动的ioc容器 return context; } ","date":"2020-03-22","objectID":"/spring_boot_start_process/:1:2","tags":["spring boot","启动流程"],"title":"Spring Boot启动流程","uri":"/spring_boot_start_process/"},{"categories":["spring"],"content":"流程图 ","date":"2020-03-22","objectID":"/spring_boot_start_process/:1:3","tags":["spring boot","启动流程"],"title":"Spring Boot启动流程","uri":"/spring_boot_start_process/"},{"categories":["spring"],"content":"自动配置原理 @EnableAutoConfiguration自动配置的魔法骑士就变成了：从classpath中搜寻所有的META-INF/spring.factories配置文件，并将其中org.springframework.boot.autoconfigure.EnableutoConfiguration对应的配置项通过反射（Java Refletion）实例化为对应的标注了@Configuration的JavaConfig形式的IoC容器配置类，然后汇总为一个并加载到IoC容器。 然后各种自动配置类依次执行,利用@condition注解,根据容器中的bean,classpath下的class, 配置文件中的属性,来综合决定给功能要不要配置, 如何配置. 我们知道, 自动配置的目的是配置好相应的bean放到容器中, 供我们使用. @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @AutoConfigurationPackage @Import(AutoConfigurationImportSelector.class) public @interface EnableAutoConfiguration { String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\"; Class\u003c?\u003e[] exclude() default {}; String[] excludeName() default {}; } ","date":"2020-03-22","objectID":"/spring_boot_start_process/:2:0","tags":["spring boot","启动流程"],"title":"Spring Boot启动流程","uri":"/spring_boot_start_process/"},{"categories":["spring"],"content":"Reference 详解SpringBoot——启动原理及自定义starter SpringBoot 启动原理解析 Spring源码-refresh方法 ","date":"2020-03-22","objectID":"/spring_boot_start_process/:3:0","tags":["spring boot","启动流程"],"title":"Spring Boot启动流程","uri":"/spring_boot_start_process/"},{"categories":["database"],"content":"https://www.jianshu.com/p/5a2dae144238 ","date":"2020-03-20","objectID":"/sql/:0:0","tags":["常用sql"],"title":"常用sql","uri":"/sql/"},{"categories":["database"],"content":"mysql 行转列 select USER_NAME, max(case COURSE when '语文' then SCORE else 0 end) \"语文\", max(case COURSE when '数学' then SCORE else 0 end) '数学', max(case COURSE when '英语' then SCORE else 0 end) '英语', sum(SCORE) '总分', avg(SCORE) '平均分' from student group by USER_NAME; ","date":"2020-03-20","objectID":"/sql/:1:0","tags":["常用sql"],"title":"常用sql","uri":"/sql/"},{"categories":["database"],"content":"mysql 列转行 select USER_NAME, '语文' course, CN_SCORE score from grade union select USER_NAME, '数学' course, MATH_SCORE score from grade union select USER_NAME, '英语' course, EN_SCORE score from grade order by USER_NAME, score ","date":"2020-03-20","objectID":"/sql/:2:0","tags":["常用sql"],"title":"常用sql","uri":"/sql/"},{"categories":["Linux"],"content":"命令行用法收集","date":"2020-03-19","objectID":"/terminal/","tags":["powershell","shell","代理"],"title":"命令行技巧","uri":"/terminal/"},{"categories":["Linux"],"content":"powershell设置代理 $env:HTTPS_PROXY=\"http://127.0.0.1:1080\" $env:HTTP_PROXY=\"http://127.0.0.1:1080\" ","date":"2020-03-19","objectID":"/terminal/:1:0","tags":["powershell","shell","代理"],"title":"命令行技巧","uri":"/terminal/"},{"categories":["Linux"],"content":"shell设置代理 http_proxy = http://username:password@proxy_ip:port/ https_proxy = http://username:password@proxy_ip:port/ ftp_proxy = http://username:password@proxy_ip:port/ export http_proxy export https_proxy export ftp_proxy ","date":"2020-03-19","objectID":"/terminal/:2:0","tags":["powershell","shell","代理"],"title":"命令行技巧","uri":"/terminal/"},{"categories":["Linux"],"content":"重命名 # 重命名文件 mv old-file-name new-file-name # 重命名文件夹 mv oldfolder newfolder ","date":"2020-03-19","objectID":"/terminal/:3:0","tags":["powershell","shell","代理"],"title":"命令行技巧","uri":"/terminal/"},{"categories":["Linux"],"content":"重命名文件夹 ","date":"2020-03-19","objectID":"/terminal/:4:0","tags":["powershell","shell","代理"],"title":"命令行技巧","uri":"/terminal/"},{"categories":["development kit"],"content":"生成ssh-key ssh-keygen -t rsa -b 4096 -C \"这里输入密钥的注释\" # 留空按三下回车 或 输入密码 # 查看公钥 cat ~/.ssh/id_rsa.pub 将公钥添加到 github/gitee/gitlab 之类的平台后，使用ssh协议传输可以不输密码 ","date":"2020-03-19","objectID":"/git/:1:0","tags":["Git","常用命令"],"title":"Git常用命令","uri":"/git/"},{"categories":["development kit"],"content":"本地git仓库切换 ssh/http 协议 参考链接 # 查看当前remote git remote -v # 切换到http： git remote set-url https://github.com/username/repository.git # 切换到ssh： git remote set-url origin git@github.com:username/repository.git ","date":"2020-03-19","objectID":"/git/:2:0","tags":["Git","常用命令"],"title":"Git常用命令","uri":"/git/"},{"categories":["development kit"],"content":"添加 \\ 删除子模块 子模块与父模块使用不同的远程仓库，互不影响,以下命令均在父模块根目录下操作 # 添加 git submodule add -b master https://github.com/username/reponame.git dirname # 或 git submodule add -b master git@github.com:username/reponame.git dirname # 移除 git rm submodule-name ","date":"2020-03-19","objectID":"/git/:3:0","tags":["Git","常用命令"],"title":"Git常用命令","uri":"/git/"},{"categories":["development kit"],"content":"克隆含有子模块的仓库 以下命令均在父模块根目录下操作 克隆含有子模块的项目, 此时子模块目录是空的 git clone https://github.com/chaconinc/MainProject 初始化子模块目录为git管理 git submodule init 拉取子模块文件 git submodule update ","date":"2020-03-19","objectID":"/git/:4:0","tags":["Git","常用命令"],"title":"Git常用命令","uri":"/git/"},{"categories":["development kit"],"content":"忽略已跟踪文件 有时候我们添加.gitignore文件之前已经提交过了文件。.gitignore只能忽略那些原来没有被track的文件（自添加以后，从未 add 及 commit 过的文件），如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。 # 删除追踪状态 git rm -r --cached . # 把要忽略的文件添加到.gitignore文件后再执行 git add . git commit -m \"fixed untracked files\" 在Linux上你可以这样: git rm -r --cached . \u0026\u0026 git add . \u0026\u0026 git commit -m \"fixed untracked files\" ","date":"2020-03-19","objectID":"/git/:5:0","tags":["Git","常用命令"],"title":"Git常用命令","uri":"/git/"},{"categories":["development kit"],"content":"回滚代码到某个commit # 回退命令： git reset --hard HEAD^ 回退到上个版本 git reset --hard HEAD~3 回退到前3次提交之前，以此类推，回退到n次提交之前 git reset --hard commit_id 退到/进到 指定commit的sha码 # 强推到远程： git push origin HEAD --force ","date":"2020-03-19","objectID":"/git/:6:0","tags":["Git","常用命令"],"title":"Git常用命令","uri":"/git/"},{"categories":["development kit"],"content":"撤销某次提交 我在Git中提交了错误的文件。我该如何撤销那一次commit呢？ git commit -m \"Something terribly misguided\" git reset HEAD~ # \u003c\u003c edit files as necessary \u003e\u003e git add . git commit -c ORIG_HEAD ","date":"2020-03-19","objectID":"/git/:7:0","tags":["Git","常用命令"],"title":"Git常用命令","uri":"/git/"},{"categories":["development kit"],"content":"从暂存区 移除/撤回 文件 把文件从暂存区域撤回，但仍然希望保留在当前工作目录中 git rm --cached README ","date":"2020-03-19","objectID":"/git/:8:0","tags":["Git","常用命令"],"title":"Git常用命令","uri":"/git/"},{"categories":["development kit"],"content":"清除缓存的用户名和密码 # 缓存输入的用户名和密码 git config --global credential.helper wincred # 清除缓存在git中的用户名和密码 git credential-manager uninstall ","date":"2020-03-19","objectID":"/git/:9:0","tags":["Git","常用命令"],"title":"Git常用命令","uri":"/git/"},{"categories":["development kit"],"content":"仓库fork自别人, 如何在本地合并原作者的更新 # 1、先克隆项目到本地： Git clone https://github.com/iakuf/mojo cd mojo # 2、添加原作者项目的 remote 地址， 然后将代码 fetch 过来 git remote add sri https://github.com/kraih/mojo git fetch sri 'sri'相当于一个别名 # 查看本地项目目录： git remote -v # 3、合并 git checkout master git merge sri/master # 如果有冲突的话，需要丢掉本地分支： git reset –hard sri/master # 4、这时你的当前本地的项目变成和原作者的主项目一样了，可以把它提交到你的GitHub库 git commit -am '更新到原作者的主分支' git push origin git push -u origin master -f # –强制提交 ","date":"2020-03-19","objectID":"/git/:10:0","tags":["Git","常用命令"],"title":"Git常用命令","uri":"/git/"},{"categories":["development kit"],"content":"github 上的项目fork自别人, 如何合并原作者的更新 https://blog.csdn.net/qq1332479771/article/details/56087333 ","date":"2020-03-19","objectID":"/git/:11:0","tags":["Git","常用命令"],"title":"Git常用命令","uri":"/git/"},{"categories":["development kit"],"content":"本地分支关联远程分支 关联前本地仓库中要有远程仓库信息, 没有的要添加: git remote remove origin git remote add origin xxx.git 远程库的某分支关联到本地的某分支 # 常规关联,不指定本地分支就关联到当前所在分支 git branch --set-upstream-to=origin/\u003cbranch\u003e dev # 推送时关联 git push -u origin master ","date":"2020-03-19","objectID":"/git/:12:0","tags":["Git","常用命令"],"title":"Git常用命令","uri":"/git/"},{"categories":["development kit"],"content":"配置username和email # 全局配置 git config --global user.name \"唐忠维\" git config --global user.email yangzhaoyunfei@qq.com # 系统配置 git config --system xxx # 单个仓库配置 git config --local user.name \"唐忠维\" git config --local user.email yangzhaoyunfei@qq.com ","date":"2020-03-19","objectID":"/git/:13:0","tags":["Git","常用命令"],"title":"Git常用命令","uri":"/git/"},{"categories":["development kit"],"content":"创建仓库 mkdir aaaa cd aaaa git init touch README.md git add README.md git commit -m \"first commit\" git remote add origin https://gitee.com/yangzhaoyunfei/aaaa.git git push -u origin master cd existing_git_repo git remote add origin https://gitee.com/yangzhaoyunfei/aaaa.git git push -u origin master ","date":"2020-03-19","objectID":"/git/:14:0","tags":["Git","常用命令"],"title":"Git常用命令","uri":"/git/"},{"categories":["big data"],"content":"在裸机上自己部署一个Hadoop集群","date":"2020-03-18","objectID":"/cdh_copy/","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"为贴近真实环境,本文档假设以下条件: 1.集群中各机器无法连接外网,只能通过内网向集群发送文件 2.集群内各机器间网络互通 3.操作者拥有集群内各机器的root权限 ","date":"2020-03-18","objectID":"/cdh_copy/:0:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"前情概要 cloudera cdh分为cm(管理组件),cdh(hadoop组件)两大基础部分,当然还有,Navigator,impala等组件. cm安装方式: rpm ,存储库方式: 在线repo/内部(http)repo/本地rpm cdh安装方式: rpm/parcel ,存储库方式: 在线repo/内部(http)repo jdk安装方式: rpm/exec ,存储库: cloudera在线repo/cloudera内部repo/oracle tarball ","date":"2020-03-18","objectID":"/cdh_copy/:1:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"系统要求 jdk(这一步放到了脚本中) 从上面配置好的apache上下载,集群每个主机必须安装受支持的统一版本,Cloudera强烈建议安装在/usr/java/jdk-version目录下,这样可以自动检测到它 系统环境准备 ","date":"2020-03-18","objectID":"/cdh_copy/:2:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"centos local yum repo 准备 ","date":"2020-03-18","objectID":"/cdh_copy/:3:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"利用iso制作本地yum源, http制作yum源镜像服务器 1.挂载iso,并复制文件供http挂载(vm虚拟机上该方案有可能因inode不足而失败,提供备选方案) # 复制到大量文件到某一目录下可能出现inode节点数不足或空间不足的现象,需要预先处理 mkdir -p /data/iso mount -o loop -t iso9660 /home/yangzhaoyunfei/CentOS-7-x86_64-Everything-1804.iso /data/iso mkdir -p /data/centos7 cp -rf /data/iso/* /data/centos7 umount /data/iso/ # vw虚拟机上使用如下脚本 mkdir -p /data/iso mount /dev/cdrom /data/iso mkdir -p /data/centos7 cp -rf /data/iso/* /data/centos7 umount /data/iso/ 2.制作并只启用本地yum源(因为无法连接外网,所以必须使用本地源) cd /etc/yum.repos.d/ ll # 备份原repo文件 for file in `ls` ;do sudo mv $file $file\"bak\";done ll cat\u003e/etc/yum.repos.d/local.repo\u003c\u003cEOF [local] name=local baseurl=file:///data/centos7 enabled=1 gpgcheck=0 EOF #验证 yum clean all yum makecache ","date":"2020-03-18","objectID":"/cdh_copy/:3:1","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"centos http yum repo 准备 ","date":"2020-03-18","objectID":"/cdh_copy/:4:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"安装web服务器 前置要求: local repo # 禁用防火墙 systemctl stop firewalld.service systemctl disable firewalld.service # 禁用selinux sed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config reboot yum install -y httpd systemctl enable httpd systemctl start httpd # 软链接挂载 cd /var/www/html \u0026\u0026 ll ln -s /data/centos7/ /var/www/html/centos7 \u0026\u0026 ll 访问浏览器http_yum测试 # 如果无法访问,检查firewall,检查selinux,正确配置后重启 # service httpd restart ","date":"2020-03-18","objectID":"/cdh_copy/:4:1","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"为其他机器配置 http yum源 上一步制作的local.repo可以启用,统一采用http.repo mv /etc/yum.repos.d/local.repo /etc/yum.repos.d/local.repobak \u0026\u0026 ll /etc/yum.repos.d/ cat\u003e/etc/yum.repos.d/http.repo\u003c\u003cEOF [http] name=http baseurl=http://192.168.181.128/centos7 enabled=1 gpgcheck=0 EOF ll /etc/yum.repos.d/ yum clean all yum makecache 将下载的jdk也挂载到http中 mkdir -p /data/softwares/ # 将jdk,jdbc驱动等放到这个文件夹中 ln -s /data/softwares/ /var/www/html/softwares 访问浏览器http_softwares验证 ","date":"2020-03-18","objectID":"/cdh_copy/:4:2","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"cm/cdh(rpm) repo库 1.下载Tarball Cloudera Manager 5: https://archive.cloudera.com/cm5/repo-as-tarball/ 2.解压缩tarball，将文件移动到Web服务器目录，然后修改文件权限 tar xvfz cm5.15.1-centos7.tar.gz sudo mv cm /var/www/html sudo chmod -R ugo+rX /var/www/html/cm 访问cm_rpms验证是否正确设置 3.创建repo文件 cat\u003e/etc/yum.repos.d/cloudera-repo.repo\u003c\u003cEOF [cloudera-repo] name=cloudera-repo baseurl=http://192.168.181.128/cm/5 enabled=1 gpgcheck=0 EOF yum clean all yum makecache ","date":"2020-03-18","objectID":"/cdh_copy/:5:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"cdh(parcel)库 1.先从cloudera官网下载对应系统平台的 ***parcel and manifest.json and sha1 文件 CDH 5: Impala, Kudu, Spark 1, and Search are included in the CDH parcel. CDH - https://archive.cloudera.com/cdh5/parcels/ Accumulo - - https://archive.cloudera.com/accumulo-c5/parcels/ GPL Extras - https://archive.cloudera.com/gplextras5/parcels/ Cloudera Distribution of Apache Spark 2 for CDH 5: The exact parcel name is dependent on the OS. You can find all the parcels at https://archive.cloudera.com/spark2/parcels/. Sqoop Connectors: https://archive.cloudera.com/sqoop-connectors/parcels/ 1.移动.parcel, .sha1 and manifest.json文件到web server目录,然后修改权限 sudo mkdir -p /var/www/html/cloudera-parcels/cdh5/5.15.1/ sudo mv *.parcel* /var/www/html/cloudera-parcels/cdh5/5.15.1/ sudo mv manifest.json /var/www/html/cloudera-parcels/cdh5/5.15.1/ sudo chmod -R ugo+rX /var/www/html/cloudera-parcels/cdh5/5.15.1/ 5.15.1 替换为你的版本 (如 5.14.0) 访问cdh_parcels ","date":"2020-03-18","objectID":"/cdh_copy/:6:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"设置NTP(集群时间同步) #服务端(master) yum install -y chrony vi /etc/chrony.conf # 注释以下四个外网时间同步服务器,并添加master机器为时间同步服务器 # Use public servers from the pool.ntp.org project. # Please consider joining the pool (http://www.pool.ntp.org/join.html). #server 0.centos.pool.ntp.org iburst #server 1.centos.pool.ntp.org iburst #server 2.centos.pool.ntp.org iburst #server 3.centos.pool.ntp.org iburst server 192.168.181.128 iburst # 重启服务 systemctl restart chronyd chronyc -a makestep chronyc sources -v ","date":"2020-03-18","objectID":"/cdh_copy/:7:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"优化内核参数 ","date":"2020-03-18","objectID":"/cdh_copy/:8:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"关闭ipv6 cat»/etc/sysctl.conf«EOF ####################### 自行添加 ########################### #关闭ipv6 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 ####################### 自行添加 ########################### EOF ## 安装expect, 执行脚本(仅master) ```bash # 上传脚本及hostname文件 yum -y install expect chmod +x InstallCDH_SSH.sh ./InstallCDH_SSH.sh root root hostsname.txt ","date":"2020-03-18","objectID":"/cdh_copy/:8:1","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"jdk准备(脚本中已有,spark2依赖jdk8,所以自定义安装8) ","date":"2020-03-18","objectID":"/cdh_copy/:9:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"cm/cms安装 前置要求: 配置cm,cdh的repo(rpm)库 sudo yum install -y cloudera-manager-daemons cloudera-manager-server ","date":"2020-03-18","objectID":"/cdh_copy/:10:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"database,connector 安装,相关数据库准备 ","date":"2020-03-18","objectID":"/cdh_copy/:11:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"安装和配置数据库 为Cloudera Software安装和配置MariaDB cloudera建议的配置文件在centos7.5自带5.x mariadb下无法启动,可能需要只适合10.x版本 # 安装,开机自启,启动 sudo yum install -y mariadb-server sudo systemctl enable mariadb sudo systemctl start mariadb # 停止数据库服务,mariadb配置文件`/etc/my.cnf`,修改内容为 \u003e这个配置文件不适用与centos7自带5.x mariadb sudo systemctl stop mariadb mv /etc/my.cnf /etc/my.cnfbak ############################################# 这个配置文件不适用与5.x mariadb cat\u003e/etc/my.cnf\u003c\u003cEOF [mysqld] datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock transaction-isolation = READ-COMMITTED # Disabling symbolic-links is recommended to prevent assorted security risks; # to do so, uncomment this line: symbolic-links = 0 # Settings user and group are ignored when systemd is used. # If you need to run mysqld under a different user or group, # customize your systemd unit file for mariadb according to the # instructions in http://fedoraproject.org/wiki/Systemd key_buffer = 16M key_buffer_size = 32M max_allowed_packet = 32M thread_stack = 256K thread_cache_size = 64 query_cache_limit = 8M query_cache_size = 64M query_cache_type = 1 max_connections = 550 #expire_logs_days = 10 #max_binlog_size = 100M #log_bin should be on a disk with enough free space. #Replace '/var/lib/mysql/mysql_binary_log' with an appropriate path for your #system and chown the specified folder to the mysql user. log_bin=/var/lib/mysql/mysql_binary_log #In later versions of MariaDB, if you enable the binary log and do not set #a server_id, MariaDB will not start. The server_id must be unique within #the replicating group. server_id=1 binlog_format = mixed read_buffer_size = 2M read_rnd_buffer_size = 16M sort_buffer_size = 8M join_buffer_size = 8M # InnoDB settings innodb_file_per_table = 1 innodb_flush_log_at_trx_commit = 2 innodb_log_buffer_size = 64M innodb_buffer_pool_size = 4G innodb_thread_concurrency = 8 innodb_flush_method = O_DIRECT innodb_log_file_size = 512M [mysqld_safe] log-error=/var/log/mariadb/mariadb.log pid-file=/var/run/mariadb/mariadb.pid # # include all files from the config directory # !includedir /etc/my.cnf.d EOF # 修改完配置后重新启动数据库 sudo systemctl start mariadb # 运行脚本 为MariaDB进行初始化,包括设置root密码和一些选项:(^mariadbtxzpw01\u0026FR) sudo /usr/bin/mysql_secure_installation # 输出如下 [...] Enter current password for root (enter for none): OK, successfully used password, moving on... [...] Set root password? [Y/n] Y New password: Re-enter new password: [...] Remove anonymous users? [Y/n] Y [...] Disallow root login remotely? [Y/n] N [...] Remove test database and access to it [Y/n] Y [...] Reload privilege tables now? [Y/n] Y [...] All done! If you've completed all of the above steps, your MariaDB installation should now be secure. Thanks for using MariaDB! ","date":"2020-03-18","objectID":"/cdh_copy/:11:1","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"为MariaDB安装MySQL JDBC驱动程序 # 前置要求: 将下载的Connector上传到http的softwares目录中 curl http://192.168.181.128/softwares/mysql-connector-java-5.1.47.tar.gz -O --progress tar zxvf mysql-connector-java-5.1.47.tar.gz sudo mkdir -p /usr/share/java/ cd mysql-connector-java-5.1.47 sudo cp mysql-connector-java-5.1.47-bin.jar /usr/share/java/mysql-connector-java.jar ","date":"2020-03-18","objectID":"/cdh_copy/:11:2","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"为Cloudera Software创建数据库(元数据库) # 登陆mariadb mysql -u root -p # 输入密码(^mariadbtxzpw01\u0026FR) # 执行以下sql,完成创建数据库,创建用户,授予权限 CREATE DATABASE scm DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL ON scm.* TO 'scm'@'%' IDENTIFIED BY '^cdhtxzpw01\u0026FR'; CREATE DATABASE amon DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL ON amon.* TO 'amon'@'%' IDENTIFIED BY '^cdhtxzpw01\u0026FR'; CREATE DATABASE rman DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL ON rman.* TO 'rman'@'%' IDENTIFIED BY '^cdhtxzpw01\u0026FR'; CREATE DATABASE hue DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL ON hue.* TO 'hue'@'%' IDENTIFIED BY '^cdhtxzpw01\u0026FR'; CREATE DATABASE metastore DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL ON metastore.* TO 'hive'@'%' IDENTIFIED BY '^cdhtxzpw01\u0026FR'; CREATE DATABASE sentry DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL ON sentry.* TO 'sentry'@'%' IDENTIFIED BY '^cdhtxzpw01\u0026FR'; CREATE DATABASE nav DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL ON nav.* TO 'nav'@'%' IDENTIFIED BY '^cdhtxzpw01\u0026FR'; CREATE DATABASE navms DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL ON navms.* TO 'navms'@'%' IDENTIFIED BY '^cdhtxzpw01\u0026FR'; CREATE DATABASE oozie DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; GRANT ALL ON oozie.* TO 'oozie'@'%' IDENTIFIED BY '^cdhtxzpw01\u0026FR'; SHOW DATABASES; # 查看所有用户 SELECT DISTINCT CONCAT('User: ''',user,'''@''',host,''';') AS query FROM mysql.user; # 可以查看某用户的权限信息 SHOW GRANTS FOR 'scm'@'%'; ","date":"2020-03-18","objectID":"/cdh_copy/:11:3","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"设置Cloudera Manager数据库 前置要求: 安装cms,创建cms数据库,mariadb与cms在同一主机上,如果不在,参考官方文档 备注: cms包含一个可以为自己创建和配置数据库的脚本scm_prepare_database.sh # 对上一步创建的数据库依次运行下面的命令 #sudo /usr/share/cmf/schema/scm_prepare_database.sh \u003cdatabaseType\u003e \u003cdatabaseName\u003e \u003cdatabaseUser\u003e # \u003cdatabaseName\u003e是cms要使用的数据库,其会在其中创建一些表用来保存管理数据等,如果指定-p -u选项,这回创建这个数据库 # \u003cdatabaseType\u003e填mysql # \u003cdatabaseUser\u003e要创建或使用scm数据库的用户名,[创建权限的时候已经默认创建了该用户] # 例如,出现提示后输入scm数据库的访问密码(^cdhtxzpw01\u0026FR) sudo /usr/share/cmf/schema/scm_prepare_database.sh mysql scm scm # 上一步中,如果没有创建cms数据库,则必须使用 -u -p 选项来创建cms数据库,命令如下 sudo /usr/share/cmf/schema/scm_prepare_database.sh mysql -uroot -p 输出如下 [root@foo-1 yangzhaoyunfei]# sudo /usr/share/cmf/schema/scm_prepare_database.sh mysql scm scm Enter SCM password: JAVA_HOME=/usr/java/jdk1.8.0_162 Verifying that we can write to /etc/cloudera-scm-server Creating SCM configuration file in /etc/cloudera-scm-server Executing: /usr/java/jdk1.8.0_162/bin/java -cp /usr/share/java/mysql-connector-java.jar:/usr/share/java/oracle-connector-java.jar:/usr/share/java/postgresql-connector-java.jar:/usr/share/cmf/schema/../lib/* com.cloudera.enterprise.dbutil.DbCommandExecutor /etc/cloudera-scm-server/db.properties com.cloudera.cmf.db. [ main] DbCommandExecutor INFO Successfully connected to database. All done, your SCM database is configured correctly! ","date":"2020-03-18","objectID":"/cdh_copy/:11:4","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"安装cdh 前置要求: 系统环境,jdk,database,connector,元数据库,配置cdh的repo(rpm)/http(parcel)库;数据库;数据库连接驱动,cms # 启动cms sudo systemctl start cloudera-scm-server # 查看启动日志 sudo tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log # 输入如下, 日志出现 Started Jetty server. ,启动成功 [yangzhaoyunfei@foo-1 ~]$ sudo tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log 2018-08-29 14:00:36,582 INFO SearchRepositoryManager-0:com.cloudera.server.web.cmf.search.components.SearchRepositoryManager: Generating entities:2018-08-29T06:00:36.582Z 2018-08-29 14:00:36,590 INFO SearchRepositoryManager-0:com.cloudera.server.web.cmf.search.components.SearchRepositoryManager: Num entities:208 2018-08-29 14:00:36,590 INFO SearchRepositoryManager-0:com.cloudera.server.web.cmf.search.components.SearchRepositoryManager: Generating documents:2018-08-29T06:00:36.590Z 2018-08-29 14:00:36,630 INFO SearchRepositoryManager-0:com.cloudera.server.web.cmf.search.components.SearchRepositoryManager: Num docs:221 2018-08-29 14:00:36,630 INFO SearchRepositoryManager-0:com.cloudera.server.web.cmf.search.components.SearchRepositoryManager: Constructing repo:2018-08-29T06:00:36.630Z 2018-08-29 14:00:37,249 INFO WebServerImpl:org.mortbay.log: jetty-6.1.26.cloudera.4 2018-08-29 14:00:37,261 INFO WebServerImpl:org.mortbay.log: Started SelectChannelConnector@0.0.0.0:7180 2018-08-29 14:00:37,261 INFO WebServerImpl:com.cloudera.server.cmf.WebServerImpl: Started Jetty server. #出现这句启动成功 2018-08-29 14:00:37,356 INFO SearchRepositoryManager-0:com.cloudera.server.web.cmf.search.components.SearchRepositoryManager: Finished constructing repo:2018-08-29T06:00:37.356Z 2018-08-29 14:00:42,368 INFO ScmActive-0:com.cloudera.server.cmf.components.ScmActive: ScmActive completed successfully. 浏览器打开安装界面进行安装 ","date":"2020-03-18","objectID":"/cdh_copy/:12:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"设置本地 parcel 存储库 url 群集安装--\u003e选择存储库--\u003e选择方法 使用 Parcel (建议) , 更多选项 删除所有远程 Parcel 存储库 URL 添加本地parcel库地址 http://192.168.181.128/cloudera-parcels/cdh5/5.15.1/ 其他 Spark 2,Sqoop Connectors,cdh5 等组件设置等同. 选择您要安装在主机上的 Cloudera Manager Agent 特定发行版,自定义存储库 agent存储库地址为上面配置过的cm repo地址 http://192.168.181.128/cm/5/ 因为配置过ssh互信,提供 SSH 登录凭据 选择 接受相同私钥,把master的私钥下载后选中 ","date":"2020-03-18","objectID":"/cdh_copy/:12:1","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"如果之前安装了jdk, jdk选择页面 不要勾选 安装JDK ","date":"2020-03-18","objectID":"/cdh_copy/:12:2","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"单用户模式配置复杂,不要勾选 ","date":"2020-03-18","objectID":"/cdh_copy/:12:3","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"Install Agents ","date":"2020-03-18","objectID":"/cdh_copy/:12:4","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"正在安装选定 Parcel ","date":"2020-03-18","objectID":"/cdh_copy/:12:5","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"检查主机正确性 解决检查出的问题后继续 Cloudera 建议将 /proc/sys/vm/swappiness 设置为最大值 10。当前设置为 60。使用 sysctl 命令在运行时更改该设置并编辑 /etc/sysctl.conf，以在重启后保存该设置。您可以继续进行安装，但 Cloudera Manager 可能会报告您的主机由于交换而运行状况不良。以下主机将受到影响： 查看详细信息 foo-[1-3].mycluster.com 已启用透明大页面压缩，可能会导致重大性能问题。请运行\"echo never \u003e /sys/kernel/mm/transparent_hugepage/defrag\"和\"echo never \u003e /sys/kernel/mm/transparent_hugepage/enabled\"以禁用此设置，然后将同一命令添加到 /etc/rc.local 等初始化脚本中，以便在系统重启时予以设置。以下主机将受到影响: 查看详细信息 foo-[1-3].mycluster.com ","date":"2020-03-18","objectID":"/cdh_copy/:12:6","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"数据库设置 查看前面相关的数据库设置 ","date":"2020-03-18","objectID":"/cdh_copy/:12:7","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"审核更改 保持默认即可 ","date":"2020-03-18","objectID":"/cdh_copy/:12:8","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"首次运行 命令 等待部署完成 ","date":"2020-03-18","objectID":"/cdh_copy/:12:9","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"恭喜 ","date":"2020-03-18","objectID":"/cdh_copy/:12:10","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"系统配置优化(可选) 修改最大线程数IO等限制(暂不进行) vi /etc/systemd/system.conf # 修改如下内容 DefaultLimitCORE=infinity DefaultLimitNOFILE=100000 DefaultLimitNPROC=100000 关闭THP(脚本中已有) # 检查状态 cat /sys/kernel/mm/transparent_hugepage/defrag # output: [always] madvise never cat /sys/kernel/mm/transparent_hugepage/enabled # output: [always] madvise never # 修改启动脚本,每次开机都禁用它们 cat\u003e\u003e/etc/rc.d/rc.local\u003c\u003cEOF ####################### 自行添加 ########################### if test -f /sys/kernel/mm/transparent_hugepage/enabled; then echo never \u003e /sys/kernel/mm/transparent_hugepage/enabled fi if test -f /sys/kernel/mm/transparent_hugepage/defrag; then echo never \u003e /sys/kernel/mm/transparent_hugepage/defrag fi ####################### 自行添加 ########################### EOF chmod +x /etc/rc.d/rc.local reboot 内核参数优化(暂不进行,应该由专业运维人员来做) # 添加以下内容 cat\u003e\u003e/etc/sysctl.conf\u003c\u003cEOF ####################### 自行添加 ########################### #关闭ipv6 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 # 避免放大攻击 net.ipv4.icmp_echo_ignore_broadcasts = 1 # 开启恶意icmp错误消息保护 net.ipv4.icmp_ignore_bogus_error_responses = 1 #关闭路由转发 net.ipv4.ip_forward = 0 net.ipv4.conf.all.send_redirects = 0 net.ipv4.conf.default.send_redirects = 0 #开启反向路径过滤 net.ipv4.conf.all.rp_filter = 1 net.ipv4.conf.default.rp_filter = 1 #处理无源路由的包 net.ipv4.conf.all.accept_source_route = 0 net.ipv4.conf.default.accept_source_route = 0 #关闭sysrq功能 kernel.sysrq = 0 #core文件名中添加pid作为扩展名 kernel.core_uses_pid = 1 # 开启SYN洪水攻击保护 net.ipv4.tcp_syncookies = 1 #修改消息队列长度 kernel.msgmnb = 65536 kernel.msgmax = 65536 #设置最大内存共享段大小bytes kernel.shmmax = 68719476736 kernel.shmall = 4294967296 #timewait的数量，默认180000 net.ipv4.tcp_max_tw_buckets = 6000 net.ipv4.tcp_sack = 1 net.ipv4.tcp_window_scaling = 1 net.ipv4.tcp_rmem = 4096 87380 4194304 net.ipv4.tcp_wmem = 4096 16384 4194304 net.core.wmem_default = 8388608 net.core.rmem_default = 8388608 net.core.rmem_max = 16777216 net.core.wmem_max = 16777216 #每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目 net.core.netdev_max_backlog = 262144 #限制仅仅是为了防止简单的DoS 攻击 net.ipv4.tcp_max_orphans = 3276800 #未收到客户端确认信息的连接请求的最大值 net.ipv4.tcp_max_syn_backlog = 262144 net.ipv4.tcp_timestamps = 0 #内核放弃建立连接之前发送SYNACK 包的数量 net.ipv4.tcp_synack_retries = 1 #内核放弃建立连接之前发送SYN 包的数量 net.ipv4.tcp_syn_retries = 1 #启用timewait 快速回收 net.ipv4.tcp_tw_recycle = 1 #开启重用。允许将TIME-WAIT sockets 重新用于新的TCP 连接 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_mem = 94500000 915000000 927000000 net.ipv4.tcp_fin_timeout = 1 #当keepalive 起用的时候，TCP 发送keepalive 消息的频度。缺省是2 小时 net.ipv4.tcp_keepalive_time = 30 #允许系统打开的端口范围 net.ipv4.ip_local_port_range = 1024 65000 #修改防火墙表大小，默认65536 #系统级别的能够打开的文件句柄的数量,ulimit 是进程级别的 fs.file-max = 265535 #系统允许的最大跟踪连接条目。在/etc/sysctl.conf文件中增加此属性，并运行\u003e/sbin/sysctl.conf –p net.ipv4.ip_conntrack_max=265535 # 确保无人能修改路由表 net.ipv4.conf.all.accept_redirects = 0 net.ipv4.conf.default.accept_redirects = 0 net.ipv4.conf.all.secure_redirects = 0 net.ipv4.conf.default.secure_redirects = 0 net.nf_conntrack_max = 6553600 # 如果在sysctl -p的时候报error: 'net.ipv4.ip_conntrack_max' is an unknown key ,通过以下命令向内核中加入模块修正： modprobe ip_conntrack echo \"modprobe ip_conntrack\" \u003e\u003e /etc/rc.local # net.netfilter.nf_conntrack_max=655350 # net.netfilter.nf_conntrack_tcp_timeout_established=1200 ####################### 自行添加 ########################### EOF # 从/etc/sysctl.conf加载内核参数 sysctl -p 1.Disable the tuned Service(暂不进行) systemctl start tuned tuned-adm off tuned-adm list # 输出中应该包含如下字样 # No current active profile systemctl stop tuned systemctl disable tuned 8.系统优化 ALL 禁用交换分区 sysctl -w vm.swappiness=0 禁用透明大页面 echo never \u003e /sys/kernel/mm/transparent_hugepage/defrag ","date":"2020-03-18","objectID":"/cdh_copy/:12:11","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"待完善 chrony时间同步存在问题,显示不可达 linux系统还有几项可以优化 脚本还需加入上面的修改项 ","date":"2020-03-18","objectID":"/cdh_copy/:13:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"附件 ","date":"2020-03-18","objectID":"/cdh_copy/:14:0","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"附件1 InstallCDH_SSH.sh 文件内容如下: #!/bin/bash # 该脚本的参数有三个,username,password,hostnames-file: # hostnames-file 内容示例,如: # 192.168.181.128=foo-1.mycluster.com # 192.168.181.129=foo-2.mycluster.com # 192.168.181.130=foo-3.mycluster.com # 192.168.181.131=foo-4.mycluster.com # 192.168.181.132=foo-5.mycluster.com # 192.168.181.133=foo-6.mycluster.com # 192.168.181.134=foo-7.mycluster.com # 192.168.181.135=foo-8.mycluster.com # 192.168.181.136=foo-9.mycluster.com # # 该脚本执行前需要按说明文档中先完成前置工作: # 1.createhostfile()中, # 2.createssh()中, # 3.createssh()中,repo文件,jdk文件需要放到第一台机器的httpd服务器中,供其所有机器下载 if [ $# -ne 3 ]; then # 如果传入的参数不是3个 echo \"Usage:\" echo \"$0linuxuser linuxpasswd hostsFile\" exit 1 fi # 获取参数 linuxuser=$1 linuxpasswd=$2 hostfilename=$3 # 创建/etc/hosts文件,这个函数仅操作第一台机器 createhostfile() { # 读取变量1个字符的变量,并赋给answer read -n 1 -p \"需要重置host文件吗？(y/n)?\" answer case $answer in Y | y) local hostfile=$1 # 局部变量 echo `date \"+%Y-%m-%d %H:%M:%S\"`\" ================================================\" echo `date \"+%Y-%m-%d %H:%M:%S\"`\" step 01 开始生成 /etc/hosts 文件\" cat /dev/null\u003e/etc/hosts # 清空hosts文件 echo \"127.0.0.1 localhost\" for line in `cat $hostfile` do ip=`echo $line|awk -F'=' '{print $1}'` hostname=`echo $line|awk -F'=' '{print $2}'` echo \"$ip$hostname\"\u003e\u003e/etc/hosts # 追加 done echo \"127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4\"\u003e\u003e/etc/hosts echo \"::1 localhost localhost.localdomain localhost6 localhost6.localdomain6\"\u003e\u003e/etc/hosts echo `date \"+%Y-%m-%d %H:%M:%S\"`\" step 01 生成 /etc/hosts 文件完成，请查看\" echo `date \"+%Y-%m-%d %H:%M:%S\"`\" =========================\" cat /etc/hosts echo `date \"+%Y-%m-%d %H:%M:%S\"`\" =========================\" echo `date \"+%Y-%m-%d %H:%M:%S\"`\"\" read -n1 -p \"请确认是否正确？(y/n)?\" answer case $answer in Y | y) echo `date \"+%Y-%m-%d %H:%M:%S\"`\" step 01 生成 /etc/hosts 文件完成\" echo `date \"+%Y-%m-%d %H:%M:%S\"`\" ================================================\" ;; N | n) echo \"请确认传入参数文件是否正确\" exit 1 ;; *) echo \"error choice\" exit 1 ;; esac ;; N | n) echo \"跳过\" ;; esac } # 免密登陆,这里只需在一个主机上信任自身,然后拷贝到其他机器上,即可完成整个集群的互信 createssh() { read -n 1 -p \"需要重置SSH吗？(y/n)?\" answer case $answer in Y | y) echo `date \"+%Y-%m-%d %H:%M:%S\"`\" ================================================\" echo `date \"+%Y-%m-%d %H:%M:%S\"`\" step 02 开始自动化建立SSH互信\" local DEST_USER=$1 local PASSWORD=$2 local HOSTS_FILE=$3 if [ $# -ne 3 ]; then echo \"Usage:\" echo \"$0remoteUser remotePassword hostsFile\" exit 1 fi SSH_DIR=~/.ssh SCRIPT_PREFIX=./tmp # 1. prepare directory .ssh mkdir $SSH_DIR chmod 700 $SSH_DIR # 2. generat ssh key TMP_SCRIPT=$SCRIPT_PREFIX.sh # ./tmp.sh echo \"#!/usr/bin/expect\"\u003e$TMP_SCRIPT echo \"spawn ssh-keygen -b 1024 -t rsa\"\u003e\u003e$TMP_SCRIPT echo \"expect *key*\"\u003e\u003e$TMP_SCRIPT # 检测到'key' echo \"send \\r\"\u003e\u003e$TMP_SCRIPT if [ -f $SSH_DIR/id_rsa ]; then # 检测文件是否为普通文件 echo \"expect *verwrite*\"\u003e\u003e$TMP_SCRIPT echo \"send y\\r\"\u003e\u003e$TMP_SCRIPT fi echo \"expect *passphrase*\"\u003e\u003e$TMP_SCRIPT echo \"send \\r\"\u003e\u003e$TMP_SCRIPT echo \"expect *again:\"\u003e\u003e$TMP_SCRIPT echo \"send \\r\"\u003e\u003e$TMP_SCRIPT echo \"interact\"\u003e\u003e$TMP_SCRIPT chmod +x $TMP_SCRIPT /usr/bin/expect $TMP_SCRIPT rm $TMP_SCRIPT ################### 3. generat file authorized_keys cat $SSH_DIR/id_rsa.pub\u003e\u003e$SSH_DIR/authorized_keys # 将本机id加到信任列表 ################### 4. chmod 600 for file authorized_keys chmod 600 $SSH_DIR/authorized_keys echo \"===========================\" ################### 5. copy all files to other hosts for ip in `cat $HOSTS_FILE|awk -F'=' '{print $2}'` # 对每个主机搜索 do if [ \"x$ip\" != \"x\" ]; then # ip不为空 echo ------------------------- TMP_SCRIPT=${SCRIPT_PREFIX}.$ip.sh # check known_hosts val=`ssh-keygen -F $ip` # 在 know_hosts 中 find 指定 hostname if [ \"x$val\" == \"x\" ]; then # 没有搜索到 echo \"$ipnot in $SSH_DIR/known_hosts, need to add\" val=`ssh-keyscan $ip 2\u003e/dev/null` # 扫描该主机中的公钥,标错输出到空 if [ \"x$val\" == \"x\" ]; then # 如果没有扫描到 echo \"ssh-keyscan $ipfailed!\" else echo $val\u003e\u003e$SSH_DIR/known_hosts # 将扫描到的公钥添加到 fi fi echo \"copy $SSH_DIRto $ip\" echo \"#!/usr/bin/expect\"\u003e$TMP_SCRIPT echo \"spawn scp -r $SSH_DIR$DEST_USER@$ip:~/\"\u003e\u003e$TMP_SCRIPT echo \"","date":"2020-03-18","objectID":"/cdh_copy/:14:1","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["big data"],"content":"附件2 hostsname.txt 内容如下: 192.168.181.128=foo-1.mycluster.com 192.168.181.129=foo-2.mycluster.com 192.168.181.130=foo-3.mycluster.com ","date":"2020-03-18","objectID":"/cdh_copy/:14:2","tags":["大数据","Hadoop","部署"],"title":"Hadoop-CDH发行版--集群离线部署教程","uri":"/cdh_copy/"},{"categories":["development kit"],"content":"安装 chocolatey 管理员运行pwsh, 并在其中运行: Get-ExecutionPolicy # If it returns Restricted, then run Set-ExecutionPolicy AllSigned or Set-ExecutionPolicy Bypass -Scope Process # 执行以下命令并等待安装完成 Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1')) # 试用 choco ","date":"2020-03-18","objectID":"/chocolatey-install/:1:0","tags":["choco"],"title":"windows下, 使用choco安装开发环境","uri":"/chocolatey-install/"},{"categories":["development kit"],"content":"使用 choco 安装软件 如果网速较慢，可为powershell设置SS代理 参考 https://blog.csdn.net/weixin_30553065/article/details/95229332 $env:HTTPS_PROXY=\"http://127.0.0.1:1080\" $env:HTTP_PROXY=\"http://127.0.0.1:1080\" 新建统一的开发工具管理文件, dev-package.config: \u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u003cpackages\u003e \u003cpackage id=\"jdk8\" /\u003e \u003cpackage id=\"visualstudio2019community\" /\u003e \u003cpackage id=\"adoptopenjdk14\" /\u003e \u003cpackage id=\"7zip\"/\u003e \u003cpackage id=\"git\" /\u003e \u003cpackage id=\"github-desktop\" /\u003e \u003cpackage id=\"hugo-extended\" /\u003e \u003cpackage id=\"maven\" /\u003e \u003cpackage id=\"gradle\" /\u003e \u003cpackage id=\"intellijidea-ultimate\" /\u003e \u003cpackage id=\"python\" /\u003e \u003cpackage id=\"nodejs\" /\u003e \u003cpackage id=\"tomcat\" /\u003e \u003cpackage id=\"golang\" /\u003e \u003cpackage id=\"vscode\" /\u003e \u003cpackage id=\"googlechrome\" /\u003e \u003cpackage id=\"docker-desktop\" /\u003e \u003cpackage id=\"virtualbox\" /\u003e \u003cpackage id=\"teamviewer\" /\u003e \u003cpackage id=\"redis-desktop-manager\" /\u003e \u003cpackage id=\"studio3t\" /\u003e \u003cpackage id=\"heidisql\" /\u003e \u003cpackage id=\"sourcetree\" /\u003e \u003cpackage id=\"dismplusplus\" /\u003e \u003cpackage id=\"tortoisesvn\" /\u003e \u003cpackage id=\"shadowsocksr-windows\" /\u003e \u003cpackage id=\"clash-for-windows\" /\u003e \u003c/packages\u003e 安装dev-package.config文件内描述的所有软件包: choco install dev-package.config -y 更多安装包，去这里搜索：https://chocolatey.org/packages ","date":"2020-03-18","objectID":"/chocolatey-install/:2:0","tags":["choco"],"title":"windows下, 使用choco安装开发环境","uri":"/chocolatey-install/"},{"categories":["development kit"],"content":"备份开发环境 创建backup.bat文件，内容如下： REM 备份开发环境 cd %userprofile% del ./out.zip tar.exe -a -c -f out.zip ^ .3T ^ .config ^ .docker ^ .dotnet ^ .eclipse ^ .gradle ^ .ideaLibSources ^ .IntelliJIdea* ^ .jmc ^ .m2 ^ .minikube ^ .oss-browser ^ .rdm ^ .ssh ^ .swt ^ .translation ^ .VirtualBox ^ .vscode ^ .vs-kubernetes ^ etc ^ go ^ node_modules ^ PycharmProjects ^ IdeaProjects ^ source ^ tmp ^ 'VirtualBox VMs' ^ .gitconfig ^ .viminfo ^ .wslconfig ^ package-lock.json ","date":"2020-03-18","objectID":"/chocolatey-install/:3:0","tags":["choco"],"title":"windows下, 使用choco安装开发环境","uri":"/chocolatey-install/"},{"categories":["development kit"],"content":"恢复开发环境 cd ~ Expand-Archive -Path .\\out.zip -DestinationPath . ","date":"2020-03-18","objectID":"/chocolatey-install/:4:0","tags":["choco"],"title":"windows下, 使用choco安装开发环境","uri":"/chocolatey-install/"},{"categories":["development kit"],"content":"References Windows统一开发环境的基础-Chocolatey ","date":"2020-03-18","objectID":"/chocolatey-install/:5:0","tags":["choco"],"title":"windows下, 使用choco安装开发环境","uri":"/chocolatey-install/"},{"categories":["distributed system"],"content":"随着用户数的不断增加，以及数据量的不断增加，通过分库与分表的方式提高查询性能的同时，带来了一系列分布式困境。 ","date":"2020-03-18","objectID":"/sharding/:0:0","tags":["分布式系统","分库分表","面试"],"title":"分布式系统中的分库分表问题","uri":"/sharding/"},{"categories":["distributed system"],"content":"数据迁移与扩容问题 水平分表策略归纳总结为随机分表和连续分表两种情况。 连续分表的操作比较容易，不需要考虑迁移旧的数据，只需要添加分表就可以自动扩容。但有可能存在数据热点的问题，有些表可能会被频繁地查询从而造成较大压力，热数据的表就成为了整个库的瓶颈，而有些表可能存的是历史数据，很少需要被查询到。 随机分表的数据比较均匀，不容易出现热点和并发访问的瓶颈。但是，扩容时需要迁移旧的数据。对于数据迁移的问题，一般做法是通过程序先读出数据，然后按照指定的分表策略再将数据写入到各个分表中。 针对于水平分表的设计至关重要，需要评估中短期内业务的增长速度，对当前的数据量进行容量规划，综合成本因素，推算出大概需要多少分片。 ","date":"2020-03-18","objectID":"/sharding/:1:0","tags":["分布式系统","分库分表","面试"],"title":"分布式系统中的分库分表问题","uri":"/sharding/"},{"categories":["distributed system"],"content":"表关联问题 在单库单表的情况下，联合查询非常容易。但是，随着分库与分表的演变，联合查询就遇到跨库关联和跨表关联问题。在设计之初就应该尽量避免联合查询，可以通过在程序中进行拼装，或者通过反范式化设计进行规避。 ","date":"2020-03-18","objectID":"/sharding/:2:0","tags":["分布式系统","分库分表","面试"],"title":"分布式系统中的分库分表问题","uri":"/sharding/"},{"categories":["distributed system"],"content":"分页与排序问题 一般情况下，列表分页时需要按照指定字段进行排序。在单库单表的情况下，分页和排序也是非常容易的。但是，随着分库与分表的演变，也会遇到跨库排序和跨表排序问题。 为了最终结果的准确性，需要在不同的分表中将数据进行排序并返回，并将不同分表返回的结果集进行汇总和再次排序，最后再返回给用户。 ","date":"2020-03-18","objectID":"/sharding/:3:0","tags":["分布式系统","分库分表","面试"],"title":"分布式系统中的分库分表问题","uri":"/sharding/"},{"categories":["distributed system"],"content":"分布式事务问题 随着分库与分表的演变，一定会遇到分布式事务问题，那么如何保证数据的一致性就成为一个必须面对的问题。目前，分布式事务并没有很好的解决方案，难以满足数据强一致性，一般情况下，使存储数据尽可能达到用户一致，保证系统经过一段较短的时间的自我恢复和修正，达到数据最终一致性。 ","date":"2020-03-18","objectID":"/sharding/:4:0","tags":["分布式系统","分库分表","面试"],"title":"分布式系统中的分库分表问题","uri":"/sharding/"},{"categories":["distributed system"],"content":"分布式全局唯一ID 在单库单表的情况下，直接使用数据库自增特性来生成主键ID，这样确实比较简单。在分库分表的环境中，数据分布在不同的分表上，不能再借助数据库自增长特性。需要使用全局唯一 ID，例如 UUID、GUID等。关于如何选择合适的全局唯一 ID，目前有多种实现方案和框架可以选择。 ","date":"2020-03-18","objectID":"/sharding/:5:0","tags":["分布式系统","分库分表","面试"],"title":"分布式系统中的分库分表问题","uri":"/sharding/"},{"categories":["distributed system"],"content":"总结 分库与分表主要用于应对当前互联网常见的两个场景：高并发 和 海量数据。然而，分库与分表是一把双刃剑，虽然很好的应对海量数据和高并发对数据库的冲击和压力，但是却提高了系统的复杂度和维护成本。 因此，大佬建议：结合实际需求，不宜过度设计，在项目一开始不采用分库与分表设计，而是随着业务的增长，在无法继续优化的情况下，再考虑分库与分表提高系统的性能。 ","date":"2020-03-18","objectID":"/sharding/:6:0","tags":["分布式系统","分库分表","面试"],"title":"分布式系统中的分库分表问题","uri":"/sharding/"},{"categories":["distributed system"],"content":"References 服务端指南 数据存储篇 | MySQL（08） 分库与分表设计 | 梁桂钊的博客 ","date":"2020-03-18","objectID":"/sharding/:7:0","tags":["分布式系统","分库分表","面试"],"title":"分布式系统中的分库分表问题","uri":"/sharding/"},{"categories":["distributed system"],"content":"什么是RPC?","date":"2020-03-17","objectID":"/rpc/","tags":["分布式系统","RPC","面试"],"title":"RPC","uri":"/rpc/"},{"categories":["distributed system"],"content":"RPC就是要像调用本地的函数一样去调远程函数. ","date":"2020-03-17","objectID":"/rpc/:0:0","tags":["分布式系统","RPC","面试"],"title":"RPC","uri":"/rpc/"},{"categories":["distributed system"],"content":"本地过程调用 在研究RPC前，我们先看看本地调用是怎么调的。假设我们要调用函数Multiply来计算lvalue * rvalue的结果: 1 int Multiply(int l, int r) { 2 int y = l * r; 3 return y; 4 } 5 6 int lvalue = 10; 7 int rvalue = 20; 8 int l_times_r = Multiply(lvalue, rvalue); 那么在第8行时，我们实际上执行了以下操作： 将 lvalue 和 rvalue 的值压栈 进入Multiply函数，取出栈中的值10 和 20，将其赋予 l 和 r 执行第2行代码，计算 l * r ，并将结果存在 y 将 y 的值压栈，然后从Multiply返回 第8行，从栈中取出返回值 200 ，并赋值给 l_times_r 以上5步就是执行本地调用的过程。 注：以上步骤只是为了说明原理。事实上编译器经常会做优化，对于参数和返回值少的情况会直接将其存放在寄存器，而不需要压栈弹栈的过程，甚至都不需要调用call，而直接做inline操作。仅就原理来说，这5步是没有问题的。 ","date":"2020-03-17","objectID":"/rpc/:1:0","tags":["分布式系统","RPC","面试"],"title":"RPC","uri":"/rpc/"},{"categories":["distributed system"],"content":"远程过程调用带来的新问题 在远程调用时，我们需要执行的函数体是在远程的机器上的，也就是说，Multiply是在另一个进程中执行的。这就带来了几个新问题： Call ID映射。 我们怎么告诉远程机器我们要调用Multiply函数，而不是Add或者FooBar呢？在本地调用中，函数体是直接通过函数指针来指定的，我们调用Multiply，编译器就自动帮我们调用它相应的函数指针。但是在远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样。所以，在RPC中，所有的函数都必须有自己的一个ID。这个ID在所有进程中都是唯一确定且相同的。客户端在做远程过程调用时，必须附上这个ID。然后我们还需要在客户端和服务端分别维护一个 {函数 \u003c–\u003e Call ID} 的对应表。两者的表不一定需要完全相同，但相同的函数对应的Call ID必须相同。当客户端需要进行远程调用时，它就查一下这个表，找出相应的Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。 序列化和反序列化。 客户端怎么把参数值传给远程的函数呢？在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。甚至有时候客户端和服务端使用的都不是同一种语言（比如服务端用C++，客户端用Java或者Python）。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。这个过程叫序列化和反序列化。同理，从服务端返回的值也需要序列化反序列化的过程。 网络传输。 远程调用往往用在网络上，客户端和服务端是通过网络连接的。所有的数据都需要通过网络传输，因此就需要有一个网络传输层。网络传输层需要把Call ID和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。只要能完成这两者的，都可以作为传输层使用。因此，它所使用的协议其实是不限的，能完成传输就行。尽管大部分RPC框架都使用TCP协议，但其实UDP也可以，而gRPC干脆就用了HTTP2。Java的Netty也属于这层的东西。 有了这三个机制，就能实现RPC了，具体过程如下： // Client端 // int l_times_r = Call(ServerAddr, Multiply, lvalue, rvalue) 1. 将这个调用映射为Call ID。这里假设用最简单的字符串当Call ID的方法 2. 将Call ID，lvalue和rvalue序列化。可以直接将它们的值以二进制形式打包 3. 把2中得到的数据包发送给ServerAddr，这需要使用网络传输层 4. 等待服务器返回结果 5. 如果服务器调用成功，那么就将结果反序列化，并赋给l_times_r // Server端 1. 在本地维护一个Call ID到函数指针的映射call_id_map，可以用std::map\u003cstd::string, std::function\u003c\u003e\u003e 2. 等待请求 3. 得到一个请求后，将其数据包反序列化，得到Call ID 4. 通过在call_id_map中查找，得到相应的函数指针 5. 将lvalue和rvalue反序列化后，在本地调用Multiply函数，得到结果 6. 将结果序列化后通过网络返回给Client 其中: Call ID映射可以直接使用函数字符串，也可以使用整数ID。映射表一般就是一个哈希表。 序列化反序列化可以自己写，也可以使用Protobuf或者FlatBuffers之类的。 网络传输库可以自己写socket，或者用asio，ZeroMQ，Netty之类。 当然，这里面还有一些细节可以填充，比如如何处理网络错误，如何防止攻击，如何做流量控制，等等。但有了以上的架构，这些都可以持续加进去。 ","date":"2020-03-17","objectID":"/rpc/:2:0","tags":["分布式系统","RPC","面试"],"title":"RPC","uri":"/rpc/"},{"categories":["distributed system"],"content":"Reference https://www.zhihu.com/question/25536695/answer/221638079 https://liuzhengyang.github.io/2016/12/16/rpc-principle/ ","date":"2020-03-17","objectID":"/rpc/:3:0","tags":["分布式系统","RPC","面试"],"title":"RPC","uri":"/rpc/"},{"categories":["distributed system"],"content":"锁 在多线程并发读写共享数据及不可预知的线程调度情况下, 为了避免造成数据不一致的问题. 我们通常会采用一定的方式来协调这些并发线程的行为. 最常用的方式就是锁. 锁其实是一种标志, 或一种设计思想, 他表示一个共享资源当前被某单位占有, 其他单位不允许操作. ","date":"2020-03-17","objectID":"/lock/:1:0","tags":["分布式系统","锁","并发"],"title":"分布式锁","uri":"/lock/"},{"categories":["distributed system"],"content":"分布式锁 在同一个jvm中, 我们可以用 synchronized, Lock 等方式来进行线程的同步;但在分布式的集群环境中, 操作同一数据的并发线程可能在不同节点上. 于是, 我们需要分布式锁. ","date":"2020-03-17","objectID":"/lock/:2:0","tags":["分布式系统","锁","并发"],"title":"分布式锁","uri":"/lock/"},{"categories":["distributed system"],"content":"场景 防止库存超卖：每个下单流程都会对现有库存加锁， 扣减库存后释放锁。 ","date":"2020-03-17","objectID":"/lock/:3:0","tags":["分布式系统","锁","并发"],"title":"分布式锁","uri":"/lock/"},{"categories":["distributed system"],"content":"实现方式 ","date":"2020-03-17","objectID":"/lock/:4:0","tags":["分布式系统","锁","并发"],"title":"分布式锁","uri":"/lock/"},{"categories":["distributed system"],"content":"Redis实现 Redis的网络模块是单线程的, 所以不需要考虑并发安全性, 但其他处理模块仍然使用多线程以提高处理效率. 我们通过setnx操作向redis中设置一个key来代表锁标志; 谁set成功，锁由谁持有，这里value我们不关心。 防死锁 为防止某申请者set锁标志后宕机造成死锁问题, 需要给key设置有效期. 有以下解决方案: 在set完key之后，直接设置key的有效期 由redis来删除key释放锁 在value中注明超时时间(存在可忽略不计的小问题) 其他申请者通过get发现时间已到之后可以执行删除key操作.然后可以使用GETSET ","date":"2020-03-17","objectID":"/lock/:4:1","tags":["分布式系统","锁","并发"],"title":"分布式锁","uri":"/lock/"},{"categories":["distributed system"],"content":"Zookeeper实现 ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。 ZooKeeper就像是我们的电脑文件系统，我们可以在d盘中创建文件夹a，并且可以继续在文件夹a中创建文件夹a1，a2。文件系统有什么特点？那就是同一个目录下文件名称不能重复，同样ZooKeeper也是这样的。在ZooKeeper所有的节点，也就是文件夹称作Znode，而且这个Znode节点是可以存储数据的。 我们可以通过” create /zkjjj nice\"来创建一个节点，这个命令就表示，在跟目录下创建一个zkjjj的节点，值是nice，这里value我们不关心。 通过在zookeeper中创建节点来代表锁标志。谁创建成功，锁由谁持有。 其他申请者创建失败，就只能监听该znode。持有者处理完业务后， 删除了该znode，监听者们会得到通知，然后尝试去创建znode，这个尝试过程是并发进行的的。 防死锁 持有者创建znode之后挂掉，导致znode未删除，造成死锁。 所以，需要用到临时性节点。临时性节点的特性是zookeeper客户端断开，则节点会被自动删除，即锁被释放。 临时顺序性节点 惊群效应： 往一群鸽子中间扔一块食物，虽然最终只有一个鸽子抢到食物，但所有鸽子都会被惊动来争夺，却没有抢到…；在分布式系统中就是，znode被删除后，所有监听者都来尝试创建znode，但最终只有一个能创建成功。 假设100个服务器同时发来请求，这个时候会在/zkjjj节点下创建100个临时顺序性节点/zkjjj/000000001，/zkjjj/000000002，一直到/zkjjj/000000100，这个编号就等于是已经给他们设置了获取锁的先后顺序了。 当001节点处理完毕，删除节点后，002收到通知，去获取锁，开始执行，执行完毕，删除节点，通知003~以此类推。避免了一次性通知99个节点，造成惊群效应。 ","date":"2020-03-17","objectID":"/lock/:4:2","tags":["分布式系统","锁","并发"],"title":"分布式锁","uri":"/lock/"},{"categories":["distributed system"],"content":"生产方案 网上有很多讨论分布式锁实现方案的文章, 我们不推荐自己来实现分布式锁, 用开源的会比较好, 这里推荐一个Redisson.其提供了很多功能, 分布式锁只是其中一个. 非spring boot需要自己配置redisson对象. public class Demo { @Autowired private Redisson redisson;// spring boot中不需要手动创建对象, 注入一个即可 public void test() throws InterruptedException { // 这个生成key的规则所有节点要统一 RLock lock = redisson.getLock(\"anyLock\"); //最常见的使用方法 lock.lock(),一直等待,直到获取锁. //支持过期自动解锁, 不怕死锁 lock.lock(10, TimeUnit.SECONDS); //尝试加锁,最多等待100秒,超时未成功返回失败 //上锁以后10秒自动解锁,不怕死锁 boolean res = lock.tryLock(100, 10, TimeUnit.SECONDS); //... lock.unlock();//完成业务逻辑后解锁, 减少加锁时间, 提高并发度 } } ","date":"2020-03-17","objectID":"/lock/:4:3","tags":["分布式系统","锁","并发"],"title":"分布式锁","uri":"/lock/"},{"categories":["distributed system"],"content":"问题 在防止库存超卖的场景中，多个用户同时下单时，会基于分布式锁串行化处理。如果是秒杀之类的高并发场景，这样的处理效率是无法接受的。 ","date":"2020-03-17","objectID":"/lock/:5:0","tags":["分布式系统","锁","并发"],"title":"分布式锁","uri":"/lock/"},{"categories":["distributed system"],"content":"高并发场景下的优化 优化思路是分段锁，类似concurrentHashMap的思路。比如把1000个库存拆成20个分段，在数据库里将原来的一个库存字段拆成20个库存字段。这样，每一个下单请求可以锁一个库存字段。这样并发度就提升至20倍。不过这个优化方案有很多缺点，不再赘述。秒杀场景下有其他更好方案防止库存超卖，使用分布式锁效率不高。 ","date":"2020-03-17","objectID":"/lock/:6:0","tags":["分布式系统","锁","并发"],"title":"分布式锁","uri":"/lock/"},{"categories":["distributed system"],"content":"References 通俗讲解分布式锁，看完不懂算作者输 面试官：每秒上千订单的场景下，如何对分布式锁进行高并发优化？ Spring Cloud微服务入门、实战与进阶-16.4.5 ","date":"2020-03-17","objectID":"/lock/:7:0","tags":["分布式系统","锁","并发"],"title":"分布式锁","uri":"/lock/"},{"categories":["linux"],"content":"免责声明 本文转载自 SeisMan 的 CentOS 7 下的软件安装方法及策略 ","date":"2020-03-17","objectID":"/software_install_strategy/:1:0","tags":["软件管理","安装策略"],"title":"linux下软件安装方法及策略","uri":"/software_install_strategy/"},{"categories":["linux"],"content":"前言 使用 Linux 尤其是 CentOS 会遇到一些坑，或是一些有洁癖的人不能忍的事情： 官方源中的软件包版本太老，在功能上无法满足需求； 多个源的软件包存在版本冲突； 手动编译软件，默认会将不同文件放置在 /usr/local 下不同的子目录下，使得软件的更新和删除变得麻烦。 等等… 在经历了几次重装 CentOS 之后，特总结出如下几条软件安装的方法与原则，以尽可能保证当前系统的稳定、整洁，尽可能降低系统洁癖引起的重装冲动。 以下所说，仅限于 CentOS7，对其他发行版，或许有借鉴意义。 ","date":"2020-03-17","objectID":"/software_install_strategy/:2:0","tags":["软件管理","安装策略"],"title":"linux下软件安装方法及策略","uri":"/software_install_strategy/"},{"categories":["linux"],"content":"软件源 ","date":"2020-03-17","objectID":"/software_install_strategy/:3:0","tags":["软件管理","安装策略"],"title":"linux下软件安装方法及策略","uri":"/software_install_strategy/"},{"categories":["linux"],"content":"官方源 CentOS 自带的四个官方源中，默认打开的有 base、updates、extras，这三个源中包含了约 9000 个软件包，是最稳定、也是最值得信赖的源。 因而若一个软件包在官方源内，则应通过官方源安装: sudo yum install PackageName ","date":"2020-03-17","objectID":"/software_install_strategy/:3:1","tags":["软件管理","安装策略"],"title":"linux下软件安装方法及策略","uri":"/software_install_strategy/"},{"categories":["linux"],"content":"第三方源 官方源虽然包含了很多软件包，但无法满足日常需求。幸好有第三方源，可以作为官方源的补充。 在使用第三方源的过程中，最怕遇到这两个问题： 第三方源和官方源中有相同的包，导致官方源的包被第三方源替代； 多个第三方源中存在同一个软件包，且版本不一致，存在冲突； 这两个问题经常是致命的，出现各种预料不到的后果，因而选择第三方源要遵循如下原则： 只选择可靠的第三方源，要确保第三方源不会替换官方源中的包； 使用尽量少的第三方源，以保证第三方源之间不会冲突； 就 CentOS 而言，根据以上的原则，使用如下第三方源： 大型第三方源，已确认不会替换官方源的包，且相互之间无冲突 EPEL：包含 6500 多个软件，科研必备 ELRepo：包含几十个各种硬件的驱动程序 Nux Dextop：多媒体相关的软件包（与 EPEL 的个别软件相冲突，可忽略） 有些小型第三方源，仅包含了几个软件，确认与官方源和 EPEL 源不会冲突，也可以添加 Google Chrome：包含了 Google Chrome，不会与官方源和 EPEL 源冲突； Adobe：仅包含 flash 插件，已确认不会冲突； dropbox：仅包含 dropbox 一个软件，已确认不会冲突； 因而，若一个软件包位于 EPEL、ELRepo 中，或一些小型的第三方源中，则添加该第三方源，并用 yum 命令安装: sudo yum install PackageName ","date":"2020-03-17","objectID":"/software_install_strategy/:3:2","tags":["软件管理","安装策略"],"title":"linux下软件安装方法及策略","uri":"/software_install_strategy/"},{"categories":["linux"],"content":"官方 rpm 包 大部分非开源的软件，在 CentOS 官方源或 EPEL 中是没有的。有些软件的官方网站会提供官方 rpm 包。此时可以从官方网站下载与当前系统对应的 rpm 包，直接用如下命令安装: sudo rpm -i PackageName.rpm 比如，WPS for Linux 就是其中一个。在安装的过程中 rpm 命令会自动检查依赖关系，若该软件所依赖的包在官方源和 EPEL 源中可以找到，则自动安装。 直接安装 rpm 包的做法相当省事，但该软件不能由 yum 更新，稍稍麻烦一点。有些软件，比如前面提到的 Google、Dropbox 和 Adobe 其实也可以通过这种方法安装，在安装的同时会给系统添加源，对于这类软件依然可以很方便的更新与删除。 ","date":"2020-03-17","objectID":"/software_install_strategy/:3:3","tags":["软件管理","安装策略"],"title":"linux下软件安装方法及策略","uri":"/software_install_strategy/"},{"categories":["linux"],"content":"解压即用 有些软件，官方提供了压缩包，解压之后即可直接运行其中的二进制文件，比如很多 Java 写的软件。这类软件没有给源代码，而是给了可以在当前平台下直接执行的二进制文件。大多数非开源的商业软件都采取这种办法。 比如 sublime_text、pycharm、mendeley、TauP、sac 等，直接解压，然后将解压后的文件夹复制到 /opt 目录下，然后将该软件的 bin 目录加入到 PATH 中即可。 比如 Mathematics、Matlab、intel studio，软件包中提供安装脚本，执行该脚本即可安装； Linux 下的习惯是，商业软件或第三方软件都安装到 /opt 目录下，这也是大多数商业软件包的默认安装路径，尽量遵循该习惯。 ","date":"2020-03-17","objectID":"/software_install_strategy/:3:4","tags":["软件管理","安装策略"],"title":"linux下软件安装方法及策略","uri":"/software_install_strategy/"},{"categories":["linux"],"content":"第三方 rpm 包 有些软件，CentOS 源和 EPEL 源中找不到，官方又没有提供 rpm 包，但是其他第三方源提供了 rpm 包。分情况讨论： 若该第三方源只包含了很少量的包，且确定这些包与官方源以及其他已使用的第三方源不冲突，则可以添加该第三方源。 若该第三方源包含了很多软件，很可能与官方源或 EPEL 源有冲突，则不添加该源 若该软件包没有复杂的依赖关系，则直接安装该源中的 rpm 包； 若该软件包依赖于该第三方源中的其他包，则放弃，寻找其他方法； ","date":"2020-03-17","objectID":"/software_install_strategy/:3:5","tags":["软件管理","安装策略"],"title":"linux下软件安装方法及策略","uri":"/software_install_strategy/"},{"categories":["linux"],"content":"第三方包管理器 不同的发行版使用不同的软件包管理器，CentOS 使用 yum，Ubuntu 使用 apt-get。近些年又出现了一些与发行版无关的第三方包管理器，比如 Linuxbrew、Gentoo Prefix、pkgsrc。 Linuxbrew Linuxbrew 是由 OS X 平台下非常流行的 Homebrew 移植到 Linux 下的。Linuxbrew 可以作为系统自带的包管理器的一个补充。其特色在于： 所有软件都安装在 ${HOME}/.linuxbrew 目录下； 软件的版本相对很新； install、uninstall、info、list、update、upgrade 等功能 若库中没有需要的软件包，可以很简单地自己创建 formulae 试用了一下，一个比较坑的地方是，linuxbrew 会自己内部解决依赖问题。比如，我试着通过 linuxbrew 安装 terminator，然后发现 terminator 依赖于 python，尽管系统已经安装了 python，linuxbrew 还是会安装一份 python，又由于 python 依赖于更多的东西，导致又安装了更多软件包在 home 下。而且，linuxbrew 是从源码编译软件的，所以相对来说速度较慢。 ","date":"2020-03-17","objectID":"/software_install_strategy/:3:6","tags":["软件管理","安装策略"],"title":"linux下软件安装方法及策略","uri":"/software_install_strategy/"},{"categories":["linux"],"content":"编译源码 大部分软件用前面的几种方法应该都能安装上了。如果没安装上，那就得问问自己，真的需要安装这个软件么。如果不是非常必要的话就不要安装啦。如果是必须的软件，那就必须要手动编译了。 常见的源码编译，一般也就是如下几步。当然，具体情况具体对待: tar -xvf xxxx.tgz ./configure --prefix=/opt/xxxx make sudo make install 一般来说，这类软件的默认安装目录都是 /usr/local ，最终文件会被分别放在 /usr/local 的 bin、lib、share、man 目录下。 我个人非常不喜欢这种方式，因为作为一个通过源码编译的软件来说，意味着编译者 要完全负起管理该软件的义务，这样的放置方式会来更新或卸载软件带来很多麻烦。 所以我总是会在 configure 的时候加上 prefix 手动指定安装路径。要卸载该软件就直接删除 /opt 下对应的目录，要更新的话，也可以先删除，再重新编译一遍。这样做稍微麻烦的一点是， 需要手动将该软件的 bin 目录加入到 PATH 中，还有可能需要修改 LD_LIBRARY_PATH。 但是一般来说，需要编译源码的软件很少，所以不会造成太大的麻烦。 ","date":"2020-03-17","objectID":"/software_install_strategy/:3:7","tags":["软件管理","安装策略"],"title":"linux下软件安装方法及策略","uri":"/software_install_strategy/"},{"categories":["linux"],"content":"编译代码 好吧，其实我不知道该怎么起标题了。。 前一节 “编译源码” 主要针对的是一些大型软件包，这一节 “编译代码” 指的是对一些 专业性很强的小代码包的处理方式。比如有些软件包编译之后实际需要的只是一个 二进制文件，这个时候就没有必要安装到 /opt 了，合适的方式是在自己的 HOME 下 建立 bin 目录，并将其路径加入到 .bashrc 中，然后将编译生成的二进制文件复制 到该目录下即可: mkdir ${HOME}/bin echo 'export PATH=${HOME}/bin:$PATH'\u003e\u003e ~/.bashrc 比如我的 ${HOME}/bin 目录下有如下文件： distaz ：给出地球上两点经纬度，计算震中距和方位角 pssac ：在 GMT 中绘制 SAC 文件 rdseed ：SEED 格式转 SAC 格式 win2sac_32 、 catwin32 ：Hi-net 网站提供的用于处理 Hi-net 数据的程序 st ：sublime_text 被安装到 /opt 目录下，在此建立一个软链接，方便在命令行调用 sublime text wlt.pl ：校内用于登陆网络通的脚本，在命令行修改网络端口，好 happy fk 、 fk.pl 、 syn 、 trav ：Prof. Lupei Zhu 的用于计算合成地震图的程序，源代码有不少，实际需要用的也就这三个可执行文件和一个 perl 脚本。 matlab ：指向 matlab 的一个软连接； 不要随便什么二进制文件都往 bin 里放，这里只应放一些常用的命令或很通用的工具。 ","date":"2020-03-17","objectID":"/software_install_strategy/:3:8","tags":["软件管理","安装策略"],"title":"linux下软件安装方法及策略","uri":"/software_install_strategy/"},{"categories":["linux"],"content":"自成系统的软件 有一类软件，其拥有众多模块或包，为了管理这众多的模块，就需要拥有一个自己的模块 / 包管理器。这其中以 TeX、Perl 和 Python 为代表。对于这一类软件，其众多的模块是最大的优势，也是最值得利用的资源，因而我通常会选择手动安装它们，原因如下： 系统的源中不可能包含该软件的所有模块； 系统的源中该软件的模块的更新要远远滞后于最新版本； 当然，即便是使用系统自带的版本，也依然可以用该软件自带的包管理器来安装模块。但将导致： 部分模块用系统的 yum 管理，部分模块用软件自带的包管理器管理； yum 安装的模块一般版本较老，软件的包管理器要安装的大多是最新版本； 这一方面会导致模块管理的混乱，另一方面用软件自带的包管理其安装模块时，可能会依赖于其他模块的最新版本，若该模块是通过系统 yum 安装的较旧的版本，则可能导致模块的安装失败。 因而，对于这类软件，一般单独安装，并用各自的包管理器管理模块： TeXLive：通过 TeXLive iso 镜像文件安装，使用其自带的 tlmgr 管理包 Perl：通过 plenv 安装最新版本的 Perl，使用 plenv 自带的 cpanm 安装模块 Python：通过 pyenv 安装最新版本的 Python，使用 Python 自带的 pip 安装模块 ","date":"2020-03-17","objectID":"/software_install_strategy/:3:9","tags":["软件管理","安装策略"],"title":"linux下软件安装方法及策略","uri":"/software_install_strategy/"},{"categories":["linux"],"content":"例外 有规则总有例外。 第三方源 mosquito-myrepo 是一个私人维护的源，其中包含了中文输入法、QQ、飞信、为知笔记、有道词典、百度云以及若干音频、视频播放器。我对这个源的态度是又爱又恨，其提供了很多中国人需要的软件，但因为其依赖于除 EPEL 外的其他第三方软件源，进而可能导致包冲突。所以对该源的使用，要保持谨慎。 ","date":"2020-03-17","objectID":"/software_install_strategy/:3:10","tags":["软件管理","安装策略"],"title":"linux下软件安装方法及策略","uri":"/software_install_strategy/"},{"categories":["linux"],"content":"总结 简单总结一下: 为系统添加 EPEL 源、Nux Dextop、ELRepo 源和个别其他小型第三方源 能够从源中安装的就从源中安装 不能从源中安装的尽量找 rpm 包安装 找不到 rpm 包的就试试 linuxbrew 能不手动编译的就不要手动编译 ","date":"2020-03-17","objectID":"/software_install_strategy/:4:0","tags":["软件管理","安装策略"],"title":"linux下软件安装方法及策略","uri":"/software_install_strategy/"},{"categories":["linux"],"content":"Scenarios 在CentOS更新后,并不会自动删除旧内核。所以在启动选项中会有多个内核选项,可以手动使用以下命令删除多余的内核: ","date":"2020-03-17","objectID":"/remove_kernel/:1:0","tags":["内核","卸载","Linux"],"title":"Linux卸载多余内核","uri":"/remove_kernel/"},{"categories":["linux"],"content":"1.查看系统当前内核版本: uname -a # 输出如下 Linux localhost.localdomain 3.10.0-229.20.1.el7.x86_64 #1 SMP Tue Nov 3 19:10:07 UTC 201 GNU/Linux ","date":"2020-03-17","objectID":"/remove_kernel/:2:0","tags":["内核","卸载","Linux"],"title":"Linux卸载多余内核","uri":"/remove_kernel/"},{"categories":["linux"],"content":"2.查看系统中全部的内核RPM包: rpm -qa | grep kernel # 输出如下 kernel-3.10.0-229.14.1.el7.x86_64 ","date":"2020-03-17","objectID":"/remove_kernel/:3:0","tags":["内核","卸载","Linux"],"title":"Linux卸载多余内核","uri":"/remove_kernel/"},{"categories":["linux"],"content":"3.删除旧内核的RPM包 yum remove kernel-3.10.0-229.14.1.el7 ","date":"2020-03-17","objectID":"/remove_kernel/:4:0","tags":["内核","卸载","Linux"],"title":"Linux卸载多余内核","uri":"/remove_kernel/"},{"categories":["linux"],"content":"4.重启系统 reboot 注意:不需要手动修改/boot/grub/menu.lst ","date":"2020-03-17","objectID":"/remove_kernel/:5:0","tags":["内核","卸载","Linux"],"title":"Linux卸载多余内核","uri":"/remove_kernel/"},{"categories":["linux"],"content":"Scenarios 在linux上我们常常会部署多个软件，从而需要多个运行环境；如有的需要python2，有的需要python3，这是我们就需要进行同一软件的多版本管理。 ","date":"2020-03-16","objectID":"/linux_multi_version_soft_manage/:1:0","tags":["多版本","软件管理"],"title":"linux下软件多版本管理","uri":"/linux_multi_version_soft_manage/"},{"categories":["linux"],"content":"Solution 以某版本hugo为例: opt └── myapp └── hugo ├── current -\u003e hugo_0.67.1/ └── hugo_0.67.1 ├── LICENSE ├── README.md └── hugo 其中, /opt/myapp 作为可选软件的存放目录, hugo 为某软件的总目录, hugo_xxx 为某具体版本目录, 多个版本就有多个目录; 如果要将某版本配置到系统PATH变量中, 方便使用, 则为其建立软链接如下: ln -s hugo_extended_0.67.1_Linux-64bit/ ./current 然后再将当前版本的 current/xxx 可执行文件软链接到系统的/usr/local/bin/xxx, 或将软件的current/bin/加到系统path变量 sudo ln -s current/hugo /usr/local/bin/ 或 sudo vim /etc/profile # 添加如下部分 PATH=$PATH:/opt/myapp/golang/current/bin export PATH ","date":"2020-03-16","objectID":"/linux_multi_version_soft_manage/:2:0","tags":["多版本","软件管理"],"title":"linux下软件多版本管理","uri":"/linux_multi_version_soft_manage/"},{"categories":["development kit"],"content":"应用场景 MongoDB采用No-Schema的方式，免去您变更表结构的痛苦，非常适用于初创型的业务需求。您可以将模式固定的结构化数据存储在RDS（Relational Database Service）中，模式灵活的业务存储在MongoDB中，高热数据存储在云数据库Memcache或云数据库Redis中，实现对业务数据高效存取，降低存储数据的投入成本。 ","date":"2020-03-14","objectID":"/mongodb/:1:0","tags":["MongoDB","Usage"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["development kit"],"content":"数据去重 image1pop \" image1 mongo中有如图所示的重复数据, 使用如下命令可去重: use dbname # 使用组合字段列表作为判重依据, 可添加多个字段 db.集合.aggregate([ { $group: { _id: {字段1: '$字段1',字段2: '$字段2'},count: {$sum: 1},dups: {$addToSet: '$_id'}} }, { $match: {count: {$gt: 1}} } ],{ allowDiskUse: true }).forEach(function(doc){ doc.dups.shift(); db.集合.remove({_id: {$in: doc.dups}}); }) 数据过多时, 可能导致内存溢出, allowDiskUse: true 选项可允许数据转存到硬盘; 注意: 此方法效率不高, 数据过多时不可使用此法, 而应该从插入数据的源头治理. Reference ","date":"2020-03-14","objectID":"/mongodb/:2:0","tags":["MongoDB","Usage"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["development kit"],"content":"集合导入与导出 mongoDB中的mongoexport工具可以把一个collection导出成JSON格式或CSV格式的文件. ","date":"2020-03-14","objectID":"/mongodb/:3:0","tags":["MongoDB","Usage"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["development kit"],"content":"导出 mongoexport -d dbname -c collectionname -o filename --type json/csv -f field # 示例 sudo mongoexport -d mongotest -c users -o /home/python/Desktop/mongoDB/users.json --type json -f \"_id,user_id,user_name,age,status\" 参数说明: -d ：数据库名 -c ：collection名 -o ：输出文件名 –type ： 输出格式，默认为json -f ：输出字段，如果-type为csv，则需要加上-f “字段名” ","date":"2020-03-14","objectID":"/mongodb/:3:1","tags":["MongoDB","Usage"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["development kit"],"content":"导入 mongoimport -d dbname -c collectionname --file filename --headerline --type json/csv -f field # 示例 sudo mongoimport -d mongotest -c users --file /home/mongodump/articles.json --type json 参数说明： -d ：数据库名 -c ：collection名 –type ：导入格式, 默认json -f ：导入字段名 –headerline ：如果导入的格式是csv，则可以使用第一行的标题作为导入的字段 –file ：要导入的文件 ","date":"2020-03-14","objectID":"/mongodb/:3:2","tags":["MongoDB","Usage"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["development kit"],"content":"数据库备份与恢复 ","date":"2020-03-14","objectID":"/mongodb/:4:0","tags":["MongoDB","Usage"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["development kit"],"content":"备份 mongodump -h dbhost -d dbname -o dbdirectory # 示例 sudo rm -rf /home/momgodump/ sudo mkdir -p /home/momgodump sudo mongodump -h 192.168.17.129:27017 -d itcast -o /home/mongodump/ 参数说明： -h: MongDB所在服务器地址，例如: 127.0.0.1，当然也可以指定端口号: 127.0.0.1:27017 -d: 需要备份的数据库实例，例如: test -o: 备份文件存放目录，例如: /home/mongodump/，当然该目录需要提前建立，这个目录里面存放该数据库实例的备份数据。 ","date":"2020-03-14","objectID":"/mongodb/:4:1","tags":["MongoDB","Usage"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["development kit"],"content":"恢复 mongorestore -h dbhost -d dbname --dir dbdirectory # 示例 mongorestore -h 192.168.17.129:27017 -d itcast_restore --dir /home/mongodump/itcast/ 参数说明： -h: MongDB所在服务器地址，例如: 127.0.0.1，当然也可以指定端口号: 127.0.0.1:27017 -d: 需要恢复的数据库实例，例如：test，当然这个名称也可以和备份时候的不一样，比如test2 –dir: 备份数据所在位置，例如：/home/mongodump/itcast/ –drop: 恢复的时候，先删除当前数据，然后恢复备份的数据。慎用！ Reference Reference(更详细选项) ","date":"2020-03-14","objectID":"/mongodb/:4:2","tags":["MongoDB","Usage"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["development kit"],"content":"可视化管理工具–studio3t Release the full power of MongoDB ","date":"2020-03-14","objectID":"/mongodb/:5:0","tags":["MongoDB","Usage"],"title":"MongoDB","uri":"/mongodb/"},{"categories":["development kit"],"content":"安装, 启动 # 拉取镜像, 默认使用latest标签 docker pull mongo # 查看镜像 docker images mongo # 启动一个MongoDB容器实例 docker run -itd --name mongo -p 27017:27017 mongo --auth 参数说明: -p 27017:27017 ：映射容器服务的 27017 端口到宿主机的 27017 端口。 –auth：开启mongo的安全验证。 -d: detach, 启动后分离终端, 让容器在后台运行。 -i: interactive, 交互式操作, 打开容器实例的标准输入, 直到脱离 -t: tty/teletypewriter, 分配一个模拟终端 ","date":"2020-03-14","objectID":"/mongodb_docker/:1:0","tags":["环境部署","MongoDB","Docker"],"title":"Docker 安装 MongoDB","uri":"/mongodb_docker/"},{"categories":["development kit"],"content":"创建用户管理员 # 连接到容器实例, 并运行其中的bash docker exec -it mongo bash # 连接mongo-shell(默认参数) mongo 在mongo-shell中进行以下操作 # 切换数据库(默认进入的是test库, 该库上不允许) use admin # 创建用户(用户管理员, 用户名/密码 请自行替换) db.createUser( { user: \"myUserAdmin\", pwd: \"123456\", roles: [ { role: \"userAdminAnyDatabase\", db: \"admin\" } ] } ) # 退出mongo-shell exit ","date":"2020-03-14","objectID":"/mongodb_docker/:2:0","tags":["环境部署","MongoDB","Docker"],"title":"Docker 安装 MongoDB","uri":"/mongodb_docker/"},{"categories":["development kit"],"content":"创建普通用户 # 连接到容器实例 docker exec -it mongo bash # 连接mongo-shell(默认参数) mongo 然后在mongo-shell中输入以下命令 # 切换数据库 use admin # 认证身份(需要切换到对应的库上, 否则认证会失败) db.auth(\"myUserAdmin\", \"123456\") # 创建普通用户(需要具有权限的用户) db.createUser( { user: \"myTester\", pwd: \"123456\", roles: [ { role: \"readWrite\", db: \"test\" }, { role: \"read\", db: \"reporting\" } ] } ) # 退出 mongo-shell exit ","date":"2020-03-14","objectID":"/mongodb_docker/:3:0","tags":["环境部署","MongoDB","Docker"],"title":"Docker 安装 MongoDB","uri":"/mongodb_docker/"},{"categories":["development kit"],"content":"删除用户 # 删除用户（需要使用具有权限的用户进行操作，比如用户管理员，超级管理员） use spider db.dropUser('spider') ","date":"2020-03-14","objectID":"/mongodb_docker/:4:0","tags":["环境部署","MongoDB","Docker"],"title":"Docker 安装 MongoDB","uri":"/mongodb_docker/"},{"categories":["development kit"],"content":"扩展–使用外部配置文件启动一个MongoDB容器实例 docker run --name some-mongo -v /my/custom:/etc/mongo -d mongo --config /etc/mongo/mongod.conf 参数说明: –config: 指定配置文件路径; -v: 映射目录; /my/custom 是容器外部配置文件所在目录; 由于mongod默认情况下不读取配置文件, 所以指定配置文件路径后, 还需要把外部配置文件所在目录映射到–config指定的目录; ","date":"2020-03-14","objectID":"/mongodb_docker/:5:0","tags":["环境部署","MongoDB","Docker"],"title":"Docker 安装 MongoDB","uri":"/mongodb_docker/"},{"categories":["development kit"],"content":"配置包管理系统（yum） 创建一个mongodb-org-4.0.repo文件，以便从MongoDB官方软件仓库安装。 cat \u003e /etc/yum.repos.d/mongodb-org-4.0.repo \u003c\u003c EOF [mongodb-org-4.0] name=MongoDB Repository baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/4.0/x86_64/ gpgcheck=1 enabled=1 gpgkey=https://www.mongodb.org/static/pgp/server-4.0.asc EOF ","date":"2020-03-14","objectID":"/mongodb_native/:1:0","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"安装、配置 # 安装最新版 sudo yum install -y mongodb-org # 配置selinux # 1.开放27017端口 semanage port -a -t mongod_port_t -p tcp 27017 # 启动 sudo systemctl start mongod.service # 查看是否启动 tail /var/log/mongodb/mongod.log # 停止 sudo systemctl stop mongod.service # 重启 sudo service mongod restart # 设置开机启动 sudo systemctl enable mongod.service # 禁止开机启动 sudo systemctl disable mongod.service ## 使用客户端shell连接 mongo --host 127.0.0.1:27017 ","date":"2020-03-14","objectID":"/mongodb_native/:2:0","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"使用 mongodb安装好以后，先创建用户管理员，然后才能创建其他用户 ","date":"2020-03-14","objectID":"/mongodb_native/:3:0","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"创建用户管理员(非超级管理员root) # 连接mongo shell mongo --host 127.0.0.1:27017 在mongo-shell输入以下命令 # 切换数据库 use admin # 创建用户(用户管理员, 用户名/密码 请自行替换) db.createUser( { user: \"myUserAdmin\", pwd: \"123456\", roles: [ { role: \"userAdminAnyDatabase\", db: \"admin\" } ] } ) # 退出mongo-shell exit ","date":"2020-03-14","objectID":"/mongodb_native/:3:1","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"开启安全验证 编辑配置文件 vi /etc/mongod.conf 找到如下选项, 修改为所示值后保存退出 # 开启身份认证 security: authorization: enabled 重新启动mongod进程 systemctl restart mongod.service ","date":"2020-03-14","objectID":"/mongodb_native/:4:0","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"创建普通用户 # 使用用户管理员登录（myUserAdmin用户只具有管理用户和角色的权限可以创建用户） mongo --port 27017 -u \"myUserAdmin\" -p '123456' --authenticationDatabase \"admin\" 然后在mongo-shell中输入以下命令 # 先创建/或切换到要创建用户的数据库 use test # 创建普通用户(需要具有权限的用户操作,如用户管理员,超级管理员) db.createUser( { user: \"myTester\", pwd: \"123456\", roles: [ { role: \"readWrite\", db: \"test\" }, { role: \"read\", db: \"reporting\" } ] } ) # 退出 mongo-shell exit 在上面这个实例中，用户被创建在test数据库上; 该库成为这个用户的身份验证数据库，用户登陆时需要必须在该库上进行身份验证; 但同时还给该用户分配了，其他数据库（reporting）的角色，使用户在其他数据库上也具有期望的权限。也就是说用户的权限不会局限在身份认证数据库上的 ","date":"2020-03-14","objectID":"/mongodb_native/:5:0","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"删除用户 # 删除用户（需要使用具有权限的用户进行操作，比如用户管理员，超级管理员） use spider db.dropUser('spider') ","date":"2020-03-14","objectID":"/mongodb_native/:6:0","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"普通用户登录 ","date":"2020-03-14","objectID":"/mongodb_native/:7:0","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"连接时认证 mongo --port 27017 -u \"myTester\" -p \"123456\" --authenticationDatabase \"test\" ","date":"2020-03-14","objectID":"/mongodb_native/:7:1","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"连接后认证 认证时, 需要切换到对应的库上, 否则认证会失败 mongo --port 27017 use test db.auth(\"myTester\", \"123456\" ) 然后就可以在你被授权的数据库上进行一些读写操作了 ","date":"2020-03-14","objectID":"/mongodb_native/:7:2","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"允许远程连接 编辑配置文件 vi /etc/mongod.conf 找到如下配置项, 并修改为所示值(经测试, 注释该项无效) bindIp 0.0.0.0 ","date":"2020-03-14","objectID":"/mongodb_native/:8:0","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"卸载 https://docs.mongodb.com/manual/tutorial/install-mongodb-on-red-hat/ ","date":"2020-03-14","objectID":"/mongodb_native/:9:0","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"注意事项 item Description 数据目录 /var/log/mongodb 日志目录 /var/lib/mongo 配置文件 /etc/mongod.conf 所以需要sudo启动 ","date":"2020-03-14","objectID":"/mongodb_native/:10:0","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"扩展阅读 在数据库中创建的第一个用户应该是具有管理其他用户的权限的用户管理员。 ","date":"2020-03-14","objectID":"/mongodb_native/:11:0","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"什么是认证数据库 添加用户时，可以在特定数据库中创建用户。该数据库是用户的认证的数据库 ","date":"2020-03-14","objectID":"/mongodb_native/:11:1","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["development kit"],"content":"认证用户 要进行身份验证，客户端必须对用户的身份验证数据库进行身份验证 权限模型 基于角色的授权方式 认证是验证用户的身份; 授权确定被验证的用户对哪些资源和操作的访问。 各数据库上的角色拥有各种对该库的各种访问权限 用户可以在各个库上担任角色 image1pop \" image1 ","date":"2020-03-14","objectID":"/mongodb_native/:11:2","tags":["环境部署","MongoDB","CentOS7"],"title":"CentOS7 安装 MongoDB","uri":"/mongodb_native/"},{"categories":["middleware"],"content":"Case 一个 mysql binlog 同步的系统，日同步数据要达到上亿. 用来将数据从一个 mysql 库原封不动地同步到另一个 mysql 库里面去（mysql -\u003e mysql）。 你在 mysql 里增删改一条数据，对应出来了增删改 3 条 binlog 日志，接着这三条 binlog 发送到 MQ 里面，再消费出来依次执行，必须保证他们的顺序. 原来是：增加、修改、删除；顺序错了给执行成删除、修改、增加, mysql执行得到的数据就是错的。 ","date":"2020-03-14","objectID":"/mq2/:1:0","tags":["消息队列","顺序性"],"title":"如何保证消息的顺序性","uri":"/mq2/"},{"categories":["middleware"],"content":"Scenarios ","date":"2020-03-14","objectID":"/mq2/:2:0","tags":["消息队列","顺序性"],"title":"如何保证消息的顺序性","uri":"/mq2/"},{"categories":["middleware"],"content":"RabbitMQ 一个 queue，多个 consumer. 比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者2先执行完操作，把 data2 存入数据库，然后是 data1/data3。这不明显乱了。 ","date":"2020-03-14","objectID":"/mq2/:2:1","tags":["消息队列","顺序性"],"title":"如何保证消息的顺序性","uri":"/mq2/"},{"categories":["middleware"],"content":"Kafka 一个 topic，一个 partition，一个 consumer(内部多线程). 生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。接着，我们在消费者里可能会搞多个线程来并发处理消息。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十 ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而多个线程并发跑的话，顺序可能就乱掉了。 ","date":"2020-03-14","objectID":"/mq2/:2:2","tags":["消息队列","顺序性"],"title":"如何保证消息的顺序性","uri":"/mq2/"},{"categories":["middleware"],"content":"Solution ","date":"2020-03-14","objectID":"/mq2/:3:0","tags":["消息队列","顺序性"],"title":"如何保证消息的顺序性","uri":"/mq2/"},{"categories":["middleware"],"content":"RabbitMQ 二选一: 拆分成多个 queue, 每个 queue 一个 consumer; 一个 queue, 一个 consumer, 该 consumer 内部用内存队列做排队, 然后分发给底层不同的 worker 来处理。 ","date":"2020-03-14","objectID":"/mq2/:3:1","tags":["消息队列","顺序性"],"title":"如何保证消息的顺序性","uri":"/mq2/"},{"categories":["middleware"],"content":"Kafka 一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。 写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。 ","date":"2020-03-14","objectID":"/mq2/:3:2","tags":["消息队列","顺序性"],"title":"如何保证消息的顺序性","uri":"/mq2/"},{"categories":["middleware"],"content":"总结 分析:其实并非所有的公司都有这种业务需求，但是还是对这个问题要有所复习。 回答:针对这个问题，通过某种算法，将需要保持先后顺序的消息放到同一个消息队列中(kafka中就是partition,rabbitMq中就是queue)。然后只用一个消费者去消费该队列。 有的人会问:那如果为了吞吐量，有多个消费者去消费怎么办？ 这个问题，没有固定回答的套路。比如我们有一个微博的操作，发微博、写评论、删除微博，这三个异步操作。如果是这样一个业务场景，那只要重试就行。 比如你一个消费者先执行了写评论的操作，但是这时候，微博都还没发，写评论一定是失败的，等一段时间。等另一个消费者，先执行写评论的操作后，再执行，就可以成功。 总之，针对这个问题，我的观点是保证入队有序就行，出队以后的顺序交给消费者自己去保证，没有固定套路。 ","date":"2020-03-14","objectID":"/mq2/:4:0","tags":["消息队列","顺序性"],"title":"如何保证消息的顺序性","uri":"/mq2/"},{"categories":["middleware"],"content":"Reference https://zhuanlan.zhihu.com/p/60166828 https://zhuanlan.zhihu.com/p/92622338 ","date":"2020-03-14","objectID":"/mq2/:5:0","tags":["消息队列","顺序性"],"title":"如何保证消息的顺序性","uri":"/mq2/"},{"categories":["middleware"],"content":"消息队列","date":"2020-03-13","objectID":"/mq1/","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"什么是消息队列 我们可以把消息队列比作是一个存放消息的容器, 当我们需要使用消息的时候可以取出消息供自己使用。消息队列是分布式系统中的重要组件, 使用消息队列主要是为了通过异步处理提高系统性能和削峰、降低系统耦合性。 ","date":"2020-03-13","objectID":"/mq1/:1:0","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"为什么要用消息队列 使用消息队列主要有以下好处： 解耦 异步 削峰 ","date":"2020-03-13","objectID":"/mq1/:2:0","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"解耦 利用消息队列实现事件驱动结构pop \" 利用消息队列实现事件驱动结构 传统模式 系统间耦合性太强，如果系统A在代码中直接调用系统B和系统C的代码，将来D系统接入，系统A还需要修改代码，过于麻烦！ 中间件模式 将消息写入消息队列，需要消息的系统自己从消息队列中订阅，从而系统A不需要做任何修改。如果模块之间不存在直接调用，那么新增模块或者修改模块就对其他模块影响较小. ","date":"2020-03-13","objectID":"/mq1/:2:1","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"异步 传统模式 一些非必要的业务逻辑以同步的方式运行，太耗费时间。 中间件模式 将消息写入消息队列，非必要的业务逻辑以异步的方式运行，加快响应速度 ","date":"2020-03-13","objectID":"/mq1/:2:2","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"削峰 传统模式 并发量大的时候，所有的请求直接怼到数据库，造成数据库连接异常 中间件模式 系统A慢慢的按照数据库能处理的并发量，从消息队列中慢慢拉取消息。在生产中，这个短暂的高峰期积压是允许的。 ","date":"2020-03-13","objectID":"/mq1/:2:3","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"使用消息队列带来的问题 系统可用性降低 系统可用性在某种程度上降低，在加入MQ之前，你不用考虑消息丢失或者说MQ挂掉等等的情况，但是，引入MQ之后你就需要去考虑了！ 系统复杂性提高 加入MQ之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！ 一致性问题 消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了! ","date":"2020-03-13","objectID":"/mq1/:3:0","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"JMS VS AMQP item JMS AMQP 定义 Java API规范 协议 跨语言 否 是 跨平台 否 是 支持模式 1. p2p; 2. pub/sub; 1. direct exchange; 2. fanout exchange; 3. topic exchange; 4. headers exchange; 5. system exchange; 本质上讲,后4种与jms的pub/sub模式没有太大差别 支持消息类型 支持多种类型 byte 总结: AMQP 为消息定义了线路层（wire-level protocol）的协议，而JMS所定义的是API规范。在 Java 体系中，多个client均可以通过JMS进行交互，不需要应用修改代码，但是其对跨平台的支持较差。而AMQP天然具有跨平台、跨语言特性。 JMS 支持TextMessage、MapMessage 等复杂的消息类型；而 AMQP 仅支持 byte[] 消息类型（复杂的类型可序列化后发送）。 由于Exchange 提供的路由算法，AMQP可以提供多样化的路由方式来传递消息到消息队列，而 JMS 仅支持 队列 和 主题/订阅 方式两种。 使用JMS需要相应的API实现方, 如 ActiveMQ; 使用AMQP需要选择基于AMQP协议实现的产品, 如 RabbitMQ; ","date":"2020-03-13","objectID":"/mq1/:4:0","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"常见消息队列对比 特性 ActiveMQ RabbitMQ Kafka RocketMQ producer-comsumer 支持 支持 支持 支持 publish-subscribe 支持 支持 支持 支持 request-reply 支持 支持 - 支持 API完备性 高 高 高 低（静态配置） 多语言支持 支持，JAVA优先 语言无关 支持，JAVA优先 支持 单机呑吐量 万级 万级 十万级 十万级 消息延迟 - 微秒级 毫秒级 - 可用性 高（主从） 高（主从） 非常高（分布式） 高 消息丢失 - 低 理论上不会丢失 - 消息重复 - 可控制 理论上会有重复 - 文档的完备性 高 高 高 中 提供快速入门 有 有 有 无 首次部署难度 - 低 中 高 注: - 表示尚未查找到准确数据 ","date":"2020-03-13","objectID":"/mq1/:5:0","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"消息队列选型 从上面对比可知: 中小型软件公司，建议选RabbitMQ 一方面，erlang语言天生具备高并发的特性，而且他的管理界面用起来十分方便。 正所谓，成也萧何，败也萧何！他的弊端也在这里，虽然RabbitMQ是开源的，然而国内有几个能定制化开发erlang的程序员呢？ 所幸，RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug，这点对于中小型公司来说十分重要。 不考虑rocketmq和kafka的原因是，一方面中小型软件公司不如互联网公司，数据量没那么大，选消息中间件，应首选功能比较完备的，所以kafka排除。 不考虑rocketmq的原因是，rocketmq是阿里出品，如果阿里放弃维护rocketmq，中小型公司一般抽不出人来进行rocketmq的定制化开发，因此不推荐。 大型软件公司，根据具体使用在rocketMq和kafka之间二选一 一方面，大型软件公司，具备足够的资金搭建分布式环境，也具备足够大的数据量。 针对rocketMQ,大型软件公司也可以抽出人手对rocketMQ进行定制化开发，毕竟国内有能力改JAVA源码的人，还是相当多的。 至于kafka，根据业务场景选择，如果有日志采集功能，肯定是首选kafka了。具体该选哪个，看使用场景。 ","date":"2020-03-13","objectID":"/mq1/:6:0","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"如何保证消息队列服务的高可用性 高可用的根本解决方案: 冗余; 以rcoketMQ为例，他的集群就有多master 模式、多master多slave异步复制模式、多 master多slave同步双写模式。 多master多slave模式部署架构图pop \" 多master多slave模式部署架构图 ","date":"2020-03-13","objectID":"/mq1/:7:0","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"如何防止消息重复消费 即保证消息队列的幂等性, 这个需要根据具体的业务场景来分析并给出解决方案. ","date":"2020-03-13","objectID":"/mq1/:8:0","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"重复消费产生的原因 正常情况下，消费者在消费完毕一个消息后，会发送一个确认信息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。只是不同的消息队列发送的确认信息形式不同.例如RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka是提交消息的offset. 无论哪种消息队列，造成重复消费的原因都是类似的: 因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道已经消费过该消息了，再次将该消息分发给其他的消费者。 ","date":"2020-03-13","objectID":"/mq1/:8:1","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"解决方案 需要结合具体的业务场景. 拿到消息做数据库的insert操作 给每个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。 拿到消息做redis的set的操作 不用解决。因为你无论set几次结果都是一样的，set操作本来就算幂等操作。 其他场景 使用第三方来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。 ","date":"2020-03-13","objectID":"/mq1/:8:2","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"如何保证消息传输的可靠性 从三个角度分析: 生产者丢数据; 消息队列丢数据; 消费者丢数据; ","date":"2020-03-13","objectID":"/mq1/:9:0","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"RabbitMQ 生产者丢数据 RabbitMQ 提供 transaction和confirm模式来确保生产者不丢消息。 transaction机制就是说，发送消息前，开启事务(channel.txSelect())，然后发送消息，如果发送过程中出现什么异常，事务就会回滚(channel.txRollback())，如果发送成功则提交事务(channel.txCommit())。 缺点就是吞吐量下降了。因此，按照博主的经验，生产上用confirm模式的居多。 一旦channel进入confirm模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始) 一旦消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个Ack给生产者(包含消息的唯一ID) 这就使得生产者知道消息已经正确到达目的队列了.如果rabiitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。 处理Ack和Nack的代码如下所示: channel.addConfirmListener(new ConfirmListener()){ @Override public void handleNack(long deliveryTag, boolean multiple) throws IOException { System.out.println(\"nack: deliveryTag = \" + deliveryTag + \" multiple: \" + multiple); } @Override public void handleAck(long deliveryTag, boolean multiple) throws IOException { System.out.println(\"ack: deliveryTag = \" + deliveryTag + \" multiple: \" + multiple); } }); 消息队列丢数据 开启持久化磁盘的配置。 这个持久化配置可以和防止生产者丢数据的confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。 这样，如果消息持久化磁盘之前，rabbitMQ挂了，那么生产者收不到Ack信号，生产者会自动重发。 持久化只需: 将queue的持久化标识durable设置为true, 则代表是一个持久的队列 发送消息的时候将deliveryMode=2 这样设置以后，rabbitMQ就算挂了，重启后也能恢复数据. 消费者丢数据 手动确认消息. 消费者丢数据一般是因为采用了自动确认消息模式。 这种模式下，消费者会自动确认收到信息。这时rahbitMQ会立即将消息删除，如果后续消费者出现异常而没能处理该消息，就会丢失该消息。 ","date":"2020-03-13","objectID":"/mq1/:9:1","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"Kafka Producer在发布消息到某个Partition时，先通过ZooKeeper找到该Partition的Leader, 然后无论该Topic的Replication Factor为多少（也即该Partition有多少个Replica），Producer只将该消息发送到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower都从Leader中pull数据。 生产者丢数据 在kafka生产中，基本都有一个leader和多个follwer。follwer会去同步leader的信息。针对这种情况，做如下配置: 在producer端设置acks=all。这个配置保证了，follwer同步完成后，才认为消息发送成功。 在producer端设置retries=MAX，一旦写入失败，这无限重试 消息队列丢数据 消息队列丢数据的情况，无外乎就是，数据还没同步，leader就挂了，这时zookpeer会将其他的follwer切换为leader,那数据就丢失了。针对这种情况，做如下配置: replication.factor 参数大于1，即要求每个partition必须有至少2个副本 min.insync.replicas 参数大于1，即要求一个leader至少感知到有至少一个follower还跟自己保持联系 这两个配置加上上面生产者的配置联合起来用，基本可确保kafka不丢数据 消费者丢数据 这种情况一般是自动提交了offset(offset：指的是kafka的topic中的每个消费组消费的下标。)，kafka以为你处理好了, 然后你处理过程中程序挂了。 简单的来说就是一条消息对应一个offset下标，每次消费数据的时候如果提交offset，那么下次消费就会从提交的offset加一那里开始消费。比如一个topic中有100条数据，我消费了50条并且提交了，那么此时的kafka服务端记录提交的offset就是49(offset从0开始)，那么下次消费的时候offset就从50开始消费。 改为手动提交即可. ","date":"2020-03-13","objectID":"/mq1/:9:2","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"如何保证消息的顺序性 通过某种算法，将需要保持先后顺序的消息放到同一个消息队列中(kafka中就是partition,rabbitMq中就是queue)。然后只用一个消费者去消费该队列。 如果为了吞吐量，有多个消费者去消费怎么办？这种场景需要具体业务具体分析. 针对这个问题，我的观点是保证入队有序就行，出队以后的顺序交给消费者自己去保证，没有固定套路。 后续文章会介绍两个特定场景下的保证消息顺序性的解决方案, 供读者参考. ","date":"2020-03-13","objectID":"/mq1/:10:0","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["middleware"],"content":"Reference https://zhuanlan.zhihu.com/p/52773169 https://zhuanlan.zhihu.com/p/84007327 ","date":"2020-03-13","objectID":"/mq1/:11:0","tags":["消息队列"],"title":"message queue","uri":"/mq1/"},{"categories":["development kit"],"content":"centos7 安装docker-ce(社区免费版) Reference ","date":"2020-03-13","objectID":"/docker_native/:1:0","tags":["环境部署","docker"],"title":"CentOS7 安装 Docker","uri":"/docker_native/"},{"categories":["development kit"],"content":"从centos7官方软件仓库安装 使用centos7官方软件仓库 # 添加企业linux扩展软件仓库(Extra Packages for Enterprise Linux),并更新仓库缓存 sudo yum install -y epel-release \u0026\u0026 yum update # 查看库中dockr软件包信息 yum info docker 输出如下: 已加载插件：fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com 可安装的软件包 名称 ：docker 架构 ：x86_64 时期 ：2 版本 ：1.13.1 发布 ：96.gitb2f74b2.el7.centos 大小 ：18 M 源 ：extras/7/x86_64 简介 ： Automates deployment of containerized applications 网址 ：https://github.com/docker/docker 协议 ： ASL 2.0 描述 ： Docker is an open-source engine that automates the deployment of any : application as a lightweight, portable, self-sufficient container that will : run virtually anywhere. : : Docker containers can encapsulate any payload, and will run consistently on : and between virtually any server. The same container that a developer builds : and tests on a laptop will run at scale, in production*, on VMs, bare-metal : servers, OpenStack clusters, public instances, or combinations of the above. 可以看到比较老了, 而且centos7中基本不会更新docker版本了 # 安装docker sudo yum install -y docker # 启动 Docker 后台服务 sudo systemctl start docker # 测试运行 hello-world sudo docker run hello-world ","date":"2020-03-13","objectID":"/docker_native/:1:1","tags":["环境部署","docker"],"title":"CentOS7 安装 Docker","uri":"/docker_native/"},{"categories":["development kit"],"content":"从docker官方软件仓库安装(版本较新) # 卸载从centos官方仓库安装的docker sudo yum autoremove docker -y 使用docker官方软件仓库 如果你禁用了默认开启的centos-extras仓库,请重新启用它. # (可选)卸载老版本 sudo yum remove -y docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine # 安装一些工具软件 sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 # 添加稳定版docker官方软件源 sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo # 更新软件仓库缓存 sudo yum makecache fast # 安装docker-ce及相关软件 sudo yum install -y docker-ce docker-ce-cli containerd.io # 启动docker守护进程 sudo systemctl start docker # 验证安装 sudo docker run hello-world 卸载从docker官方仓库安装的docker-ce # 卸载软件 sudo yum remove -y docker-ce # 删除相关镜像/容器/数据卷 sudo rm -rf /var/lib/docker 使用国内的docker镜像仓库(网易镜像) sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u003c\u003c-'EOF' { \"registry-mirrors\": [\"http://hub-mirror.c.163.com\"] } EOF # 重新加载相关信息,重启docker sudo systemctl daemon-reload sudo systemctl restart docker 以非root 身份管理docker # 添加docker用户组 sudo groupadd docker # 向用户组添加用户(以foo用户为例) sudo usermod -aG docker foo # 注销并重新登录 exit # 重新登录后, 执行以下命令验证是否生效 docker run hello-world 开机启动docker # 设置开机启动 sudo systemctl enable docker # 禁止开机启动 sudo systemctl disable docker ","date":"2020-03-13","objectID":"/docker_native/:1:2","tags":["环境部署","docker"],"title":"CentOS7 安装 Docker","uri":"/docker_native/"},{"categories":["development kit"],"content":"Debian10 安装docker-ce(社区免费版) Reference 使用docker官方软件仓库 sudo apt-get remove docker docker-engine docker.io containerd runc sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg2 \\ software-properties-common curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add - sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/debian \\ $(lsb_release -cs)\\ stable\" sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io sudo docker run hello-world ","date":"2020-03-13","objectID":"/docker_native/:2:0","tags":["环境部署","docker"],"title":"CentOS7 安装 Docker","uri":"/docker_native/"},{"categories":["development kit"],"content":"fedora30 安装docker-ce(社区免费版) Reference 使用docker官方软件仓库 # 卸载老版本 sudo dnf remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine # 设置docker官方repository（stable版本） sudo dnf -y install dnf-plugins-core sudo dnf config-manager \\ --add-repo \\ https://download.docker.com/linux/fedora/docker-ce.repo # 安装docker-ce sudo dnf install docker-ce docker-ce-cli containerd.io # 启动docker sudo systemctl start docker # 验证安装是否成功 sudo docker run hello-world ","date":"2020-03-13","objectID":"/docker_native/:3:0","tags":["环境部署","docker"],"title":"CentOS7 安装 Docker","uri":"/docker_native/"},{"categories":["development kit"],"content":"docker-mysql-8.x 安装文档 参考链接 ","date":"2020-03-13","objectID":"/mysql_docker/:0:0","tags":["环境部署","mysql"],"title":"Docker 安装 MySQL","uri":"/mysql_docker/"},{"categories":["development kit"],"content":"拉取镜像(不加tag则拉取最新版本) docker pull mysql ","date":"2020-03-13","objectID":"/mysql_docker/:1:0","tags":["环境部署","mysql"],"title":"Docker 安装 MySQL","uri":"/mysql_docker/"},{"categories":["development kit"],"content":"(可选)在宿主机上创建 将要映射到容器中的目录 及 自定义mysql配置文件.cnf # 数据卷目录 DOCKER_V_MYSQL_DIR=/opt/docker_v/mysql sudo mkdir -p $DOCKER_V_MYSQL_DIR sudo chmod 777 -R $DOCKER_V_MYSQL_DIR mkdir -p $DOCKER_V_MYSQL_DIR/conf mkdir -p $DOCKER_V_MYSQL_DIR/logs mkdir -p $DOCKER_V_MYSQL_DIR/data touch $DOCKER_V_MYSQL_DIR/conf/my.cnf ","date":"2020-03-13","objectID":"/mysql_docker/:2:0","tags":["环境部署","mysql"],"title":"Docker 安装 MySQL","uri":"/mysql_docker/"},{"categories":["development kit"],"content":"运行容器 指定数据卷目录的参考5.x,因为该文档实在windows版docker上实践, 故没有使用数据卷 不指定数据卷目录 docker run -p 3306:3306 \\ --name mysql \\ -e MYSQL_ROOT_PASSWORD=123456 \\ -d \\ mysql ","date":"2020-03-13","objectID":"/mysql_docker/:3:0","tags":["环境部署","mysql"],"title":"Docker 安装 MySQL","uri":"/mysql_docker/"},{"categories":["development kit"],"content":"配置远程登陆 修改后可能需要刷新权限信息 # 进入容器 docker exec -it mysql bash # 登录mysql mysql -u root -p # 修改root密码(可选,推荐) ALTER USER 'root'@'localhost' IDENTIFIED BY '654321'; # 给root添加远程的登录权限(可选,不推荐) GRANT ALL PRIVILEGES ON *.* TO 'root'@'%'; # 添加远程登录用户(推荐) CREATE USER 'foo'@'%' IDENTIFIED WITH mysql_native_password BY '123456'; GRANT ALL PRIVILEGES ON *.* TO 'foo'@'%'; ","date":"2020-03-13","objectID":"/mysql_docker/:4:0","tags":["环境部署","mysql"],"title":"Docker 安装 MySQL","uri":"/mysql_docker/"},{"categories":["development kit"],"content":"命令说明 -p 3306:3306：将容器的 3306 端口映射到主机的 3306 端口。 -v -v $PWD/conf:/etc/mysql/conf.d：将主机当前目录下的 conf/my.cnf 挂载到容器的 /etc/mysql/my.cnf。 -v $PWD/logs:/logs：将主机当前目录下的 logs 目录挂载到容器的 /logs。 -v $PWD/data:/var/lib/mysql ：将主机当前目录下的data目录挂载到容器的 /var/lib/mysql 。 -e MYSQL_ROOT_PASSWORD=123456：初始化 root 用户的密码。 docker-mysql-5.x 安装文档 参考链接 ","date":"2020-03-13","objectID":"/mysql_docker/:5:0","tags":["环境部署","mysql"],"title":"Docker 安装 MySQL","uri":"/mysql_docker/"},{"categories":["development kit"],"content":"拉取镜像(不加tag则拉取最新版本) docker pull mysql:5.7 ","date":"2020-03-13","objectID":"/mysql_docker/:6:0","tags":["环境部署","mysql"],"title":"Docker 安装 MySQL","uri":"/mysql_docker/"},{"categories":["development kit"],"content":"(可选)在宿主机上创建 将要映射到容器中的目录 及 自定义mysql配置文件.cnf # 数据卷目录 DOCKER_V_MYSQL_DIR=/opt/docker_v/mysql sudo mkdir -p $DOCKER_V_MYSQL_DIR sudo chmod 777 -R $DOCKER_V_MYSQL_DIR mkdir -p $DOCKER_V_MYSQL_DIR/conf mkdir -p $DOCKER_V_MYSQL_DIR/logs mkdir -p $DOCKER_V_MYSQL_DIR/data touch $DOCKER_V_MYSQL_DIR/conf/my.cnf ","date":"2020-03-13","objectID":"/mysql_docker/:7:0","tags":["环境部署","mysql"],"title":"Docker 安装 MySQL","uri":"/mysql_docker/"},{"categories":["development kit"],"content":"运行容器 docker run -p 3306:3306 --name mysql57 \\ -v $DOCKER_V_MYSQL_DIR/conf:/etc/mysql/conf.d \\ -v $DOCKER_V_MYSQL_DIR/logs:/logs \\ -v $DOCKER_V_MYSQL_DIR/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=123456 \\ -d \\ mysql:5.7 ","date":"2020-03-13","objectID":"/mysql_docker/:8:0","tags":["环境部署","mysql"],"title":"Docker 安装 MySQL","uri":"/mysql_docker/"},{"categories":["development kit"],"content":"CentOS7-Redis-4.x 安装 ","date":"2020-03-13","objectID":"/redis_native/:0:0","tags":["环境部署","redis"],"title":"CentOS7 安装 Redis","uri":"/redis_native/"},{"categories":["development kit"],"content":"yum 包管理器安装 该软件包在 epel-release 需要先安装该软件存储库, centos7.5目前是3.2版本, 不是很新 # 安装redis yum -y install redis # 启动redis systemctl restart redis.service # 查看状态 systemctl status redis.service # 设置redis开机启动 systemctl enable redis.service # 测试 redis-cli ","date":"2020-03-13","objectID":"/redis_native/:1:0","tags":["环境部署","redis"],"title":"CentOS7 安装 Redis","uri":"/redis_native/"},{"categories":["development kit"],"content":"设置redis密码 # 编辑配置文件 sudo vi /etc/redis.conf 找到被注释的# requirepass foobared, 去掉前面的#, 并把foobared改成你的密码。如: # requirepass foobared 改为 requirepass 123456 ","date":"2020-03-13","objectID":"/redis_native/:2:0","tags":["环境部署","redis"],"title":"CentOS7 安装 Redis","uri":"/redis_native/"},{"categories":["development kit"],"content":"更改配置文件的位置 redis.conf文件默认在/etc目录下, 你可以更改它的位置和名字 更改后, 注意在文件/usr/lib/systemd/system/redis.service中, 把ExecStart=/usr/bin/redis-server /etc/redis/6379.conf --daemonize no中的xxx.conf的路径改成的新的路径。 ","date":"2020-03-13","objectID":"/redis_native/:3:0","tags":["环境部署","redis"],"title":"CentOS7 安装 Redis","uri":"/redis_native/"},{"categories":["development kit"],"content":"编译安装redis-4.x ","date":"2020-03-13","objectID":"/redis_native/:4:0","tags":["环境部署","redis"],"title":"CentOS7 安装 Redis","uri":"/redis_native/"},{"categories":["development kit"],"content":"文件夹准备,(可根据需要自行更改) # 装备安装目录 sudo mkdir /opt/myapp sudo chown -R yangzhaoyunfei:yangzhaoyunfei /opt/myapp sudo chmod -R 755 /opt/myapp # 或执行 sudo chmod -R u=rwx,g=rx,o=rx /opt/myapp # 添加一个目录专门用作自定义path,避免修改系统path sudo mkdir /opt/path sudo chown -R yangzhaoyunfei:yangzhaoyunfei /opt/path sudo chmod -R 755 /opt/path ll /opt # 获取最新的redis稳定版,并解压,查看 wget -c http://download.redis.io/releases/redis-stable.tar.gz \u0026\u0026 tar -zxf redis-stable.tar.gz \u0026\u0026 ls # 安装依赖 sudo yum groupinstall 'Development Tools' sudo yum install tcl wget # 编译安装 cd redis-stable/ make distclean \u0026\u0026 make \u0026\u0026 make test \u0026\u0026 make PREFIX=/opt/myapp/redis install # 创建redis_6379服务,会有一些选项要求选择,配置文件位置也会告诉你/etc/redis/6379.conf # 备注,脚本添加服务时,redis可执行文件要选择服务端文件: /opt/myapp/redis/bin/redis-server cd utils sudo ./install_server.sh # 启动, 如果要设置密码, 先修改下面的配置文件后在启动 systemctl daemon-reload sudo systemctl restart redis_6379 # 开机启动 sudo systemctl enable redis_6379 # 创建软链接 sudo ln -s /opt/myapp/redis/bin/redis-server /opt/path/redis-server sudo ln -s /opt/myapp/redis/bin/redis-cli /opt/path/redis-cli 注意 运行配置脚本以后会生成这个文件,使用以下命令打开该文件,进行查看: sudo vi /etc/init.d/redis_6379 部分内容如下: EXEC=/opt/myapp/redis/bin/redis-server CLIEXEC=/opt/myapp/redis/bin/redis-cli PIDFILE=/var/run/redis_6379.pid CONF=\"/etc/redis/6379.conf\" REDISPORT=\"6379\" AUTH=\"123456\" # 如果设置了密码时要加入这个选项, 不然会导致centos系统启动失败, 启动卡顿等问题 # 还要在如下部分中加上上买了定义的 AUTH 变量 stop) if [ ! -f $PIDFILE ] then echo \"$PIDFILEdoes not exist, process is not running\" else PID=$(cat $PIDFILE) echo \"Stopping ...\" $CLIEXEC -p $REDISPORT -a $AUTH shutdown ","date":"2020-03-13","objectID":"/redis_native/:4:1","tags":["环境部署","redis"],"title":"CentOS7 安装 Redis","uri":"/redis_native/"},{"categories":["development kit"],"content":"docker-rabbitmq-latest 安装文档 参考链接 ","date":"2020-03-13","objectID":"/rabbitmq_docker/:0:0","tags":["环境部署","rabbitmq"],"title":"Docker 安装 RabbitMQ","uri":"/rabbitmq_docker/"},{"categories":["development kit"],"content":"拉取镜像(不加tag则拉取最新版本) docker pull rabbitmq:management # 查看镜像 docker images rabbitmq:management ","date":"2020-03-13","objectID":"/rabbitmq_docker/:1:0","tags":["环境部署","rabbitmq"],"title":"Docker 安装 RabbitMQ","uri":"/rabbitmq_docker/"},{"categories":["development kit"],"content":"运行容器 ","date":"2020-03-13","objectID":"/rabbitmq_docker/:2:0","tags":["环境部署","rabbitmq"],"title":"Docker 安装 RabbitMQ","uri":"/rabbitmq_docker/"},{"categories":["development kit"],"content":"不指定配置文件 docker run -d \\ --name rabbitmq \\ -p 5672:5672 \\ -p 15672:15672 \\ rabbitmq:management ","date":"2020-03-13","objectID":"/rabbitmq_docker/:2:1","tags":["环境部署","rabbitmq"],"title":"Docker 安装 RabbitMQ","uri":"/rabbitmq_docker/"},{"categories":["development kit"],"content":"访问管理界面 可以使用默认的账户登录, 用户名和密码都是 guest http://[宿主机IP]:15672, 如： http://localhost:15672 ","date":"2020-03-13","objectID":"/rabbitmq_docker/:2:2","tags":["环境部署","rabbitmq"],"title":"Docker 安装 RabbitMQ","uri":"/rabbitmq_docker/"},{"categories":["development kit"],"content":"docker-redis-latest 安装文档 参考链接 ","date":"2020-03-13","objectID":"/redis_docker/:0:0","tags":["环境部署","redis"],"title":"Docker 安装 Redis","uri":"/redis_docker/"},{"categories":["development kit"],"content":"拉取镜像(不加tag则拉取最新版本) docker pull redis # 查看镜像 docker images redis ","date":"2020-03-13","objectID":"/redis_docker/:1:0","tags":["环境部署","redis"],"title":"Docker 安装 Redis","uri":"/redis_docker/"},{"categories":["development kit"],"content":"(可选)在宿主机上创建 将要映射到容器中的目录 及 自定义mysql配置文件.cnf # 数据卷目录 DOCKER_V_DATA_DIR=/opt/docker_v/redis sudo mkdir -p $DOCKER_V_DATA_DIR sudo chmod 777 -R $DOCKER_V_DATA_DIR mkdir -p $DOCKER_V_DATA_DIR/data mkdir -p $DOCKER_V_DATA_DIR/conf touch $DOCKER_V_DATA_DIR/conf/my.cnf ","date":"2020-03-13","objectID":"/redis_docker/:2:0","tags":["环境部署","redis"],"title":"Docker 安装 Redis","uri":"/redis_docker/"},{"categories":["development kit"],"content":"运行容器 ","date":"2020-03-13","objectID":"/redis_docker/:3:0","tags":["环境部署","redis"],"title":"Docker 安装 Redis","uri":"/redis_docker/"},{"categories":["development kit"],"content":"不指定配置文件 # 如果没有指定数据卷, 这里不要 -v 选项 docker run -d \\ -p 6379:6379 \\ --name redis_nopasswd \\ -v $DOCKER_V_DATA_DIR:/data \\ redis:latest \\ redis-server --appendonly yes ","date":"2020-03-13","objectID":"/redis_docker/:3:1","tags":["环境部署","redis"],"title":"Docker 安装 Redis","uri":"/redis_docker/"},{"categories":["development kit"],"content":"指定配置文件 # 如果没有指定数据卷, 这里不要 -v 选项 docker run -d \\ -p 6379:6379 \\ --name redis \\ -v $DOCKER_V_DATA_DIR:/data \\ -v $DOCKER_V_DATA_DIR/conf/my.cnf:/usr/local/etc/redis/redis.conf \\ redis:latest \\ redis-server --appendonly yes \\ /usr/local/etc/redis/redis.conf ","date":"2020-03-13","objectID":"/redis_docker/:3:2","tags":["环境部署","redis"],"title":"Docker 安装 Redis","uri":"/redis_docker/"},{"categories":["development kit"],"content":"命令说明 命令说明： -d : (--detach)脱离shell, 后台运行容器,并打印容器id -p 6379:6379 : 将容器的6379端口映射到主机的6379端口 -v $DOCKER_V_DATA_DIR/data:/data : 将主机中指定目录下的data挂载到容器的/data redis-server --appendonly yes : 在容器执行redis-server启动命令, 并打开redis持久化配置 ","date":"2020-03-13","objectID":"/redis_docker/:4:0","tags":["环境部署","redis"],"title":"Docker 安装 Redis","uri":"/redis_docker/"},{"categories":["development kit"],"content":"可视化管理工具 redis-desktop-manager 非订阅版下载地址 订阅版下载地址 ","date":"2020-03-13","objectID":"/redis_docker/:5:0","tags":["环境部署","redis"],"title":"Docker 安装 Redis","uri":"/redis_docker/"},{"categories":["development kit"],"content":"常用命令 # 启动容器 docker start mysql57 # 停止容器 docker stop mysql57 # 查看运行中容器 docker ps # 查看所有容器 docker ps -a # 在运行的容器中运行命令--连接容器,并在其中运行某命令(redis-cli) docker exec -it redis redis-cli # 启动docker时启动某容器 docker run mysql57 --restart always # 从容器拷贝文件到宿主机(在宿主机上执行,无需启动容器) docker cp mycontainer:/opt/test/file.txt /opt/test/ # 从宿主机拷贝文件到容器(在宿主机上执行,无需启动容器) docker cp /opt/test/file.txt mycontainer:/opt/test/ ","date":"2020-03-13","objectID":"/docker_command/:0:0","tags":["环境部署","docker"],"title":"Docker 常用命令","uri":"/docker_command/"},{"categories":["development kit"],"content":"常用选项 -i, –interactive Attach container’s STDIN -t, –tty Allocate a pseudo-TTY -p -v ","date":"2020-03-13","objectID":"/docker_command/:1:0","tags":["环境部署","docker"],"title":"Docker 常用命令","uri":"/docker_command/"},{"categories":["development kit"],"content":"推送镜像到repository docker tag local-image:tagname new-repo:tagname docker push new-repo:tagname Make sure to change tagname with your desired image repository tag. ","date":"2020-03-13","objectID":"/docker_command/:2:0","tags":["环境部署","docker"],"title":"Docker 常用命令","uri":"/docker_command/"},{"categories":["distributed system"],"content":"接口幂等性的实现方案讨论","date":"2020-03-06","objectID":"/idempotence/","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"分布式系统中接口的幂等性 ","date":"2020-03-06","objectID":"/idempotence/:0:0","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"前言 幂等与你是不是分布式高并发还有JavaEE都没有关系, 关键是你的接口提供的操作是不是幂等的。 幂等性是分布式系统设计中十分重要的概念, 具有这一性质的接口在设计时总是秉持这样的一种理念： 调用接口发生异常并且重复尝试时, 总是会造成系统所无法承受的损失, 所以必须阻止这种现象的发生。 ","date":"2020-03-06","objectID":"/idempotence/:1:0","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"场景 对于业务中需要考虑幂等性的地方一般都是接口的重复请求, 重复请求是指同一个请求因为某些原因被多次提交, 导致产生重复数据或数据不一致（假定程序业务代码没问题）。导致这种情况会有几种场景： 前端重复提交：提交订单, 用户快速重复点击多次, 造成后端生成多个内容重复的订单。 接口超时重试：对于给第三方调用的接口, 为了防止网络抖动或其他原因造成请求丢失, 这样的接口一般都会设计成超时重试多次。 消息重复消费：MQ消息中间件, 消息重复消费。 单体架构下同样要避免重复请求, 但在单体架构转成微服务架构之后, 以上问题变得尤为突出。 为了解决以上问题, 就需要保证接口的幂等性, 接口的幂等性实际上就是接口可重复调用, 在调用方多次调用的情况下, 接口最终得到的结果是一致的。有些接口可以天然的实现幂等性, 比如查询接口, 对于查询来说, 你查询一次和两次, 对于系统来说, 没有任何影响, 查出的结果也是一样。 ","date":"2020-03-06","objectID":"/idempotence/:2:0","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"幂等的概念 幂等（idempotent、idempotence）是一个数学与计算机学概念, 常见于抽象代数中。 在编程中.一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数, 或幂等方法, 是指可以使用相同参数重复执行, 并能获得相同结果的函数。这些函数不会影响系统状态, 也不用担心重复执行会对系统造成改变。例如, “getUsername()和setTrue()“函数就是一个幂等函数. 更复杂的操作幂等保证是利用唯一交易号(流水号)实现. 我的理解：幂等就是一个操作, 不论执行多少次, 产生的效果和返回的结果都是一样的 老顾的理解应该是多次调用对系统的产生的影响是一样的, 即对资源的作用是一样的, 但是返回值允许不同。 幂等性是分布式系统设计中十分重要的概念, 具有这一性质的接口在设计时总是秉持这样的一种理念：调用接口发生异常并且重复尝试时, 总是会造成系统所无法承受的损失, 所以必须阻止这种现象的发生。 ","date":"2020-03-06","objectID":"/idempotence/:3:0","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"各类操作的幂等性 在编程中主要操作就是CURD, 其中读取（Retrieve）操作和删除（Delete）操作是天然幂等的, 受影响的就是创建（Create）、更新（Update）。 查询操作 在数据不变的情况下, 查询一次和查询多次, 查询结果是一样的；查询具有天然的幂等性。 删除操作 删除一次和多次删除的结果都是把数据删除, 对资源的作用都是一样的(注意可能返回结果不一样, 首次删除时, 返回成功；再次删除时, 数据不存在, 返回0)； 更新操作 更新在大多场景下结果一样,但是如果是增量修改是需要保证幂等性的,如下例子: 把表中id为XXX的记录的A字段值设置为1,这种操作不管执行多少次都是幂等的 把表中id为XXX的记录的A字段值增加1,这种操作就不是幂等的 新增操作 增加在重复提交的场景下会出现幂等性问题, 比如同一订单创建多次。 ","date":"2020-03-06","objectID":"/idempotence/:4:0","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"实现接口幂等的技术方案 ","date":"2020-03-06","objectID":"/idempotence/:5:0","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"全局唯一ID 适用场景：全局唯一ID是一个通用方案, 可以支持插入、更新、删除业务操作；但是这个方案看起来很美但是实现起来比较麻烦。 使用全局唯一ID, 就是根据业务的操作和内容生成一个全局ID, 在执行操作前先根据这个全局唯一ID是否存在, 来判断这个操作是否已经执行。如果不存在则把全局ID, 存储到存储系统中, 比如数据库、redis等。如果存在则表示该方法已经执行。 从工程的角度来说, 使用全局ID做幂等可以作为一个业务的基础微服务存在, 在很多的微服务中都会用到这样的服务。另外打造一个高可靠的幂等服务还需要考虑很多问题, 比如一台机器虽然把全局ID先写入了存储, 但是在写入之后挂了, 这就需要引入全局ID的超时机制。 使用, 下面的方案适用于特定的场景, 但是实现起来比较简单。 ","date":"2020-03-06","objectID":"/idempotence/:5:1","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"数据库去重表 适用场景：业务中具有唯一标识的插入场景中, 如新增类接口等； 比如在以上的支付场景中, 如果一个订单只会支付一次, 所以订单ID可以作为唯一标识。这时, 我们就可以建一张去重表, 并且把唯一标识作为唯一索引, 在我们实现时, 把创建支付单据和写入去重表, 放在一个事务中, 如果重复创建, 数据库会抛出唯一约束异常, 操作就会回滚。 例如博客点赞问题, 要想防止一个人重复点赞, 可以设计一张表, 将博客id与用户id绑定建立唯一索引, 每当用户点赞时就往表中写入一条数据, 这样重复点赞的数据就无法写入。 ","date":"2020-03-06","objectID":"/idempotence/:5:2","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"多版本控制 适用场景：更新场景; 多版本并发控制, 乐观锁的一种实现, 在数据更新时需要去比较持有数据的版本号, 版本号不一致的操作无法成功. 比如我们要更新商品的名字, 这时我们就可以在更新的接口中增加一个版本号, 来做幂等: boolean updateGoodsName(int id,String newName,int version); 在实现时可以如下: update goods set name=#{newName},version=#{version} where id=#{id} and version\u003c${version} ","date":"2020-03-06","objectID":"/idempotence/:5:3","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"状态机控制 适用场景：适合在有状态流转的情况下, 每个状态都有前置状态和后置状态, 以及最后的结束状态。 例如流程的待审批, 审批中, 驳回, 重新发起, 审批通过, 审批拒绝。订单的待提交, 待支付, 已支付, 取消。 以订单为例, 已支付的状态的前置状态只能是待支付, 而取消状态的前置状态只能是待支付, 通过这种状态机的流转我们就可以控制请求的幂等。 public enum OrderStatusEnum { UN_SUBMIT(0, 0, \"待提交\"), UN_PADING(0, 1, \"待支付\"), PAYED(1, 2, \"已支付待发货\"), DELIVERING(2, 3, \"已发货\"), COMPLETE(3, 4, \"已完成\"), CANCEL(0, 5, \"已取消\"), ; //前置状态 private int preStatus; //当前状态值 private int status; //状态描述 private String desc; OrderStatusEnum(int preStatus, int status, String desc) { this.preStatus = preStatus; this.status = status; this.desc = desc; } //... } 假设当前状态是已支付, 这时候如果支付接口又接收到了支付请求, 则会抛异常或拒绝此次处理。在做状态机更新时, 我们就这可以这样控制, 使其只能按指定方向流转： update `order` set status=#{status} where id=#{id} and status\u003c#{status} ","date":"2020-03-06","objectID":"/idempotence/:5:4","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"token机制 适用场景：防止重复提交等。 注意：redis要用删除操作来判断token, 删除成功代表token校验通过, 如果用select+delete来校验token, 存在并发问题, 不建议使用 注意：Token防重复提交, 只需要网关这层控制即可；Token的处理机制, 还需要缓存调用的处理结果, 以判断是否需要放行后续的重试请求； 主要流程就是： 服务端提供了发送token的接口。我们在分析业务的时候, 哪些业务是存在幂等问题的, 就必须在执行业务前, 先去获取token, 服务器会先把token保存到redis中。（集群环境用redis, 单机就用jvm缓存或redis）。 然后调用业务接口请求时, 把token携带过去, 一般放在请求头部。 服务器判断token是否存在redis中, 存在表示第一次请求, 可以继续执行业务, 执行业务完成后, 最后需要把redis中的token删除。 如果判断token不存在redis中, 就表示是重复操作, 直接返回重复标记给client, 这样就保证了业务代码, 不被重复执行。 以电商平台为例子, 电商平台上的订单id就是最适合的token。 ","date":"2020-03-06","objectID":"/idempotence/:5:5","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"对外提供接口的api如何保证幂等 如银联提供的付款接口：需要接入商户提交付款请求时附带：source来源, seq序列号 source+seq在数据库里面做唯一索引, 防止多次付款, (并发时, 只能处理一个请求) 重点： 对外提供接口为了支持幂等调用, 接口有两个字段必须传, 一个是来源source, 一个是来源方序列号seq, 这个两个字段在提供方系统里面做联合唯一索引, 这样当第三方调用时, 先在本方系统里面查询一下, 是否已经处理过, 返回相应处理结果；没有处理过, 进行相应处理, 返回结果。注意, 为了幂等友好, 一定要先查询一下, 是否处理过该笔业务, 不查询直接插入业务系统, 会报错, 但实际已经处理了。 ","date":"2020-03-06","objectID":"/idempotence/:6:0","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"测试方案 通过下面的方法可以初步验证接口幂等性的健壮性： 同一个请求, 多次提交到同一台节点, 多次提交到不同的节点 同一个请求, 同时到达同一个节点, 同时到达到不同的节点 有逻辑先后顺序的消息、请求乱序的处理, 比如创建订单的请求和支付订单的请求, 不能保证第一个请求先于第二个请求到达服务器； ","date":"2020-03-06","objectID":"/idempotence/:7:0","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"总结 幂等就是要使接口具备抵御重复请求对系统带来的破坏。 可以采取的方案有： UUID——通用 去重表——新增场景 多版本控制——增量更新场景 状态机——带状态流转的更新场景 token机制——防止数据重复提交等场景 source + seq序列号——对外api 乐观锁、悲观锁、分布式锁——既可以控制并发, 也可以防止长流程中多个重复请求操作一个对象。 ","date":"2020-03-06","objectID":"/idempotence/:8:0","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["distributed system"],"content":"声明 本菜鸡并未参与过分布式高并发系统的开发, 该文只是学习记录, 特此声明, 轻喷。 看到网上还有不少教程列举了, 乐观锁, 悲观锁, 分布式锁之类的方案, 我想这应该是属于并发控制的范围, 不属于幂等实现方案。如果理解有误, 请大神不吝评论指正。 参考链接 https://blog.csdn.net/WANGYAN9110/article/details/70953273 https://blog.csdn.net/xichenguan/article/details/78085801 https://juejin.im/post/5ceb4c4f51882572a206d174 https://blog.csdn.net/rdhj5566/article/details/50646599 https://www.jianshu.com/p/475589f5cd7b ","date":"2020-03-06","objectID":"/idempotence/:9:0","tags":["微服务","分布式","幂等"],"title":"分布式系统中接口的幂等性","uri":"/idempotence/"},{"categories":["working"],"content":"合理工作","date":"2020-02-29","objectID":"/996/","tags":["996","加班","劳动法"],"title":"WLB","uri":"/996/"},{"categories":["working"],"content":"案例 如何看待 36 岁清华毕业 IT 男马桶上猝死，死前对母亲说「太累」？ - 知乎 https://www.zhihu.com/question/29357990 如何看待『前端大神』司徒正美离世的消息？ - 知乎 https://www.zhihu.com/question/384157840 某码农长期久坐加班，突发腰痛住院十天。 案例过多，不宜展示 ","date":"2020-02-29","objectID":"/996/:1:0","tags":["996","加班","劳动法"],"title":"WLB","uri":"/996/"},{"categories":["working"],"content":"。。。 只有健康或者才是对家人的负责。公司少了你，默哀一分钟，招个人继续干，家庭少了你，就是塌了天。 工作的目的是为了让生活变好，而不是失去生活。 ","date":"2020-02-29","objectID":"/996/:2:0","tags":["996","加班","劳动法"],"title":"WLB","uri":"/996/"},{"categories":["encyclopedia"],"content":"什么是闰年","date":"2020-02-15","objectID":"/leap-year/","tags":["leap year"],"title":"闰年","uri":"/leap-year/"},{"categories":["encyclopedia"],"content":"闰年 闰年(Leap Year)是为了弥补因人为历法规定造成的年度天数与地球实际公转周期的时间差而设立的。 公历中分闰年和平年, 平年有365天, 而闰年有366天（2月中多一天）； 普通闰年:公历年份是4的倍数的, 且不是100的倍数, 为闰年。（如2004年就是闰年）； 世纪闰年:公历年份是整百数的, 必须是400的倍数才是世纪闰年（如1900年不是世纪闰年, 2000年是世纪闰年）； 最根本的原因是：地球绕太阳运行周期为365天5小时48分46秒（合365.24219天）即一回归年（tropical year）。公历的平年只有365日, 比回归年短约0.2422 日, 所余下的时间约为每四年累计一天, 故第四年于2月末加1天, 使当年的历年长度为366日, 这一年就为闰年。 现行公历中每400年有97个闰年。按照每四年一个闰年计算, 平均每年就要多算出0.0078天, 这样经过四百年就会多算出大约3天来。因此每四百年中要减少三个闰年。所以公历规定：年份是整百数时, 必须是400的倍数才是闰年；不是400的倍数的世纪年, 即使是4的倍数也不是闰年。 这就是通常所说的：四年一闰, 百年不闰, 四百年再闰。 例如, 2000年是闰年, 2100年则是平年。 ","date":"2020-02-15","objectID":"/leap-year/:0:0","tags":["leap year"],"title":"闰年","uri":"/leap-year/"},{"categories":["成人教育"],"content":"学历提升指导","date":"2020-02-14","objectID":"/educational-1/","tags":["学历提升","专科","本科","专本连读","成人教育"],"title":"专本套读指南--1 前言","uri":"/educational-1/"},{"categories":["成人教育"],"content":"学历提升 写这篇文章的初衷是某个朋友向我征求学历提升的建议, 所以整理了一套方案供其参考。 种一棵树最好的时间就是十年前, 还有现在。 愿有梦想的人, 都能梦想成真。 另外, 我们的关系已经破裂了。 ","date":"2020-02-14","objectID":"/educational-1/:0:0","tags":["学历提升","专科","本科","专本连读","成人教育"],"title":"专本套读指南--1 前言","uri":"/educational-1/"},{"categories":["成人教育"],"content":"目前我国成人教育提升学历有以下几种方式 含金量和考试难度依次递减： 自学考试 成人高考 远程教育 开放大学（前身为电大） ","date":"2020-02-14","objectID":"/educational-1/:1:0","tags":["学历提升","专科","本科","专本连读","成人教育"],"title":"专本套读指南--1 前言","uri":"/educational-1/"},{"categories":["成人教育"],"content":"远程/网络教育大专耗时情况 高起专学制 2.5 年, 学习期限 2.5-5 年。所以最快 2.5 年申请毕业。 ","date":"2020-02-14","objectID":"/educational-1/:2:0","tags":["学历提升","专科","本科","专本连读","成人教育"],"title":"专本套读指南--1 前言","uri":"/educational-1/"},{"categories":["成人教育"],"content":"自考本科耗时情况 自考一般顺利的话, 一年半即可考完所有科目, 一般两年多就可以拿到毕业证。 自考本科每次你报考四门, 每门一次过关, 课程一般是 13-15 门课, 有的地方一年考四次, 像浙江省现在一年考二次, 如果你学习复习好, 一年就至少可以过8门课。 ","date":"2020-02-14","objectID":"/educational-1/:3:0","tags":["学历提升","专科","本科","专本连读","成人教育"],"title":"专本套读指南--1 前言","uri":"/educational-1/"},{"categories":["成人教育"],"content":"专本套读 ","date":"2020-02-14","objectID":"/educational-1/:4:0","tags":["学历提升","专科","本科","专本连读","成人教育"],"title":"专本套读指南--1 前言","uri":"/educational-1/"},{"categories":["成人教育"],"content":"什么是专本套读 在报考自考本科时不需要提供专科毕业证, 只有在自考本科申请毕业时才需要提供。 也就是说, 专科在读的同时, 套读一个自考本科 两者同时进行, 但需在本科毕业之前拿到专科毕业证。 专本套读时间线加载失败! \" 专本套读时间线 如上图所示, 在专本套读时, 专科课程的学习时间与本科课程的学习时间重叠。 常见的方式为： 通过远程考试或开放大学获得专科学历, 再搭配含金量比较高且报考时不需要提供学历证明的自考本科获得本科学历。 ","date":"2020-02-14","objectID":"/educational-1/:4:1","tags":["学历提升","专科","本科","专本连读","成人教育"],"title":"专本套读指南--1 前言","uri":"/educational-1/"},{"categories":["成人教育"],"content":"专本套读的三种形式 成考大专 + 自考本科—-2.5年 专科毕业 + 推后半年申请本科 = 3年 网教大专 + 自考本科—-2.5年 专科毕业 + 推后半年申请本科 = 3年 自考大专 + 自考本科—-1年 申请大专 + 推后半年申请本科 = 1.5年 统招大专 + 自考本科—-1年 申请本科 = 1年 开放大专 + 自考本科； ","date":"2020-02-14","objectID":"/educational-1/:4:2","tags":["学历提升","专科","本科","专本连读","成人教育"],"title":"专本套读指南--1 前言","uri":"/educational-1/"},{"categories":["成人教育"],"content":"各形式区别 可爱的图片标题(●'◡'●)加载失败! \" 可爱的图片标题(●'◡'●) ","date":"2020-02-14","objectID":"/educational-1/:4:3","tags":["学历提升","专科","本科","专本连读","成人教育"],"title":"专本套读指南--1 前言","uri":"/educational-1/"},{"categories":["成人教育"],"content":"专本套读得特点 时间短 对于很多想要提升学历的人来说, 时间是一个问题, 经常有很多学生, 要短时间拿到本科学历。但是如果按部就班的话, 拿到国家认可本科学历, 需要5年时间。专本套读整整缩短了一半时间。 难度降低 其实自考的时间是最快的了, 如果一个人的能力够强的话, 可以专科本科都选择自考, 自考的难度, 我相信很多人都清楚。而专本套读同样是将难度缩小一半。 费用低 专本套读时, 专科选择电大、远程教育、成考, 本科选择自考、同时拿到专本科学历, 费用可控。 ","date":"2020-02-14","objectID":"/educational-1/:4:4","tags":["学历提升","专科","本科","专本连读","成人教育"],"title":"专本套读指南--1 前言","uri":"/educational-1/"},{"categories":["成人教育"],"content":"各种毕业证样本 统招全日制毕业证 统招全日制毕业证加载失败! \" 统招全日制毕业证 自学考试毕业证 自学考试毕业证加载失败! \" 自学考试毕业证 网络教育毕业证 网络教育毕业证加载失败! \" 网络教育毕业证 成人高考毕业证 成人高考毕业证加载失败! \" 成人高考毕业证 开放大学毕业证 开放大学毕业证加载失败! \" 开放大学毕业证 ","date":"2020-02-14","objectID":"/educational-1/:5:0","tags":["学历提升","专科","本科","专本连读","成人教育"],"title":"专本套读指南--1 前言","uri":"/educational-1/"},{"categories":["成人教育"],"content":"其他 自考通常一年有四次考试机会, 最快一年半可以考完, 两年拿证。 详细流程见之后专题。 ","date":"2020-02-14","objectID":"/educational-1/:6:0","tags":["学历提升","专科","本科","专本连读","成人教育"],"title":"专本套读指南--1 前言","uri":"/educational-1/"},{"categories":["Input Method"],"content":"击键爱好者常用社区","date":"2020-02-13","objectID":"/input-method-community/","tags":["community","input method"],"title":"Input Method Community","uri":"/input-method-community/"},{"categories":["Input Method"],"content":"击键爱好者常用社区 ","date":"2020-02-13","objectID":"/input-method-community/:0:0","tags":["community","input method"],"title":"Input Method Community","uri":"/input-method-community/"},{"categories":["Input Method"],"content":"编码方案 【声笔系列码】(群号445906697) 【西风瘦码】(群号15571505) 【真码输入法】(群号192524731) ","date":"2020-02-13","objectID":"/input-method-community/:1:0","tags":["community","input method"],"title":"Input Method Community","uri":"/input-method-community/"},{"categories":["Input Method"],"content":"练习工具 【极速跟打器】(群号139711547) ","date":"2020-02-13","objectID":"/input-method-community/:2:0","tags":["community","input method"],"title":"Input Method Community","uri":"/input-method-community/"},{"categories":["Input Method"],"content":"竞技交流 【指爱(打字/提速)】(群号49269560) ","date":"2020-02-13","objectID":"/input-method-community/:3:0","tags":["community","input method"],"title":"Input Method Community","uri":"/input-method-community/"},{"categories":["Input Method"],"content":"在rime平台上使用西风瘦码","date":"2020-02-12","objectID":"/xfsm/","tags":["Input Method","rime","西风瘦码"],"title":"西风瘦码-rime配置","uri":"/xfsm/"},{"categories":["Input Method"],"content":"西风瘦码的rime输入法配置 ","date":"2020-02-12","objectID":"/xfsm/:0:0","tags":["Input Method","rime","西风瘦码"],"title":"西风瘦码-rime配置","uri":"/xfsm/"},{"categories":["Input Method"],"content":"演示环境 操作系统：windows10专业版1909 输入法软件：rime-0.14.3 输入方案：西风瘦码原版 ","date":"2020-02-12","objectID":"/xfsm/:1:0","tags":["Input Method","rime","西风瘦码"],"title":"西风瘦码-rime配置","uri":"/xfsm/"},{"categories":["Input Method"],"content":"下载rime 下载地址. ","date":"2020-02-12","objectID":"/xfsm/:2:0","tags":["Input Method","rime","西风瘦码"],"title":"西风瘦码-rime配置","uri":"/xfsm/"},{"categories":["Input Method"],"content":"获取输入方案 点击链接加入群聊【西风瘦码】：https://jq.qq.com/?_wv=1027\u0026k=5E8i2YT 我使用的是自己修改的原版瘦码：原版瘦码自用方案 ","date":"2020-02-12","objectID":"/xfsm/:3:0","tags":["Input Method","rime","西风瘦码"],"title":"西风瘦码-rime配置","uri":"/xfsm/"},{"categories":["Input Method"],"content":"安装rime 图片标题加载失败! \" 图片标题 ","date":"2020-02-12","objectID":"/xfsm/:4:0","tags":["Input Method","rime","西风瘦码"],"title":"西风瘦码-rime配置","uri":"/xfsm/"},{"categories":["Input Method"],"content":"打开用户文件夹 切换到rime后, 右击状态栏图标, 打开菜单-用户文件夹 step 1加载失败 \" step 1 step 2加载失败 \" step 2 step 3加载失败 \" step 3 ","date":"2020-02-12","objectID":"/xfsm/:5:0","tags":["Input Method","rime","西风瘦码"],"title":"西风瘦码-rime配置","uri":"/xfsm/"},{"categories":["Input Method"],"content":"部署瘦码方案 将方案文件放入用户文件夹中, 其中没有选中的是无关文件 step 4加载失败 \" step 4 右击状态栏图标, 重新部署, 维护中的提示结束后即部署完成 step 5加载失败 \" step 5 按默认键F4呼出方案菜单, 选择瘦码即可使用 step 6加载失败 \" step 6 ","date":"2020-02-12","objectID":"/xfsm/:6:0","tags":["Input Method","rime","西风瘦码"],"title":"西风瘦码-rime配置","uri":"/xfsm/"},{"categories":["Input Method"],"content":"友情链接 点击链接加入群聊【真码输入法】：https://jq.qq.com/?_wv=1027\u0026k=55NuYXm ","date":"2020-02-12","objectID":"/xfsm/:7:0","tags":["Input Method","rime","西风瘦码"],"title":"西风瘦码-rime配置","uri":"/xfsm/"},{"categories":["Input Method"],"content":"问题 初次写作, 发现截图尺寸没有标准, 不美观, 以后改进。 ","date":"2020-02-12","objectID":"/xfsm/:8:0","tags":["Input Method","rime","西风瘦码"],"title":"西风瘦码-rime配置","uri":"/xfsm/"},{"categories":null,"content":"关于网站 学习笔记, 欢迎交流。 关于我 🎂1993年生人 👨‍💻半路出家的码农 💻技术宅, 喜欢研究计算机的东西 🤪强迫症与拖延症患者 ❤️爱好数学、物理、历史、文学、金融 职场感悟 行业对大龄开发不友好, 加班风气对身体的损耗也极大, 对个人、家庭生活的侵占较严重; 即使一直保持学习, 也无法保证大龄之后能找到满意的工作.资本无情，早做打算。 关于生活 ","date":"2019-12-01","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"案例 如何看待 36 岁清华毕业 IT 男马桶上猝死，死前对母亲说「太累」？ - 知乎 https://www.zhihu.com/question/29357990 如何看待『前端大神』司徒正美离世的消息？ - 知乎 https://www.zhihu.com/question/384157840 某码农长期久坐加班，突发腰痛住院十天。 案例过多，不宜展示 只有健康活着才是对家人的负责。公司少了你，默哀一分钟，招个人继续干；家庭少了你，就是塌了天。 工作的目的是为了让生活变好，而不是失去生活，期望大家都以健康的方式工作。 关于版权 本站所有的原创文章均受 [创作共享 署名-非商业性 4.0 许可协议 / CC BY-NC 4.0 保护]: https://creativecommons.org/licenses/by-nc/4.0/ 。 任何个人及媒体在转载本站原创内容（包含文字、自制图像、摄影作品）时请遵守以下版权要求： 注明转载 注明来源为本站首页网址 ([yangzhaoyunfei.github.io]: https://yangzhaoyunfei.github.io/), 或所转内容在本站的完整网址 本站图片, 除原创作品之外, 多数来自互联网。 此类图片的原版权所有者可在任何时候、以任何理由要求本站停止使用有关图片, 其中包括被本站编辑（比如加注中文说明）过的图片, 联系方式见本站首页。 免责声明 本站所有内容仅作学习记录之用，对使用本站内容、代码等导致的任何结果本人概不负责。 ","date":"2019-12-01","objectID":"/about/:1:0","tags":null,"title":"关于","uri":"/about/"},{"categories":["公务员考试"],"content":"公考数量关系学习笔记","date":"2019-12-01","objectID":"/number_relation/","tags":["公考","数量关系","技巧"],"title":"数量关系","uri":"/number_relation/"},{"categories":["公务员考试"],"content":"数量关系-1 ","date":"2019-12-01","objectID":"/number_relation/:0:0","tags":["公考","数量关系","技巧"],"title":"数量关系","uri":"/number_relation/"},{"categories":["公务员考试"],"content":"三大方法 代入排除法 数字特性法 方程法 ","date":"2019-12-01","objectID":"/number_relation/:1:0","tags":["公考","数量关系","技巧"],"title":"数量关系","uri":"/number_relation/"},{"categories":["公务员考试"],"content":"六大题型 工程问题 行程问题 经济利润 高频几何问题 容斥原理 排列组合与概率 分期付：居中代入, 付余法 多数排列求最值：最大代入 将总人数分为 a、b 两部分, 给出比例 a：b、总人数的范围, 结合倍数去做. ","date":"2019-12-01","objectID":"/number_relation/:2:0","tags":["公考","数量关系","技巧"],"title":"数量关系","uri":"/number_relation/"},{"categories":["公务员考试"],"content":"题型 。通常判定整数倍优先看 3 和 9，是命题老师比较习惯考查的点 小数转分数 A 占其它数总和的 m/N，则 A 占所有数总和的 m/（N+m）。将占部分量的比转化为占所有量的比。 ax+by=M，当 a 或 b 与 M 有公因子（公约数）时，考虑倍数特性 都有公因子时找大的，因为需要排除选项 用短除法找公因子（最大公因子） 不定方程组中有无穷组解，但是答案是唯一的，说 明从无穷组解中随便挑一组特殊的解出来，答案还是唯一的，即取哪组解和答案无关 效率比不变可以更高效做题. 按照组数工作的题目，思考的效率是按照组数来做题的。 ","date":"2019-12-01","objectID":"/number_relation/:3:0","tags":["公考","数量关系","技巧"],"title":"数量关系","uri":"/number_relation/"},{"categories":["公务员考试"],"content":"公考资料分析笔记","date":"2019-11-30","objectID":"/data_alnasys/","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"概述 资料分析几乎都可以估算, 所以掌握速算技巧很重要 资料分析1-技巧 除法：截尾估算 比较：分子分母同大同小与否；同大同小, 则竖看、横看找倍数关系明显的；都不明显的, 直接除, 看商位。四个选项的, 除, 看首位, 两个选项的, 技巧比较大小 ","date":"2019-11-30","objectID":"/data_alnasys/:0:0","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"速算技巧 错位相加x1.1, 错位相减x0.9； 截位直除 选项差距大, 暴露2位有效数字 选项差距小, 保留3位~ 选项差距大的两种：首位不同；首位同, 次位差大于首位 截位采用 四舍五入 原则 一步除法, 截分母, 好除； 多步除法, 分子分母截, 好除； 选项有10倍上数量级, 要注意小数点和位数, 否则不需要注意。 分数比较 一大一小, 分子大的较大 同大同小, 竖着直接除, 看首位 横着比倍数, 谁大谁牛皮, 小的看成1 四个分数比大小, 直接除大致看范围, 2+, 3+… ","date":"2019-11-30","objectID":"/data_alnasys/:1:0","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"阅读技巧 文字材料, 三要素, 时间, 关键词, 数据；关键在于找到每段的关键词 图表材料看表头, 三要素：时间、主体、单位 饼形图构成原则, 12点方向顺时针 ","date":"2019-11-30","objectID":"/data_alnasys/:2:0","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"基期、现期 公式： 现期=基期×(1+r) 现期=基期+增长量 速算：|r|\u003e5%, 截位直除, |r|\u003c5%；方法：化除为乘 化除为乘的应用条件：求基期, 选项差距小, |r|\u003c5%, r下降的时候用, 不好除, 好乘; 变号, 开括号； 资料分析-2-增长率问题 ","date":"2019-11-30","objectID":"/data_alnasys/:3:0","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"常规增长率 识别： 公式：增长量/基期；速算技巧：直除等； 比较： 当 现/基 倍数关系明显时, 直接除比较首位； 当 现/基 不明显时, 可用 增长量/基期, 然后比较分数； 倍数=增长率+1 遇番数, 化倍数；1番=2；2番=4；3番=8；4番=16 ","date":"2019-11-30","objectID":"/data_alnasys/:4:0","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"间隔增长率 识别：一般隔一年, 如2017-2018-2019；求2019相对于2017年增长率；2017为基期, 2019为现期； 计算：r=r1+r2+r1*r2 速算：当r1,r2均小于10%时, r1*r2可忽略, 不能忽略是保留一位有效数字即可估算, 化百分为小数。 题型： 求间隔增长率 求间隔倍数：间隔增长率+1 求间隔基期：现期/(1+r隔) ","date":"2019-11-30","objectID":"/data_alnasys/:5:0","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"年均增长率 识别： 公式：(1+r)^n=现/基 速算： 比较时, n相同, 直接比 现/基 计算时, 根据选项居中整数带入, 算出数据跟已知数据比较 题型： 2006-2010, 基期2006, 现期2010, 年份差4 十一五, (2006-2010), 基期2006-1, 现期2010, 年份差5 ","date":"2019-11-30","objectID":"/data_alnasys/:6:0","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"混合增长率 识别：比例混合类问题 计算：线段法 速算：线段长度与分母成反比 资料分析3-增长量问题 识别： 公式： * 增长量=现期-基期 * 增长量=基期*r=[现期/(1+r)]*r 速算：尾数法, 百化分 ","date":"2019-11-30","objectID":"/data_alnasys/:7:0","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"年均增长量 识别： 公式：年均增长量=(现期-基期)/年份差 注意：“十一五\"基期要往前推一年 ","date":"2019-11-30","objectID":"/data_alnasys/:8:0","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"已知现期、增长率, 求增长量 如果增长率 x% 可化为|r|=1/n,则： * 增长量Δ=现期/(n+1); * 减少量Δ=现期/(n-1) ","date":"2019-11-30","objectID":"/data_alnasys/:9:0","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"百化分技巧 ","date":"2019-11-30","objectID":"/data_alnasys/:10:0","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"比较增长量 已知现期、基期, 比较增长量：比较差值（数据形式） 或 高度差（柱形图） 已知现期、增长率, 比较增长量, 口诀：大大则大（第一个\"大\"指现期大, 第二个\"大\"指增长率大, 第 三个\"大\"指增长量大）, 一大一小百化分 比较倍数 ","date":"2019-11-30","objectID":"/data_alnasys/:11:0","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"比重 比重=部分/总体 总体=部分/比重 部分=总体*比重 ","date":"2019-11-30","objectID":"/data_alnasys/:12:0","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"现期比重 比重=部分/总体 利润率=利润/收入 增长贡献率=部分增长量/总体增长量 ","date":"2019-11-30","objectID":"/data_alnasys/:12:1","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"基期比重 条件：已知部分及总体的现期量、增长率 基期比重=(P/S)*((1+rs)/(1+rp)), 其中P,S为部分、总体现期量数据, rs,rp为部分、总体现期增长率 ","date":"2019-11-30","objectID":"/data_alnasys/:12:2","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"两期比重 比较大小 识别： 遇到两期比重比较, 看rp(部分增速)、rs(总体增速)的大小： rp\u003ers,今年比重上升 rp\u003crs,今年比重下降 rp=rs,今年比重不变 知识点：利润率=利润/收入, 也是比重的一种。两个年份+比重+上升/下降, 判断题型为两期比重比较问题, 看 a、b 的大小 两期比重差 现期比重-基期比重=(P/S)*[(rp-rs)/(1+rp)] 速算： * （1）判方向：a＞b, 上升；a＜b, 下降。 * （2）定大小：小于|a-b|。 ","date":"2019-11-30","objectID":"/data_alnasys/:12:3","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["公务员考试"],"content":"倍数 普通求倍数 已知两数据A、B的现期量、增长率, 求基期时A、B的倍数关系 现期倍数 基期倍数 倍数与增长率的关系 平均数 削峰填谷法 ","date":"2019-11-30","objectID":"/data_alnasys/:13:0","tags":["公考","资料分析","技巧"],"title":"资料分析","uri":"/data_alnasys/"},{"categories":["Quick Start"],"content":"Guide to writing usage in Hugo","date":"2019-10-01","objectID":"/quick-start/","tags":["usage"],"title":"Quick Start","uri":"/quick-start/"},{"categories":["Quick Start"],"content":"新建一篇文章 进入网站文件夹的根目录。 cd ~/xxx-blog # \"xxx-blog\" 为网站文件夹名。 使用以下命令新建一篇文章。 hugo new posts/my-first-post.md # \"my-first-post.md\" 是新建文章的文件名。 编辑新建的文章, 添加内容并保存。 ","date":"2019-10-01","objectID":"/quick-start/:1:0","tags":["usage"],"title":"Quick Start","uri":"/quick-start/"},{"categories":["Quick Start"],"content":"本地预览网站效果 启动 Hugo server。 hugo server 使用浏览器打开 http://localhost:1313 预览。 ","date":"2019-10-01","objectID":"/quick-start/:2:0","tags":["usage"],"title":"Quick Start","uri":"/quick-start/"},{"categories":["Quick Start"],"content":"构建网站 在 Hugo 网站文件夹的根目录下, 执行 hugo 命令来构建。 hugo 注意：Hugo 会将构建的网站内容默认保存至网站根目录的 public/ 文件夹中。 ","date":"2019-10-01","objectID":"/quick-start/:3:0","tags":["usage"],"title":"Quick Start","uri":"/quick-start/"},{"categories":["Quick Start"],"content":"部署网站 将网站根目录下的public/文件夹中的内容发布到你的web服务器 这里是推送到xxx.github.io仓库 ","date":"2019-10-01","objectID":"/quick-start/:4:0","tags":["usage"],"title":"Quick Start","uri":"/quick-start/"},{"categories":["Quick Start"],"content":"网站地址 https://yangzhaoyunfei.github.io ","date":"2019-10-01","objectID":"/quick-start/:5:0","tags":["usage"],"title":"Quick Start","uri":"/quick-start/"},{"categories":["Quick Start"],"content":"自动化部署 在GitHub上创建一个（例如shell-blog）存储库 使用如下命令将创建的hugo项目关联到shell-blog仓库 hugo new site shell-bolg # 创建一个新项目 启动 hugo server 确认内容无误后, 停止 hugo server, 删除public目录, 重新构建/或创建public目录,并git init 它,创建首次提交,然后使用下面的命令将其添加为子模块. 使用下列命令将hugo 项目下的 public 目录关联到 gitpage的仓库 # 这个git子模块将会与hugo项目使用不同的远程仓库, 并互不影响 git submodule add -b master https://github.com/yangzhaoyunfei/yangzhaoyunfei.github.io.git public # 或 git submodule add -b master git@github.com:yangzhaoyunfei/yangzhaoyunfei.github.io.git public 在hugo项目根目录（shell-blog/）创建添加自动部署脚本deploy.sh, deploy.bat格式需自行修改 #!/bin/sh # If a command fails then the deploy stops set -e printf \"Deploying updates to GitHub...\" # Build the project. hugo # if using a theme, replace with `hugo -t \u003cYOURTHEME\u003e` # Go To Public folder cd public # Add changes to git. git add . # Commit changes. msg=\"rebuilding site $(date)\" if [ -n \"$*\" ]; then msg=\"$*\" fi git commit -m \"$msg\" # Push source and build repos. git push origin master 然后您可以运行./deploy.sh “Your optional commit message\"将更改发送到.github.io, 几分钟之后就可以刷新查看了。 ","date":"2019-10-01","objectID":"/quick-start/:6:0","tags":["usage"],"title":"Quick Start","uri":"/quick-start/"},{"categories":["Quick Start"],"content":"提示 如果删除之后重新添加子模块失败,进行下列操作后重试: # 移除子模块 git rm submodule-name # 重新克隆远程仓库到public git clone git@github.com:yangzhaoyunfei/yangzhaoyunfei.github.io.git public # 再作为子模块管理 git submodule add -b master git@github.com:yangzhaoyunfei/yangzhaoyunfei.github.io.git public ","date":"2019-10-01","objectID":"/quick-start/:7:0","tags":["usage"],"title":"Quick Start","uri":"/quick-start/"},{"categories":null,"content":"imagepop \" image Syntax Description Header Title Paragraph Text hugo server -D -e production github token 155e39a5c368b4e39f70bd16e1aba571f0fcebb9 idea-setting https://github.com/yangzhoayunfei/idea-setting.git 快速返回上次查看代码的位置 ctrl + alt + 方向键 jackson 日期格式化 https://www.cnblogs.com/carrychan/p/9883172.html github token 155e39a5c368b4e39f70bd16e1aba571f0fcebb9 idea-setting https://github.com/yangzhoayunfei/idea-setting.git ","date":"0001-01-01","objectID":"/template/:0:0","tags":null,"title":"","uri":"/template/"}]